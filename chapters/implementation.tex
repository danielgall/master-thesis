\chapter{Implementation of ACT-R in CHR}

After the comprehensive but at some point informal overview of the ACT-R theory in chapter \ref{actr_description}, this chapter presents a possible implementation of the described concepts of the ACT-R theory in CHR.

For the implementation, some special cases and details that are not exactly defined in theory have to be considered. Hence, some concepts of the theory that are implemented in this work are formalized first. The implementation in form of CHR rules sticks to those formalisms and is often very similar to them.

Additionally, the implementation is described incrementally, ie. first, a very minimal subset of ACT-R is presented that will be refined gradually with the progress of this chapter. In the end, an overview of the actual implementation as a result of this work is given.

Some of the definitions in this chapter result directly from the theory, some of them needed a further analysis of the official ACT-R 6.0 Reference Manual \cite{actr_reference} or the tutorials \cite{actr_tutorial}. 

\section{Declarative and Procedural Knowledge}

The basic idea of the implementation is to represent declarative knowledge, working memory etc. as constraints and to translate the ACT-R production rules to CHR rules. This approach leads to a very compact and direct translation of ACT-R models to Constraint Handling Rules.

In addition to the production rules there will be rules that implement parts of the framework of ACT-R, for example rules that implement basic chunk operations like modifying or deleting chunks from declarative memory or a buffer. Those parts of the system are described as well as the central data structures and the translation.

First, a formalization of declarative knowledge in form of chunk networks and their implementation in CHR is given. Then, the working memory -- also referred to as the buffer system -- is explored and the implementation is discussed. After those definitions of the basic data structures of ACT-R, the procedural system is described including the translation of ACT-R production rules to CHR rules using the previously defined data structures.

Furthermore, the reproduction of ACT-Rs modular architecture is shown and the implementation of the declarative module is presented.

After this overview of the basic concepts of ACT-R, the description goes into more detail about timing issues and the subsymbolic layer.

\section{Chunk Stores}

Since chunks are the central data-structure of ACT-R used for representation of declarative knowledge and to exchange information between modules and to state requests, this section first deals with this central part of ACT-R.

\subsection{Formal Representation of Chunks}

In multiple parts of ACT-R it is necessary to store chunks and then operate on then. Hence, the abstract data structure of such a chunk store is defined.

Since chunk stores have been referred to as networks in the previous chapters, the general idea of this definition of a chunk store bases upon a relation that represents such a network.

\begin{definition}[chunk-store]
A \emph{chunk-store} $\Sigma$ is a tuple $(C,E,\mathcal{T},HasSlot,Isa)$, where $C$ is a set of chunks and $E$ a set of primitive elements, with $C \cap E = \emptyset$. $V = C \cup E \cup \{ \mathtt{nil} \}$ are the \emph{values} of~$\Sigma$ and $\mathcal{T}$ a set of chunk-types. A chunk-type $T = (t,S) \in \mathcal{T}$ is a tuple with a \emph{unique}\footnote{$\forall (t,S), (t',S') \in \mathcal{T}: t = t' \Rightarrow S = S'$ } type name $t$ and a set of slots $S$. The set of all slot-names is $\mathcal{S}$. 

$HasSlot \subseteq C \times \mathcal{S} \times V$ and $Isa \subseteq C \times T$ are relations and are defined as follows:

\begin{itemize}
 \item $c \enspace Isa \enspace T \Leftrightarrow$ chunk $c$ is of type $T$.
 \item $(c,s,v) \in HasSlot \Leftrightarrow v$ is the value of slot $s$ of $c$. This can also be written as $c \overset{s}{\longrightarrow} v$ and is spoken ``$c$ is connected to $v$'' or ``$v$ is in the slot $s$ of $c$''.
\end{itemize}

The $Isa$ relation has to be right-unique and left-total, so each chunk has to have exactly one type.

% The following function is defined:
% 
% \begin{align*}
%  %\item $slots: C \rightarrow \mathcal{S} \times V$ \\
%  %$slots(c) = \{ (s,v) | (c,s,v) \in HasSlot \}$ 
%  slots: \mathcal{T} \rightarrow \mathcal{S} &\\
%        slots((t,S)) = S&
% \end{align*}


A chunk-store is \emph{type-consistent}, iff $\forall (c,(t,S)) \in Isa: \forall s \in S \enspace \exists ! (c,s,v) \in HasSlot$. So every chunk must have exactly one value for each slot of its type and only describe slots of its type. Empty slots are represented by the value \verb|nil|. Since every chunk has exactly one type, this is valid for all chunks in the store.

%iff $\forall(c,s,v) \in HasSlot: c \enspace Isa \enspace (T,S) \Rightarrow \exists s' \in S: s=s'$ and $\forall c \in C: \enspace c \enspace Isa \enspace (T,S) \Rightarrow \forall s \in S: \exists (c',s',v) \in HasSlot: c=c', s=s'$. 

\end{definition}


\begin{definition}[abstract methods of a chunk store]
\label{def:abstract_methods_chunk_store}
The following methods can be defined over a chunk store $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$:

\begin{description}
 \item[\texttt{chunk-type(name slot\textsubscript{1} slot\textsubscript{2} ... slot\textsubscript{n})}] adds the type $T = (\mathtt{name},\{\mathtt{slot_1}, \dots, \mathtt{slot_n}\})$ to the store, ie. $\mathcal{T'} = \mathcal{T} \cup \{T\}$. 
 \item[\texttt{add-chunk(name isa type slot\textsubscript{1} val\textsubscript{1} ... slot\textsubscript{n} val\textsubscript{n})}] adds a new chunk to the store, ie. $C' = C \cup \{ \mathtt{name} \}$, $Isa' = Isa \cup (\mathtt{name}, (\mathtt{type}, slots(\mathtt{type}))$ and $HasSlot' = \bigcup_{i = 1}^n{\mathtt{(name,slot_i,val_i)}} \cup HasSlot.$ Note, that due to the expansion of $C$, the condition that $C$ and $E$ have to be disjoint may be violated. To fix this violation, the element can be removed from $E$: $E' = (E \cup C) - (E \cap C).$ 
 
 Additionally, a valid mechanism to restore type-consistency may be introduced: It might happen, that not all slots are specified in the call of the \verb|add-chunk| method. Since it is claimed by the definition of $HasSlot$ that for all slots $s$ of a chunk $c$ there must be a $(c,s,v) \in HasSlot$, in implementations the unspecified slots are initialized as empty slots, represented by the empty value \verb|nil|. Furthermore, slots specified in the call of the method that are not a member of the chunk's type should cause an error to preserve type-consistency.
  \item[\texttt{alter-slot(name slot\textsubscript{1} val\textsubscript{1} ... slot\textsubscript{n} val\textsubscript{n})}] changes the slot values of a chunk identified by its name. Only existing slots can be altered.
  \item[\texttt{remove-chunk(name)}] removes the chunk with the given name from $C$ and all of its occurrences in $Isa$ and $HasSlot$.
  \item[\texttt{return-chunk(name)}] gets a chunk name as input and returns a chunk specification, ie. the name, type and all slot-value pairs of this chunk in the store.
\end{description} 
\end{definition}

\begin{example}
 \label{ex:addition_fact_formal}
 The addition-fact chunk in figure \ref{fig:chunk_addition_fact} and its chunk-type are defined as follows:\\
\begin{lstlisting}
chunk-type(addition-fact arg1 arg2 sum)
add-chunk(a isa addition-fact arg1 5 arg2 2 sum 7)
\end{lstlisting}
 
 This leads to the following chunk-store: 
 \begin{align*}
 (\{a\}, \{2,5,7\},\\ 
 \{(addition-fact, \{arg1, arg2, sum\})\},\\
 \{(a,arg1,5), (a,arg2,2), (a,sum,7)\},\\
 \{(a, addition-fact)\}).
 \end{align*}
 
 $slots(a) = \{(arg1,5), (arg2,2), (sum,7)\}$ and $slots((addition-fact,\{arg1, arg2, sum\}) = \{arg1, arg2, sum\}$. Hence, the store is type-consistent.
\end{example}

\subsection{Representation of Chunks in CHR}

Declarative knowledge is represented as a network of chunks, defined by the two relations $Isa$, specifying the belonging of a chunk to a type, and $HasSlot$, specifying the slot-value pairs of a chunk. Those relations can be translated directly into CHR by defining the following constraints representing the relations and sets:

\begin{lstlisting}
:- chr_constraint chunk_type(+).
% chunk_type(ChunkTypeName)

:- chr_constraint chunk_type_has_slot(+,+).
% chunk_type_has_slot(ChunkTypeName, SlotName).
\end{lstlisting}

The \verb|chunk_type/1| constraint represents the set $\mathcal{T}$ of chunk-types in the store, but refers only to the chunk-type names. The set of slots of a chunk-type is specified by the \verb|chunk_type_has_slot/2| constraint\footnote{For a chunk-type $T \in \mathcal{T}$, with $T = (t, S)$, there exists a \texttt{chunk\_type(t)} and for every slot $s \in S$ there is a \texttt{chunk\_type\_has\_slot(t,s)} in the constraint store.}.

For the chunks:

\begin{lstlisting}
:- chr_constraint chunk(+,+).
% chunk(ChunkName, ChunkType)

:- chr_constraint chunk_has_slot(+,+,+).
% chunk_has_slot(ChunkName, SlotName, Value)
\end{lstlisting}

The \verb|chunk/2| constraint represents both the set $C$ of chunks and the $Isa$ relation, since the presence of a constraint \verb|chunk(c,t)| signifies, that chunk \verb|c| is of a type $T = (\mathtt{t},S)$.

The $HasSlot$ relation is represented by the \verb|chunk_has_slot(c,s,v)| constraint, which really is just a direct translation of an element $(c,s,v) \in HasSlot$.

Note that all values in the just presented constraints have to be ground. This is a demand claimed by the original ACT-R implementation and makes sense, since each value in a slot of a chunk is a real, ground value and the concept of variables does not have an advantage in this context, because every element that can be stored in the brain is assumed to be known by the brain.

Additionally, from the definition of a chunk store it is known, that the $HasSlot$ and the $Isa$ relations have to be left-complete. \FIXME{correct expression! correct definitions!} Therefore, for every chunk \verb|c| in the store, exactly one \verb|isa(c,t)| constraint has to be in the store. For each \verb|chunk_type_has_slot(t,s)| constraint, a \verb|chunk_has_slot(c,s,v)| constraint has to be defined. If one wants to express, that a chunk has an empty slot, he might use \verb|nil| for the value to indicate that. Note that \verb|nil| must not be a chunk name or chunk-type name.

\begin{example}
\label{ex:addition_fact_chr}
The chunk and chunk-type in example~\ref{ex:addition_fact_formal} are represented as:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)
\end{lstlisting}
\end{example}


\subsubsection{Distinction of Elements and Chunks}

A chunk store distinguishes between a set of chunks $C$ and a set of elements $E$. For implementational reasons it can be helpful if there are only chunks in the system, because elements just behave like chunks with no slots. Hence, a chunk-type \verb|chunk| with no slots will be added automatically to the store. Each element $e \in E$ and added as a chunk of type \verb|chunk| to the set of chunks $C$. After this operation $E = \emptyset$, and for every former element $e$ of $E$: $e \in C$, $(e,(chunk,\emptyset)) \in Isa$.

So $E$ is represented now by $\{ c \in C | c Isa (chunk,\emptyset)$ in the implementation.

\begin{example}
The chunk representation from example~\ref{ex:addition_fact_chr} is changed to:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk_type(chunk)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)

chunk(5,chunk)
chunk(2,chunk)
chunk(7,chunk)
\end{lstlisting}

\end{example}


\subsubsection{Simple Implementation of the Default Methods}
\label{chunk_specification}

To implement the methods in definition~\ref{def:abstract_methods_chunk_store}, first a data type for chunk specifications has to be introduced. From this specification the correct constraints modeling the chunk-store are added or modified.

The straight-forward definition of a data type for chunk specifications is just to use the specification like in definition~\ref{def:abstract_methods_chunk_store}: Since \verb|(name isa type slot_1 val_1 \dots slot_n val_n)| is just a list in LISP and specifies a chunk uniquely, a similar Prolog term can be used:

\begin{lstlisting}
:- chr_type chunk_def ---> nil; chunk(any, any, slot_list).
:- chr_type list(T) ---> []; [T | list(T)].
% a list of slot-value pairs
:- chr_type slot_list == list(pair(any,any)).
:- chr_type pair(T1,T2) ---> (T1,T2).
\end{lstlisting}

This definition states that a chunk is either \verb|nil|, ie. an empty chunk, or a term \verb|chunk(Name, Type, SVP)|, where \verb|SVP| is a list of slot-value pairs. This is the direct translation of the chunk-specification used in the definition, amended by the \verb|nil| construct, that may be needed for later purposes.

The default methods can be implemented as follows:

\paragraph{add\_chunk}

This method creates the chunks and elements of the chunk store. The set $E$ of elements is minimal, ie. only elements that appear in the slots of a chunk but are not chunks themselves are members of $E$. However, the set $E$ is never constructed explicitly, but represented by chunks of the special type \verb|chunk| that provides no slots. So each value in the slot of a chunk that is added to the store and that is not an element of the chunk store yet, gets its own chunk of type \verb|chunk|. As soon as a chunk with the name of such a primitive element is added to the store, the chunk of type \verb|chunk| is removed from the store.

\begin{lstlisting}[caption={Rules for \texttt{add\_chunk}}, label=lst:add_chunk_rules]
% empty chunk will not be added
add_chunk(nil) <=> true.
  
% initialize all slots with nil
add_chunk(chunk(Name,Type, _)), chunk_type_has_slot(Type,S) ==> 
  chunk_has_slot(Name,S,nil).

% chunk has been initialized with empty slots -> actually add chunk
add_chunk(chunk(Name,Type, Slots)) <=>
  do_add_chunk(chunk(Name,Type,Slots)).
\end{lstlisting}

First, all \verb|chunk_type_has_slot| constraints are added to the store and initialized with \verb|nil| as slot value. This leads to complete chunk specifications that are consistent to the type as demanded by a type-consistent chunk-store.

If all slots have been initialized, \verb|do_add_chunk| performs the actual setting of the real slot values:
  
\begin{lstlisting}[caption={Additional rules for adding chunks}]  
% base case
do_add_chunk(chunk(Name, Type, [])) <=> chunk(Name, Type). 

% overwrite slots with empty values
chunk(V,_) \ do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=>
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).

% overwrite slots with empty values  
do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=> 
  V == nil | % do not add chunk(nil,chunk)
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).  

% overwrite slots with empty values  
do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=> 
  V \== nil |
  chunk_has_slot(Name,S,V), 
  chunk(V,chunk), % no chunk for slot value found => add chunk of type chunk 
  
do_add_chunk(_) <=> false.
\end{lstlisting}

The first rule is the base case, where no slots have to be added any more. Then, as a last step the actual \verb|chunk| constraint of the chunk that is added to the store is created.

The second rule deals with the case, that a slot-value pair has to be added with a value that is already described by a chunk. Then the \verb|nil|-initialized slot of this chunk is removed and replaced by another slot containing the actual value.

The next rule ensures that the helper chunk specification \verb|nil| will not get a chunk in the store, even if it is in the slots of a chunk.

Otherwise, if the value of the slot to be added is not \verb|nil|, the next rule can fire and the slot with the actual value will replace the previously \verb|nil|-initialized slot with the actual value. Additionally, since the first rule obviously did not fire for this constellation, \verb|V| is a value different from \verb|nil| that does not have a chunk in the store. Hence, it must be a primitive element. Thus a new chunk of type \verb|chunk| is added to the store for this value.

If no rule matches, the user tried to create a chunk with slots that are not specified in the chunk-type. This leads to an error.

On top of the rules in listing~\ref{lst:add_chunk_rules}, there must be added a rule that deletes a primitive element (ie. a chunk of type \verb|chunk|), if the user introduces a real chunk with the name of this element:

\begin{lstlisting}[caption={Clean up primitive elements}]  
% delete chunk of Type chunk, if real chunk is added
add_chunk(chunk(Name,_,_)) \ chunk(Name,Type) <=> 
  Type == chunk |
  true.
\end{lstlisting}


\paragraph{add\_chunk\_type}

The following rules create a new chunk type:

\begin{lstlisting}[caption={rules for \texttt{add\_chunk\_type}}]
add_chunk_type(CT, []) <=> 
  chunk_type(CT).
add_chunk_type(CT, [S|Ss]) <=> 
  chunk_type_has_slot(CT, S), 
  add_chunk_type(CT, Ss).
\end{lstlisting}

\paragraph{alter\_slot}

This method replaces the value of an existing slot for a given chunk, but only if it is a valid slot for the chunk-type of the altered chunk.

\begin{lstlisting}
alter_slot(Chunk,Slot,Value), chunk_has_slot(Chunk,Slot,_) <=>
  chunk_has_slot(Chunk,Slot,Value).
  
alter_slot(Chunk,Slot,Value) <=>
  false.
\end{lstlisting}

The first rule replaces the existing \verb|chunk_has_slot| constraint by a new one. This is called \emph{destructive assignment} as described in \cite[32]{fru_chr_book_2009}. The second rule only matches, if the first did not match (due to the refined operational semantics of CHR). This is only the case, if it is tried to alter a slot with a non-existing \verb|chunk_has_slot| constraint. However, since the chunk descriptions are complete, the slot cannot be valid for the type of the chunk and the altering has to fail.

\paragraph{remove\_chunk}

This method removes all occurrences of a chunk.

\begin{lstlisting}
remove_chunk(Name) \ chunk(Name, _) <=> true.
remove_chunk(Name) \ chunk_has_slot(Name, _, _) <=> true.
remove_chunk(_) <=> true.
\end{lstlisting}

\paragraph{return\_chunk}

This method creates a chunk specification as defined in section~\ref{chunk_specification} from the chunk name of a chunk in the store.

\begin{lstlisting}[caption={rules for \texttt{return\_chunk}}]
chunk(ChunkName, ChunkType) \ return_chunk(ChunkName,Res) <=> 
  var(Res) | 
  build_chunk_list(chunk(ChunkName, ChunkType, []),Res).

chunk_has_slot(ChunkName, S, V) \ build_chunk_list(chunk(ChunkName, ChunkType, L), Res) <=> 
  \+member((S,V),L) | 
  build_chunk_list(chunk(ChunkName, ChunkType, [(S,V)|L]),Res).
  
build_chunk_list(X,Res) <=> Res=X.
\end{lstlisting}

The first rule creates the initial chunk specification with name and type set, but without any slot specification. This initial representation is handed to the \verb|build_chunk_list| constraint.

The second rule adds a slot-value pair from the store to the list of slot-value pairs in the specification and builds the next chunk specification from this new representation.

In the last rule, the process terminates, if no other rule can fire any more. Then the result is bound to the handed specification.

\subsubsection{Checking Consistency and Type-Consistency}

At the moment, there are no rules that check the consistency of the chunk store. However, if the default methods for adding chunks are used, a type-consistent store is built automatically, since for every chunk has exactly one chunk-type\footnote{left-totality and right-uniqueness of $Isa$} and all slots from its chunk-type are described and only those slots are described (satisfies type-consistency). Additionally, there are no two different slot descriptions for the same chunk and every chunk in the store is described\footnote{This is demanded by the type-consistency: Since $Isa$ is left-total, every chunk is in the $Isa$ relation. Type-consisteny demands, that every chunk in the $Isa$ relation has a value for all slots of its type.} (satisfies the definition of a chunk-store).

Rules for checking those constraints could be added easily to the implementation.

\section{Procedural Module}

The part of the system, where the computations are performed, is the procedural module. It is the central component, that holds all the production rules, the working memory (in the buffer system) and organizes communication between modules (through buffers and requests). In the following, all of those subcomponents of the procedural module are described.

\subsection{Buffer System}

The buffer system can be regarded as a chunk-store, that is enhanced by buffers. A buffer can hold only one chunk at a time. The procedural module has a set $B$ of buffers, a chunk-store $\Sigma$ and a relation between the buffers and the chunks in $\Sigma$.

\begin{definition}[buffer system]
\label{def:buffer_system}
A \emph{buffer system} is a tuple $(B,\Sigma,Holds)$, where $B$ is a set of buffers, $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$ a type-consistent chunk-store and $Holds \subseteq B \times (C \cup \{ \mathtt{nil} \})$ a right-unique and left-total relation, that assigns every buffer at most one chunk that it holds. If a buffer $b$ is empty, ie. it does not hold a chunk, then $(b,\mathtt{nil}) \in Holds$.

A buffer system is \emph{consistent}, if every chunk that appears in $Holds$ is a member of $C$ and $\Sigma$ is a type-consistent chunk-store.

A buffer system is \emph{clean}, if its chunk-store only holds chunks which appear in $Holds$.
\end{definition}

For the implementation of a buffer system, the code of a chunk-store can be extended by a \verb|buffer/2| constraint, that encodes the set $B$ and the relation $Holds$ at once, since the relation is complete by definition\footnote{$\forall b \in B \enspace \exists c \in (C \cup \{ \mathtt{nil} \}): (b,c) \in Holds$}.

\subsubsection{Destructive Assignment and Consistency}
\label{destructive_assignment}

The demand of $Holds$ being right-unique\footnote{$\forall b \in B \enspace \forall c, d \in (C \cup \{ \mathtt{nil} \}): (b,c), (b,d) \in Holds \Rightarrow b = c$} is a form of destructive assignment as described in \cite[p. 32]{fru_chr_book_2009}, ie. if a new chunk is assigned to a buffer, the old \verb|buffer| constraint is removed and a new \verb|buffer| constraint is introduced, holding the new chunk:

\begin{lstlisting}
set_buffer(B, C) \ buffer(B, _) <=> buffer(B, C).
\end{lstlisting}

This rule ensures that only one \verb|buffer| constraint exists for each buffer in $B$.

At the beginning of the program, a \verb|buffer| constraint has to be added for all the available buffers of the modules. This problem is discussed in section~\ref{initialization}.

In addition, if a new chunk is put into a buffer, it also has to be present in the chunk-store, since the production system relies on the knowledge about the chunks in its buffers and chunks are essentially defined by their slots (\emph{consistency property} in definition~\ref{def:buffer_system}). Hence, every time a chunk is stored in a buffer, the \verb|add_chunk| method described in definition~\ref{def:abstract_methods_chunk_store} has to be called. However, the chunks in the slots are not loaded, since they are not present for working memory. They only appear as primitive elements in the chunk-store. Figure~\ref{fig:buffer_system}

%This process is discussed later when talking about buffer requests in section~\ref{buffer_requests}.

\subsubsection{Buffer States}

Another formal detail of the buffer system is that buffers can have various states: \emph{busy}, \emph{free} and \emph{error}. A module is busy, if it is completing a request and free otherwise.

Since a module can only handle one request at a time and requests may need a certain time (like the retrieval request for example), the procedural module could state another request to a busy module. This is called \emph{jamming} which leads to error messages and should be avoided. One technique to avoid module jamming is to \emph{query} the buffer state in the conditional part of a production rule \cite[unit 2, p. 9]{actr_tutorial}. The possibility to query buffer states is discussed in the next section.

A buffer's state is set to \emph{error}, if a request was unsuccessful because of an invalid request specification or, in case of the declarative module for instance, a chunk that could not be found.

In CHR, a buffer state can be represented by a \verb|buffer_state(b,s)| constraint, which signifies that buffer \verb|b| has the state \verb|s|. Since every buffer has exactly one state all the time, it is required, that for every buffer there is such a constraint and it is ensured, that only one \verb|buffer_state| constraint is present for each buffer. This can be achieved by the destructive assignment method described in section~\ref{destructive_assignment}. 

At the beginning of the program, when a buffer is created (a \verb|buffer| constraint is placed into the store), a corresponding \verb|buffer_state| constraint has to be added. The initial state can be set to \verb|free|, since no request is being computed at the time of creation.

\subsection{Production Rules}

Production rules consist of a \emph{condition} part and an \emph{action} part. Syntactically, in ACT-R the condition is separated from the action by \verb|==>|. Additionally, each production rule has a name. Thus, a rule is defined by:

\begin{verbatim}
(p name condition* ==> action*)
\end{verbatim}

The condition part is also called the \emph{left hand side} of a rule (LHS) and the action part is called \emph{right hand side} (RHS).

\subsubsection{The Left Hand Side of a Rule}

Generally, a condition is either a \emph{buffer test}, ie. a specification of slot-value pairs that are checked against the chunk in the specified buffer or a \emph{buffer query}, ie. a check of the state of a buffer's module (either busy, free or error). A buffer test on the LHS of a rule is indicated by a \verb|=| followed by the buffer name of the tested buffer; a query is indicated by a \verb|?| in front of the buffer name.

The LHS of a rule may contain bound or unbound variables: \verb|=varname| is a variable with name \verb|varname|.

If the chunks in the buffers pass all buffer tests specified by the rule, the rule can fire, ie. its right hand side will be applied. The LHS is a conjunction of buffer tests, ie. there is no specific order for the tests \cite[p. 165]{actr_reference}.

\begin{example}[counting example -- left hand side]
The left hand side of the counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  ... )
\end{lstlisting}

The condition part consists of two buffer tests:

\begin{enumerate}
 \item The goal buffer is tested for a chunk of type \verb|count| and a slot with name \verb|number|. The value of the slot is bound to the variable \verb|=n|.
 \item The retrieval buffer is tested for a chunk of type \verb|count-fact| that has the variable \verb|=n| in its \verb|first| slot (with the same value as the \verb|number| slot of the chunk in the goal buffer, since \verb|=n| has been bound to that value), and another value in its second slot which is bound to the variable \verb|=m|.
\end{enumerate}

\end{example}

\subsubsection{The Right Hand Side of a Rule}

For the right hand side of a rule the following actions are allowed:

\begin{description}
 \item[Buffer Modification] 
 \item[Buffer Request]
 \item[Buffer Clearing]
\end{description}


\begin{example}[counting example]
\label{ex:counting}
The counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  =goal>
    number =m
  +retrieval>
    isa    count-fact
    first  =m
)
\end{lstlisting}

\FIXME{add description}

\end{example}

\subsubsection{Direct Translation of Buffer Tests}

An ACT-R production rule of the form

\begin{lstlisting}[mathescape]
(p name
  =buffer$_\mathtt{1}$>
    isa    type$_1$
    slot$_\mathtt{1,1}$  val$_\mathtt{1,1}$
    ...
    slot$_\mathtt{1,n}$  val$_\mathtt{1,n}$
  ...
  =buffer$_\mathtt{k}$>
    isa    type$_\mathtt{k}$
    slot$_\mathtt{k,1}$  val$_\mathtt{k,1}$
    ...
    slot$_\mathtt{k,m}$  val$_\mathtt{k,m}$
==>
... )
\end{lstlisting}

states formally, that:

If $buffer_1 \enspace Holds \enspace c_1 \enspace \wedge \enspace c \enspace Isa \enspace type_1 \enspace \wedge \enspace c_1 \xrightarrow{slot_{1,1}} val_{1,1} \enspace \wedge \enspace \dots \enspace \wedge \enspace buffer_k \enspace Holds \enspace c_k \enspace \wedge \enspace c_k \enspace Isa \enspace type_k \enspace \wedge \enspace \dots$ is true, then the rule matches and the RHS should be performed.

This can be directly translated into a CHR rule:

\begin{lstlisting}[mathescape]
name @
  buffer(buffer$_\mathtt{1}$,C$_\mathtt{1}$),
  chunk(C$_\mathtt{1}$,type1),
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,1}$,val$_\mathtt{1,1}$),
  ...
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,n}$,val$_\mathtt{1,n}$),
  ...
  buffer(bufferk,C$_\mathtt{k}$),
  chunk(C$_\mathtt{k}$,type$_\mathtt{k}$),
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,1}$,val$_\mathtt{k,1}$),
  ...
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,m}$,val$_\mathtt{k,m}$)
==>
  ...
\end{lstlisting}

This rule checks the buffer system for the existence of a buffer holding a particular chunk and then checks the chunk store of the buffer system for that chunk with the type and slots specified in the ACT-R rule. The rule is a propagation rule, because the information of the chunk-store should not be removed.

If the values in the slot tests are variables, they can be directly translated to Prolog variables.

The CHR rule only fires, if all the checked buffers hold chunks that meet the requirements specified in the slot tests of the ACT-R rule. Since those slot-tests are just a conjunction of relation-membership tests and the CHR rule is a translation of these tests into constraints, both are equivalent. In detail: \FIXME{geht besser}

\begin{itemize}
 \item If a checked buffer \verb|b| holds no chunk, the constraint \verb|buffer(b,nil)| will be present, but the chunk store will not hold any of the required \verb|chunk| or \verb|chunk_has_slot| constraints and the rule will not fire.
 \item If a checked buffer \verb|b| holds a chunk, but the chunk does not meet one of the requirements in its slots, the rule does not fire.
 \item The rule only fires, if for all checked buffers there are valid \verb|buffer|, \verb|chunk| and \verb|chunk_has_slot| constraints present that meet all the requirements specified by the ACT-R rule.
 \item Variables on the LHS of a rule are bound to the values of the actual constraints that are tried for the matching. After the matching, each variable from the rule has a ground value bound to it, because there are no variables in the implementation of the buffer store. This corresponds to the semantics of a ACT-R production rule with variables on the LHS.
\end{itemize}

\FIXME{ist die begründung schlüssig? evtl section über variablen hier einfügen}

\subsubsection{Translation of Actions}
\label{translation_of_actions}

For each action type a constraint

\begin{lstlisting}
buffer_action(buffer,chunk-specification)
\end{lstlisting}

with corresponding rules that handle the action have to be added. Note, that the buffer action is defined by the action name, the buffer name and a chunk specification, because actions in ACT-R are defined through a buffer modifier that specifies the action, the name of the buffer and a list of slot-value pairs. Hence, this is a direct translation to CHR.

\paragraph{Buffer Modifications}

The modification of a buffer takes an incomplete chunk specification and modifies the given slots of the chunk in the specified buffer. This can be implemented as follows:

\begin{lstlisting}
buffer(BufName, OldChunk) \ buffer_change(BufName, chunk(_,_,SVs)) <=>
  alter_slots(OldChunk,SVs).
\end{lstlisting}

This implementation uses a generalization of the \verb|alter_slot| method as described in definition~\ref{def:abstract_methods_chunk_store} and section~\ref{chunk_specification}:

\begin{lstlisting}  
alter_slots(_,[]) <=> true.
alter_slots(Chunk,[(S,V)|SVs]) <=> 
  alter_slot(Chunk,S,V),
  alter_slots(Chunk,SVs). 
\end{lstlisting}

Note that types cannot be changed. This corresponds to the grammar definition of ACT-R as presented in section~\ref{production_rule_grammar}.

\paragraph{Buffer Clearings}

When clearing a buffer, the chunk that was stored in the buffer will be removed from the chunk store and \verb|nil| will be written to the store. Additionally, the chunk goes to the declarative memory.

\begin{lstlisting}
do_buffer_clear(BufName), buffer(BufName, ModName, Chunk) <=> 
  write_to_dm(Chunk), 
  delete_chunk(Chunk), 
  buffer(BufName, nil).
\end{lstlisting}

\verb|write_to_dm| handles the writing of the chunk to the declarative memory:

\begin{lstlisting}
write_to_dm(ChunkName) <=> return_chunk(ChunkName, ResChunk), add_dm(ResChunk).
\end{lstlisting}

where \verb|add_dm| is basically just a global wrapper for the \verb|add_chunk| method of the declarative memory and will be explained in section~\ref{global_method_for_adding_chunks}.

\paragraph{Buffer Requests} The buffer requests have to be handled a little bit differently from the other actions. Therefore, they will be explained in section~\ref{interface_for_module_requests}. The changes to the buffer system are presented in section~\ref{how_the_buffer_system_states_a_request} and an example implementation of the module request interface for retrieval requests is given in section~\ref{retrieval_requests}.


\begin{example}[counting example in CHR -- simple]
The production rule in example~\ref{ex:counting} can be translated to:

\begin{lstlisting}
count-rule @
  buffer(goal,C1), 
    chunk(C1,count),
    chunk_has_slot(number,N),
  buffer(retrieval,C2),
    chunk(C2,count-fact),
    chunk_has_slot(first,N),
    chunk_has_slot(second,M)
==>
  buffer_change(goal,chunk(_,_,[(number,M)])),
  buffer_request(retrieval,chunk(_,count-fact,[first,M)])).
\end{lstlisting}

\end{example}


\subsection{Translation of Buffer Queries}

A buffer query

\begin{lstlisting}
...
?buffer>
  state  bstate 
...
==> ...
\end{lstlisting}

on the LHS of a production rule can be translated to the following CHR rule head:

\begin{lstlisting}
...
buffer_state(buffer,bstate) ... ==> ...
\end{lstlisting}

\subsubsection{The Production Rule Grammar}

The discussed concepts lead to the following grammar for production rules, which is a simplified version of the actual grammar used in the original ACT-R implementation \cite[p. 162]{actr_reference}. 


\begin{lstlisting}{caption={The ACT-R production rule grammar} label=lst:production_rule_grammar}
production-definition ::= (p name condition* ==> action*)
name ::= a symbol that serves as the name of the production for reference
condition ::= [ buffer-test | query ]
action ::= [buffer-modification | request | buffer-clearing | output ]
buffer-test ::= =buffer-name> isa chunk-type slot-test*
buffer-name ::= a symbol which is the name of a buffer
chunk-type ::= a symbol which is the name of a chunk-type in the model
slot-test ::= {slot-modifier} slot-name slot-value
slot-modifier ::= [= | - | < | > | <= | >=]
slot-name ::= a symbol which names a possible slot in the specified chunk-type
slot-value ::= a variable or any Lisp value
query ::= ?buffer-name> query-test*
query-test ::= {-} queried-item query-value
queried-item ::= a symbol which names a valid query for the specified buffer
query-value ::= a bound-variable or any Lisp value
buffer-modification ::= =buffer-name> slot-value-pair*
slot-value-pair ::= slot-name bound-slot-value
bound-slot-value ::= a bound variable or any Lisp value
request ::= +buffer-name> isa chunk-type request-spec*
request-spec ::= {slot-modifier} slot-value-pair
request-parameter ::= a Lisp keyword naming a request parameter provided by the buffer specified
buffer-clearing ::= -buffer-name>
variable ::= a symbol which starts with the character =
output ::= !output! [ output-value ]
output-value ::= any Lisp value or a bound-variable
bound-variable ::= a variable which is used in the buffer-test conditions of the production (including a
variable which names the buffer that is tested in a buffer-test or dynamic-buffer-test) or is bound with
an explicit binding in the production
\end{lstlisting}

Some of the details in this grammar that have not been discussed yet are presented in the following.

\subsubsection{The Order of Rule Applications}

In the current translation scheme, the order of the rule applications does not match the semantics as described in the ACT-R theory\footnote{see section~\ref{procedural_knowledge}}. Consider the following rules in a compact notation:

\begin{lstlisting}
=b1>
  isa foo
  s1  v1
==>
=b1>
  s1  v2
=b2>
  s   x
\end{lstlisting}

and

\begin{lstlisting}
=b1>
  isa foo
  s1  v2
==>
=b2>
  s   y
=b1>
  s1  v3 % for termination
\end{lstlisting}

In the semantics of ACT-R, if the first rule matches, all the buffer modifications are performed first. After that, the procedural module can look for the next matching rule, which is the second one (due to the result of the first rule). This rule then would overwrite the value \verb|x| in the \verb|s| slot of buffer \verb|b2| with \verb|y|.

\begin{lstlisting}
buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)
==>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])).

buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)
==>
buffer_change(b2,chunk(_,_,[(s,y)])),
buffer_change(b1,chunk(_,_,[(s1,v3)])). % this is for termination
\end{lstlisting}

For the query

\begin{lstlisting}
chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c).
\end{lstlisting}

the result would be

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c2,s,x)
chunk_has_slot(c,s1,v3)
\end{lstlisting}

Ie., the buffer \verb|b2| holds the chunk with value \verb|x|. This is due to the fact, that after the first rule has modified the buffer \verb|b1|, the second rule matches and will be fired immediately, which then changes the value of \verb|b1| to \verb|y|. Afterwards, the second action of the first rule will be executed and the \verb|s| slot of the chunk in buffer \verb|b2| will be overwritten with \verb|x|.

Hence, somehow the fact that the procedural module is busy and cannot fire another rule, has to be modeled. This can be achieved by a simple phase constraint \verb|fire| that will be added after the complete execution of a rule and will be removed as soon as a rule is executed.

For every production rule, the rule

\begin{lstlisting}
{ buffer_tests } ==> { actions }
\end{lstlisting}

has to be changed to a simpagation rule

\begin{lstlisting}
{ buffer_tests } \ fire <=> { actions }, fire.
\end{lstlisting}

It is important, that the adding of \verb|fire| is the last action of a rule.

The example would be modified as follows:

\begin{lstlisting}
buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)
  \ fire
<=>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])),
fire.

buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)
  \ fire
<=>
buffer_change(b2,chunk(_,_,[(s,y)])),
fire.
\end{lstlisting}


The test query

\begin{lstlisting}
chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c), fire.
\end{lstlisting}

yields

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c,s1,v3)
chunk_has_slot(c2,s,y)
fire
\end{lstlisting}

The fire constraint has to be added at the end of the query. This ensures the correct semantics and a completely constructed buffer system.\footnote{This was actually the reason, why in the first example without the \texttt{fire} constraint, the buffer \texttt{b1} was created at the end of the query: If it would be created at an earlier point, the first rule would have matched immediately and the computation would have yielded a different result.}

In appendix~\ref{app:ex:rule_order} a minimal executable example is provided.

\subsubsection{Bound and Unbound Variables}
\label{bound_and_unbound_variables}

According to the ACT-R production rule grammar in listing~\ref{lst:production_rule_grammar}, unbound variables can only appear on the left hand side of a rule. Hence, no new variables are introduced on the right hand side. Since all the elements in the buffer store are completely described and ground, every variable on the LHS of a rule will be bound to a ground value. This simplifies the rule selection and application process a lot, since every value of the calculation is known after the matching. This enables simple implementations of arithmetic tests, for example (see section~\ref{slot_modifiers}).

\subsubsection{Double Chunk Checks}

A problem that has not been addressed yet, is that ACT-R allows buffer tests like the following:

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  spam
\end{lstlisting}

In the logical reading, this would signify that $buffer \enspace Holds \enspace c \enspace \wedge \enspace c \enspace Isa \enspace foo \enspace \wedge \enspace c \xrightarrow{bar} spam \enspace \wedge \enspace c \xrightarrow{bar} spam$ which is equivalent to the test with only one check of the \verb|bar| slot\footnote{$x \wedge x = x$}.

However, in CHR the following rule resulting from the simple translation scheme would not match:

\begin{lstlisting}
buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam),
chunk_has_slot(C,bar,spam)
\end{lstlisting}

Because there are no two identical \verb|chunk_has_slot| constraints in the store, the rule could not fire. When translating such a rule, the second test has to be eliminated.

However, this does not the trick for all possible cases. For example, suppose a test

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  =x
\end{lstlisting}

where the second test refers to a variable (or even both tests are variables). This problem could be solved by adding a guard to the rule from the simple translation:

\begin{lstlisting}
buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)
==> spam == X
\end{lstlisting}

Since \verb|X| must be bound after the matching\footnote{see section~\ref{bound_and_unbound_variables}}, the test will always give the correct result. This also works for the first example, where the test would be \verb|spam == spam|, which is always true and hence could be reduced to the rule with the second test eliminated and no guard\footnote{true guards can always be reduced}.

It also works if the two slot-tests were contradictory, for example: 

\begin{lstlisting}
bar  spam
bar  eggs
\end{lstlisting}

would describe a rule that never can fire. The translation models exactly this behaviour:

\begin{lstlisting}
buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)
==> spam == eggs
\end{lstlisting}

since the built-in syntactic-equality test of Prolog would never return true for those two constants.

\subsubsection{Slot Modifiers}
\label{slot_modifiers}

In ACT-R, slot-tests can be preceded by \emph{slot modifiers}. Those modifiers allow to specify tests like inequality (\verb|-|) or arithmetic comparisons (\verb|<, >, <=, >=|) of the slot value of a chunk with the specified variable or value. Since the slots in a chunk store are always fully defined with ground values, those tests are decidable.

If no slot modifier is specified in a slot test, the default modifier \verb|=| is used, that states that the chunk in the specified buffer must have the specified value in the specified slot. This default semantics has been used in the previous sections when translating simple ACT-R rules to CHR and is performed automatically by the matching of CHR.

To translate the other slot modifiers to CHR, another CHR mechanism can be used: Guards. Since the allowed modifiers are all default built-in constraints\footnote{ie. Prolog predicates}, a slot test with a modifier

\begin{lstlisting}
...
=buffer>
  ...
  ~slot  val
...
==>
\end{lstlisting}

where \verb|~| stands for one of the modifiers in \{ \verb|=,-,<,>,<=,>=| \} can be translated as follows:

\begin{lstlisting}
buffer(buffer,C),
  ...
  chunk_has_slot(C,slot,V),
  ...
==>
  V # val |
  ...
\end{lstlisting}

where \verb|#| is the placeholder for the built-in constraint that computes the test specified by \verb|~| and \verb|V| is a fresh variable that has not been used in the rule, yet.

For arithmetic slot modifiers the values being compared have to be numbers. If a value is not a number, the arithmetic test will fail and the rule cannot be applied \cite{actr_reference}.

Note, that slot tests with modifiers other than \verb|=| do not bind variables, but only perform simple checks, like it is with guards in CHR. If \verb|val| is an unbound variable and is never bound to a value on LHS, the default implementation throws a warning, and the rule will not match. Therefore, to handle this case, the rule translation scheme has to be extended by an additional guard check \verb|ground(Val)|, where \verb|Val| is the Prolog variable that replaces each occurrence of the variable \verb|val|.

As with normal slot tests, it is important to mention that if there are several tests on the same slot, the \verb|chunk_has_slot| constraint must appear only once on the LHS of the CHR rule, since every slot-value pair is unique in the constraint store. Ie., if the first slot test of a particular slot appears on the LHS of the ACT-R rule, a \verb|chunk_has_slot| constraint has to be added to the LHS of the CHR rule. For every other occurrence of this slot in a slot test, only guard checks are added.

\begin{example}
To clarify the details of the matching concept in ACT-R, here are some examples and their behaviour:

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
\end{lstlisting}

will throw a warning when loading the model. When running it, the rule will never fire, since no chunk value will match the inequality to the unbound variable \verb|bar|.

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
  eggs   =bar
\end{lstlisting}

will fire, if there is a chunk whose value in \verb|eggs| is different from the value in \verb|spam|.

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
\end{lstlisting}

matches for every value of the spam slot. The translation to CHR is:

\begin{lstlisting}
buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar),
==>
  Bar=Eggs |
  ...
\end{lstlisting}

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
  ham   =eggs
\end{lstlisting}

will match all chunks which have the same value in \verb|spam| and \verb|ham|. \FIXME{CHR translation???}

\end{example}

\paragraph{Relation to Negation-as-Absence}

Negation-as-absence as described in \cite[147\psqq]{fru_chr_book_2009} is a concept provided by many production rule systems. It enables the programmer to negate a fact in the sense that the fact is not in the store and therefore the rule is applicable -- so the programmer asks for the absence of a particular fact.

At the first glance, the slot modifiers seem to implement this concept, but this is not the case: All negated slot tests in ACT-R can be reduced to simple built-in guard checks, because the chunks in the store are always described completely and the values are ground, so simple built-in checks work automatically. This also works for invalid slot-tests that ask for slots which are not offered by the chunk-type they ask for. Then there will never be a constraint matching the head of the rule due to type consistency.

With these restrictions, ACT-R avoids the problems that come with negation-as-absence as they are explained in \cite[147\psqq]{fru_chr_book_2009} and the translation of such tests to CHR is very simple.

\subsubsection{Empty Slots}

An important special case in the semantics of ACT-R production rules is, that if there is a slot test specified, then a potential chunk only matches, if it really has a value in this slot. Chunks that have \verb|nil| in a slot specified in a buffer test, will not match the test. Hence, variables can not be used to test if two slots have the same value and the value is \verb|nil|, since every positive slot test involving \verb|nil| fails automatically \cite[p. 164, section ``Variables'', last sentence]{actr_reference}.

In CHR this special case can be handled, by adding a guard for each variable occurring in a positive slot-test checking that this variable does not equal \verb|nil|.

For negated slot tests, this is not the case: 

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  4
\end{lstlisting}

matches also a chunk with an empty \verb|spam| slot (\verb|nil| in its \verb|spam| slot).



\subsubsection{Outputs}

The production system of ACT-R also provides methods to produce side-effects. In this work, only a subset of those methods is concerned: the outputs. Outputs can appear on the right hand side of an ACT-R rule:

\begin{lstlisting}
=buffer>
  isa  foo
==>
  !output! (a1 a2 a3)
\end{lstlisting}

The argument of such an output call is a list of Lisp-symbols, so it is possible to hand variables or terms.

This mechanism can be translated to Prolog directly:

\begin{lstlisting}
output([]) :-
  nl.
output([X|Xs]) :-
  write(X),
  output(Xs).
\end{lstlisting}

The \verb|X| have to be Prolog terms.

In ACT-R, function calls like \verb|!eval!| or \verb|!bind!| are allowed, but they are ignored in this work.

\section{Modular Organization}

The term \emph{module} is highly overloaded: In ACT-R it describes independent parts of human cognition, whereas in the world of programming the term is used in a slightly different manner. In the following, implementational modules will always be named explicitly as \emph{Prolog modules}.

Nevertheless, the modular organization of ACT-R with its independent modules can be implemented by defining a Prolog module for each ACT-R module and adding some other modules around them. In the following, the concept of Prolog modules is explained.

\subsection{Prolog Modules}

Defining a new module creates a new namespace for all CHR constraints and Prolog predicates, which is illustrated in the following example:

\begin{example}[Prolog Modules and CHR]

In this example, two modules \verb|mod1| and \verb|mod2| are defined, with partially overlapping constraints. \verb|mod2| exports the constraint \verb|c|. In the following, the behaviour an interaction of the modules is explored.

\begin{lstlisting}[caption={Definition of Module 1},label=lst:mod1]
:- module(mod1,[]).
:- use_module(library(chr)).

:- use_module(mod2).

:- chr_constraint a/0, b/0.

a <=> c.
\end{lstlisting}

\begin{lstlisting}[caption={Definition of Module 2},label=lst:mod2]
:- module(mod2,[c/0]).
:- use_module(library(chr)).

:- use_module(mod1).

:- chr_constraint a/0, b/0, c/0. 

a <=> b.
b <=> mod1:a.
\end{lstlisting}


In this definition, two new modules \verb|mod1| and \verb|mod2| are created and only the \verb|c| constraint of \verb|mod2| is exported, indicated by the lists in the module definitions.

The CHR constraint \verb|a| in listing~\ref{lst:mod1} is internally represented as \verb|mod1:a|, so it lives in its own namespace and does not pollute other namespaces. The constraint can appear on the right hand side of rules of other modules, but has to be called explicitly with its full namespace identifier. In line~8 of listing~\ref{lst:mod2}, the presence of the local \verb|a| constraint leads the rule to fire and \verb|mod2:a| is replaced by \verb|mod2:b|, which leads the rule in line~9 to fire and replaces the local \verb|mod2:b| constraint by an external \verb|mod1:a| constraint. So, external constraints can be called by their complete identifiers.

However, on the left hand side of a rule, only the constraints local to the current module can appear. 

Exported constraints can only appear once in a program, since they can be called without their namespace definition, which is demonstrated in line~8 of listing~\ref{lst:mod1}, where \verb|mod2:c| is called in \verb|mod1| without referring to \verb|mod2| explicitly.
\end{example}

\subsection{Interface for Module Requests}
\label{interface_for_module_requests}

The architecture of ACT-R provides an infrastructure for the procedural module to state requests to all the other modules. To implement this concept as general as possible, an interface has to be defined, which allows the adding of new modules to the system by just implementing this interface.

\begin{lstlisting}[caption={Simple Interface ``Module''},label=lst:interface_module]
module_request(+BufName,+Chunk,-ResChunk,-ResState)
\end{lstlisting}

The arguments of such a request are:

\begin{description}
 \item[BufName] The name of the requested buffer, eg. \verb|retrieval|.
 \item[Chunk] A chunk specification that represents the arguments of the request. The form of the allowed chunk specifications and the semantics of the request are module-dependent. For example: \verb|chunk(_,t,[(foo,bar),(spam,eggs)])| could describe a chunk, that should be retrieved from declarative memory.
\end{description}

The request provides the following result:

\begin{description}
 \item[ResChunk] The resulting chunk in form of a chunk specification. The actual result and its semantics depend on the particular module.
 \item[ResState] The state of the buffer after the request. For example, if no matching chunk could be retrieved from declarative memory, the state would be \verb|error|.
\end{description}

This interface will be extended later on.

\subsection{How the Buffer System States a Request}
\label{how_the_buffer_system_states_a_request}

Every module that can handle a request implements the interface in listing~\ref{lst:interface_module}. When the buffer system gets a call \verb|buffer_request(buffer,chunk-specification)|, it simply can call the \verb|module_request| method of the corresponding module. This can be achieved by \verb|ModName:module_request(...)|, where \verb|ModName| is the name of the corresponding module.

Hence, the buffer system must now, which buffer belongs to which module. The \verb|buffer/2| constraint therefore has to be extended to a \verb|buffer/3| constraint, that also holds the module name of its module:

\begin{lstlisting}
buffer(BufName,ModName,Chunk)
\end{lstlisting}

A buffer request can now be handled as follows:

\begin{lstlisting}
buffer(BufName, ModName, _), buffer_request(BufName, Chunk) <=>
  set_buffer_state(BufName,busy),
  buffer_clear(BufName), % clear buffer immediately
  ModName:module_request(BufName, Chunk, ResChunk,ResState),
(ResState=error, 
  buffer(BufName, ModName, nil),
  set_buffer_state(BufName,error) ;
  
  ResState = free,
  ResChunk = chunk(ResChunkName,_,_),
  add_chunk(ResChunk), 
  buffer(BufName, ModName, ResChunkName),
  set_buffer_state(BufName,free)).
\end{lstlisting}

When getting a buffer request, the buffer state is set to \verb|busy| first. Then the buffer is cleared immediately, which leads the chunk in the buffer being added to the declarative memory. Then the module request is stated according to the interface. If the resulting state is \verb|error|, then the buffer gets this state and the content of the buffer is \verb|nil|, otherwise, if the resulting state is \verb|free|, the result will be added to the buffer and the state will eventually be set to \verb|free|. 

\subsection{Components of the Implementation}

uml component diagram + discussion



\section{Declarative Module}

The Declarative Module is a \emph{chunk store}, that additionally implements the \emph{module} interface. Therefore some rules to handle requests that find certain chunks in the chunk store have to be implemented. 

\subsection{Global Method for Adding Chunks}
\label{global_method_for_adding_chunks}

Since the declarative module is very important to the whole theory it kind of is a special module. Therefore, its Prolog module exports a predicate \verb|add_dm| that is just a wrapper for its chunk store. Hence, with the command \verb|add_dm| chunks can be added to the chunk store of the declarative module from every part of the program. This is eg. used for the clearing of buffers in the buffer system, where the chunk of a buffer goes to the declarative memory when the buffer is cleared. This is the implementation of the command:

\begin{lstlisting}
add_dm(ChunkDef) <=> add_chunk(ChunkDef).
\end{lstlisting}



\subsection{Retrieval Requests}
\label{retrieval_requests}

A retrieval request gets an incomplete chunk specification as input and returns a chunk, whose slots match the provided chunk pattern.

\subsubsection{Chunk Patterns}

The chunk patterns are transmitted in form of chunk specifications as defined in section~\ref{chunk_specification}. Since those specifications may be incomplete, variables are considered as place-holders for values in the result. The result always is a complete and ground chunk specification, because every chunk in a chunk store has to be defined completely; empty slots are indicated by the value nil.

\begin{example}
In this example some possible requests are discussed.

\begin{enumerate}
 \item Request:
\begin{lstlisting}
chunk(foo,bar,_)        
\end{lstlisting}

A chunk with name \verb|foo|, type \verb|bar| and arbitrary slot values is requested.

 \item Request:
\begin{lstlisting}
chunk(_,bar,_)        
\end{lstlisting}

This request is satisfied by every chunk of type \verb|bar|.

 \item Request:
\begin{lstlisting}
chunk(_,t,[(foo,bar),(spam,eggs)])        
\end{lstlisting}

The most common case of requests is a specification of the type and a (possibly incomplete) number of slot-value pairs for that type. If a type does not provide a specified slot, the request is invalid and no chunk will be returned.

\end{enumerate}

\end{example}

\subsubsection{Finding Chunks}

In this section, a CHR constraint \verb|find_chunk/3| will be defined, that produces a \verb|match_set/1| constraint for each chunk that matches a specified pattern. Eventually, the match set will be collected and returned.

\begin{lstlisting}
find_chunk(N1,T1,Ss), chunk(N2,T2) ==> 
  unifiable((N1,T1),(N2,T2),_), 
  nonvar(Ss) | 
  test_slots(N2,Ss), 
  match_set([N2]).
  
find_chunk(N1,T1,Ss), chunk(N2,T2) ==> 
  unifiable((N1,T1),(N2,T2),_), 
  var(Ss) | 
  test_slots(N2,[]), 
  match_set([N2]).

find_chunk(_,_,_) <=> true.
\end{lstlisting}

First, for each chunk in the store, whose name and type is unifiable with the specified name and type, will be part of the initial match set. If in the chunk specification the name and type are variables, each chunk will match. For the unification test, the \verb|unifiable/3| predicate of Prolog is used, because the unification should not be performed but only tested. 

If name and type match the pattern, then the slots have to be tested.

The rule in line~7 is for chunk specifications that do not specify the slots. In this case, no slots have to be tested. If all chunks have been tested or no chunk matches at all, the process is finished (rule in line ~13).

After adding each matching candidate to the match set, whose name and type have already been checked, the match set is pruned from chunks that have non-matching slot values:

\begin{lstlisting}
test_slots(_,[]) <=> true.

chunk_has_slot(N,S,V1), match_set([N]) 
\ test_slots(N,[(S,V2)|Ss]) <=> 
  unifiable(V1,V2,_) | 
  test_slots(N,Ss).

chunk_has_slot(N,S,V1) 
\ test_slots(N,[(S,V2)|_]), match_set([N]) <=> 
    \+unifiable(V1,V2,_) | 
    true.

test_slots(N,_) \ match_set([N]) <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more and the test is finished and has been successful.

In line~3, the rule applies, if there is at least one slot \verb|(S,V2)| that has to be tested and a $HasSlot$ relation of the kind \verb|N| $\xrightarrow[]{\mathtt{S}}$ \verb|V1| with the slot \verb|S| to be tested, that is still in the match set, so no conflicting slot has been found yet. If the values \verb|V1| and \verb|V2| are unifiable, ie. the both are the same constant or at least one is a variable, then the test passes and the chunk \verb|N| remains in the match set and the rest of the slot tests are performed.

The second rule in line~8 applied if the guard of the first rule did not hold, so the values \verb|V1| and \verb|V2| are not unifiable, but there is a connection \verb|N| $\xrightarrow[]{\mathtt{S}}$ \verb|V1| and in the request it has been specified that the value of slot \verb|S| has to be \verb|V2|. In this case, \verb|V1| $\neq$ \verb|V2|, so the test fails and the chunk \verb|N| has to be removed from the match set, since one of its slots does not match.

If the last two rules cannot be applied, the chunk does not provide a slot that, however, has been specified in the request. Hence, the chunk does not match and the last rule therefore deletes it from the match set. \FIXME{make simpagation rule to simplification rule?}

If those rules have been applied exhaustively, only the matching chunks will remain in the match set: If there would be an outstanding slot test, one of the rules would be applicable and the chunk would be removed from the match set, if the test fails (and the test would also be removed, because it has been performed). If the test is successful, the chunk will remain part of the match set, but the test will be removed. So the match set is correct and complete.

However, since the match set is distributed over a set of \verb|match_set| constraints, it would be desirable to collect all those matches in one set. This can be triggered by a \verb|collect_matches/1| constraint, that gets the complete match set in its arguments:

\begin{lstlisting}
collect_matches(_) \ match_set(L1), match_set(L2) <=> 
  append(L1,L2,L), 
  match_set(L).
  
collect_matches(Res), match_set(L) <=> Res=L.

collect_matches(Res) <=> Res=[].
\end{lstlisting}

The first rule merges two match sets to one singe merge set containing a list with all the chunks of the former sets, if the \verb|collect_matches| trigger is present. 

In the second rule, if no two match sets are in the store, the result of the \verb|collect_matches| operation is the match set. The same applies for the last rule, where no match set is in the store and therefore the result is empty.

Note, that this implies, that the rules have to be applied from top to bottom, left to right\footnote{This is called the refined operational semantics of CHR}.

The symbolic layer does not implement any rule for which chunk will be returned, if there are more than one in the match set. In this implementation, the first chunk in the list is chosen. The module request is now implemented as follows:

\begin{lstlisting}
module_request(retrieval,chunk(Name,Type,Slots),ResChunk,ResState) <=> 
  find_chunk(Name,Type,Slots),
  collect_matches(Res),
  first(Res,Chunk),
  return_chunk(Chunk,ResChunk),
  get_state(ResChunk,ResState).
\end{lstlisting}

where \verb|first(L,E)| gets a list \verb|L| and returns its first element \verb|E| or \verb|nil|, if the list was empty.

With \verb|return_chunk/2| and \verb|get_state/2|, the actual results of the request are computed:

By now, the variable \verb|Chunk| holds the name of the chunk to return, but in the specification of the module request, a complete chunk specification is demanded. \verb|return_chunk/2| is defined as a default method of a chunk store that gets a chunk name as its first argument and returns a chunk specification created from the values in the chunk store as its second argument.

The resulting state of the request is computed as follows: If the result chunk is \verb|nil|, then no chunk was in the match set, so the state of the declarative module will be \verb|error|. In any other case, the state is \verb|free| after the request has been performed.

\subsection{Chunk Merging}

An important technique used in ACT-R's declarative memory module, is the chunk merging: If a chunk enters the chunk store and all of its slots and values are the same as of a chunk already in the store, then those two chunks get merged. The merged chunk can be called with both names.

If a chunk entering the declarative memory has the same name as a chunk in that already is in the store, the new chunk gets a new name and if its slots are the same as the slots of the old chunk, they will be merged and the new name will be deleted.

\begin{lstlisting}
chunk(Name,Type) \ add_chunk(chunk(Name,Type,Slots)) <=>
  Type \== chunk |
  add_chunk(chunk(Name:new,Type,Slots)).

% first check, if identical chunk exists
add_chunk(chunk(C,T,S)) ==> 
  T \== chunk | 
  check_identical_chunks(chunk(C,T,S)).
\end{lstlisting}

The rules are added before the empty slot initialization in listing~\ref{lst:add_chunk_rules}. The first rule handles the case where a chunk with a already allocated name is added to the store. Then it gets a new name (which basically is just the old name extended by \verb|:new|, and tries to add this new chunk to the memory. 

The second rule adds a identity check for each chunk to be added except for primitive elements, since their slots are identical for every name, because every primitive element has no slots. Nevertheless they have to be distinguishable by their names and therefore cannot be merged.

The identity check is implemented as follows:

\begin{lstlisting}
check_identical_chunks(nil) <=> true.

chunk(NameOld,Type), check_identical_chunks(chunk(NameNew,Type,Slots)) ==> 
  check_identical_chunks(chunk(NameNew,Type,Slots),NameOld).
  
check_identical_chunks(_) <=> true.
\end{lstlisting}

The rule in line~3 adds for each identity check and each chunk in the store a pairwise identity check which is performed by the following rules:

\begin{lstlisting}
chunk(NameOld, Type) \ check_identical_chunks(chunk(NameNew,Type,[]),NameOld) <=> 
  identical(NameOld,NameNew).
  
chunk(NameOld, Type), chunk_has_slot(NameOld, S, V) \ check_identical_chunks(chunk(NameNew,Type,[(S,V)|Rest]),NameOld) <=> 
  check_identical_chunks(chunk(NameNew,Type,Rest),NameOld).
  
chunk(NameOld, Type), chunk_has_slot(NameOld, S, VOld) \ check_identical_chunks(chunk(_,Type,[(S,VNew)|_]),NameOld) <=> 
  VOld \== VNew |
  true.
    
remove_duplicates @ identical(N,N) <=> true.

% abort checking for identical chunks if one has been found
cleanup_identical_chunk_check @ identical(NameOld,NameNew) \ check_identical_chunks(chunk(NameNew,_,_),NameOld) <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more. Then the chunks are identical and an \verb|identical/2| constraint is added to the store for those two chunks.

The next rule applies for an identity check for a slot-value pair that is successful, whereas the third rule handles the opposite case and aborts the check for this pair of chunks without adding an \verb|identical| constraint.

In the fourth rule redundant information is removed and the lust rule aborts the identity check as soon as one matching chunk has been found.

Note that this implementation assumes that the chunk specification of the chunk entering the declarative memory is complete. If it is not complete, the correct semantics of the adding is that all unspecified slots are empty so their values equal \verb|nil|. Nevertheless, this implementation would merge the chunk with a chunk that has values in those unspecified slots. This could be improved by completing the chunk specifications before checking for identical chunks in the store.

For the easier use of the identical constraint at other points, transitive identities can be reduced to the only real chunk in the store (the one with the \verb|chunk| constraint):

\begin{lstlisting}
reduce @ chunk(C1,_), identical(C1,C2) \ identical(C2,C3) <=> identical(C1,C3).
\end{lstlisting}

Additionally, the newly created names can be deleted if the chunk was identical to another chunk with a real name, since the new nomenclature was only store internal, so only the original name must be kept:

\begin{lstlisting}
identical(C,C:new) <=> true.
\end{lstlisting}

In the declarative module, the chunk search must be extended to find merged chunks by both names. This can be achieved as follows:

\begin{lstlisting}
identical(C1,C2) \ find_chunk(C2,T2.Ss2)  <=> ground(C2) | find_chunk(C1,T2,Ss2).
\end{lstlisting}

so the chunk search of a chunk that is only a pointer to another chunk can be reduced to the search of this chunk. \FIXME{maybe this can cause problems if a production rule refers to a particular name and gets a chunk with the name of its brother..}

The process of chunk merging is described in \cite[??]{actr_reference}. The treating of identical names is not described there, but has been tested in the original implementation: ACT-R handles those identical names similarly to this approach by adding a sequential number to the identical name. For example, the chunk with name \verb|a| would be called \verb|a-0| if there already was a chunk \verb|a| in the store.

\section{Initialization}
\label{initialization}

In the examples the models had to be run by stating complex queries which create all necessary buffers and add all chunk types and chunks to the declarative memory manually. In the original ACT-R implementation, the command \verb|run| is used to run a model. This behaviour can be transferred to the CHR implementation easily by adding a \verb|run| constraint and a rule for this constraint, that performs all the initialization work.

\FIXME{modify count example from above}

\section{Timing in ACT-R}

So far, the execution order of the production rules has been controlled by the \verb|fire| constraint -- a phase constraint that simulated the occupation of the production system while a rule is executed.

However, certain buffer actions like buffer requests may take some time until they are finished. The procedural system is free to fire the next rule after all actions have been started\footnote{see chapters \ref{serial_parallel_aspects} and \ref{process_of_rule_selection_and_execution}} and the requests are performed in parallel to that.

Additionally, for the simulation it may be interesting to explore how much time certain actions have taken, especially when it comes to the subsymbolic layer.

Those aspects cannot be implemented easily using the current approach with phase constraints. Hence, the idea of introducing a central scheduling unit is a possible solution of those requirements: The unit has a serialized ordered list of events with particular timings. If a new event is scheduled, the time it is executed must be known. The scheduling unit inserts the event at the right position of the list preserving the ordered time condition. Figure~\ref{fig:scheduler} illustrates this approach.

The system just removes such events from the queue and executes them, which leads to new events in the queue. The queue organizes the right order of the events.

With this approach, the simulation of a parallel execution of ACT-R can be achieved: Each buffer action on the RHS of a rule just schedules an event that actually performs the action at a specified time (the current time plus its duration). 

The heart of the scheduler is a \emph{priority queue} which is described in the next section.

\subsection{Priority Queue}

A \emph{priority queue} is an abstract data structure that serves objects by their priority. It provides the following abstract methods:

\begin{description}
 \item[enqueue with priority] An object with a particular priority is inserted to the queue. 
 \item[dequeue highest priority] The object with the highest priority is removed from the queue and returned.
\end{description}

\subsubsection{Objects}

In the implementation of the scheduler, the priority queue contains objects of the form \verb|q(Time,Priority,Event)|. The priority of such a queue object is composed from the \verb|Time| and the \verb|Priority|. The order between the elements is defined as follows:

\begin{definition}[ordered time-priority condition]
\verb|q(T1,P1,E1)| $\prec$ \verb|q(T2,P2,E2)|, if \verb|T1| $<$ \verb|T2|. In the case that \verb|T1 = T2|, then \verb|q(T1,P1,E1)| $\prec$ \verb|q(T2,P2,E2)| if \verb|P1| $>$ \verb|P2|. So, events with smaller times will be returned first. If two events appear at the same time, it is possible to define a priority and the event with the higher priority will be returned first. 
\end{definition}

\subsubsection{Representation of the Queue}

The representation of the priority queue is inspired by \cite[38\psqq]{fru_chr_book_2009}: An order constraint \verb|A --> B| is introduced, which states that \verb|A| will be returned before \verb|B| (or \verb|B| is the direct successor of \verb|A|). The beginning of the queue will be defined by a start symbol \verb|s|, so the first real element is the successor of \verb|s|. A possible queue could be:

\begin{lstlisting}
s         --> q(1,0,e1)
q(1,0,e1) --> q(3,7,e2)
q(3,7,e2) --> q(3,2,e3)
\end{lstlisting}

This queue achieves the ordered time-priority condition, since the queue objects are in the correct order according to their times and priorities. It is also consistent in a sense that it has no gaps and no object has more than one successor.

In general, there can be defined some rules to make such a queue consistent, ie. every object only has one successor and the queue achieves the time-priority condition:

\begin{lstlisting}
A --> A <=> true.

_ --> s <=> false.

A --> B, A --> C <=>
  leq(B,C) |
  A --> B,
  B --> C.
\end{lstlisting}

The first rule states, that if an object is its own successor, this information can be deleted. The second rule states, that nothing can be the predecessor of the start symbol. The last rule is the most important one: If one object has two successors, then these connections have to be divided into two connections according to the defined time-priority condition. This condition can be implemented as follows:

\begin{lstlisting}
leq(s,_).

% Time1 < Time2 -> event with time1 first, priority does not matter
leq(q(Time1,_,_), q(Time2,_,_)) :- 
  Time1 < Time2.

% same time: event with higher priority first
leq(q(Time,Priority1,_), q(Time,Priority2,_)) :- 
  Priority1 >= Priority2.
\end{lstlisting}

The first predicate states that the start symbol is is less than every other object. The other two rules implement the time-priority condition directly.

Note that two objects are considered the same, iff. their time, priority and event are syntactically the same. If an object is altered in one of the \verb|-->| constraints, it has to be edited in every other occurrence in the   list to avoid gaps.

Another important property is, that the list does not have any gaps, so it must be possible to track the queue from every element backwards to the start symbol. This condition is not achieved by the rules above, but since a priority queue only offers two mechanisms to modify it, a lot of those problems can be avoided:

\begin{description}
 \item[add\_q(Time,Priority,Event)] Enqueues an object with the specified properties. Ie., a new \verb|q(Time,Priority,Event)| object will be created and the following constraint will be added: \verb|s --> q(Time,Priority,Event)|. The rules presented above will lead to a linear, serialized list achieving the time-priority condition without gaps.
\begin{lstlisting}
add_q(Time,Priority,Evt) <=>
  s --> q(Time,Priority,Evt).
\end{lstlisting}
 \item[de\_q(X)] Dequeues the first element of the queue according to the time-priority condition and binds its value to \verb|X|.
\begin{lstlisting}
de_q(X), s --> A, A --> B <=>
  X = A,
  s --> B.

de_q(X), s --> A <=>
  X = A.  
  
de_q(X) <=> X = nil.
\end{lstlisting}

The first object just is the successor of \verb|s|, since the list has been constructed preserving the correct order and the property, that everything starts at \verb|s|. If the first object has a successor, this object is the new first object. If there are no order constraints left, the queue is empty and \verb|de_q| returns \verb|nil|.

\end{description}

\subsubsection{Special Operation for ACT-R}

In this implementation, another default method is added to the priority queue: 

\begin{description}
 \item[after\_next\_event(E)] Adds the event \verb|E| to the queue, after the first event without destroying the consistency and the time-priority condition of the queue.
\end{description}

To implement this method, the time and priorities have to be set such that the time-priority condition does hold:

\begin{lstlisting}
s --> q(Time,P1,E1) \ after_next_event(Evt) <=> 
  NP1 is P1 + 2, % increase priority of first event, so it still has highest priority
  P is P1 + 1, % priority of event that is added, ensured that it is higher than of the former second event (because it is P1+1)
  de_q(_), % remove head of queue
  add_q(Time,NP1,E1), % add head of queue again with new priority. Will be first again, because it has old prio (which is higher than prio of all successors)
  add_q(Time,P,Evt). % add new event. Will be < than Prio of head but it is ensured that it is higher than prio of second event
\end{lstlisting}

If the first event is \verb|q(Time,P1,E1)| and a new event \verb|Evt| has to be added after this event, the times of the two events are the same, the priority of the first event is \verb|P1 + 2| and the priority of the new event is \verb|P1 + 1|. The first event is removed from the queue and would be added with its new priority to the queue again, as it is with the new event. 

This is correct: The first event will be the first event again, because its old priority was higher than any other priority at that time point and since the new priority is even higher than that, no other event from the queue will have a higher priority. The new event also has a higher priority than every other event in the queue, but a lower priority than the first event, so it will be added after the first event.

By the \verb|de_q| and \verb|add_q| actions it is ensured, that no garbage of the old event remains in the queue and the events are added correctly through a official method of the queue.

\subsection{Scheduler}

The scheduler component is a own module that manages events by feeding a priority queue and controls the recognize-act cycle. It also holds the current time of the system. 

\subsubsection{Current Time}

The current time can be saved in a \verb|now/1| constraint. It is important that there is only one such constraint and that time increases monotonically.

Other modules can access the time only by a \verb|get_now/1| that only returns the current time saved in the \verb|now/1| constraint. The current time cannot be set from outside, but is determined by the last event dequeued from the priority queue.

\subsubsection{Recognize-Act Cycle}

As described before, the procedural module can only fire one rule at a time. When executing the RHS of a rule, all its actions are added to the scheduler with the time point when their execution is finished. For example: If on the RHS of the firing rule a retrieval request has to be performed, an event will be added to the priority queue with the time $Now + Duration$, so the chunk retrieved from the declarative memory will be written to the retrieval buffer at this time point.

After all events of the RHS have been added to the scheduler, the procedural module is free again and therefore the next rule can fire. The event of firing will be added to the priority queue as well by the \verb|fire| constraint at the end of each production rule. The rule will be added at the current time point, but with low priority, since it has to be ensured, that every action of the previously executed rule has been performed yet (in the sense that a corresponding event has been added at the specified time point). In many cases, no other rule will be applicable at this time, because most of the meaningful production rules have to wait for the results of the production rule before. 

Many of the buffer actions are performed immediately, so an event with the current time point is added for the buffer modifications or clearings. They are performed in a certain order defined by their priority as shown in table~\ref{tab:action_priorities}. The request actions are performed at last, but they perform a buffer clearing immediately and then start their calculation which can take some time. 

If no rule is applicable, the next time that a rule could be applicable is after having performed the next event. So, the next \verb|fire| event is scheduled directly after the first event in the queue. This simulates the behaviour that the procedural module stays ready to fire the next rule, without polling at every time point if a rule is applicable, but only reacting on changes to the buffer system. 


The following enumeration summarizes the recognize-act cycle with a scheduler:

\begin{enumerate}
 \item The next event is removed from the queue, the current time is set to the time of the event and the event is performed.
 \begin{enumerate}
 \item The dequeued event is a \verb|fire| constraint: The rule that matches all its conditions is fired and removes the \verb|fire| constraint.
 \item The actions of the rule are scheduled in the queue. Modifications and Clearings have the current time point, requests have a time point in the future depending on the module.
 \item The last action of the rule is to add a \verb|fire| constraint to the queue with the current time point and a low priority. This simulates that the procedural module is free again, after all in-place actions of a rule have been fired.
 \item There are two possibilities:
 \begin{enumerate}
  \item \emph{The next rule matches:} It will be performed like the last rule.
  \item \emph{No rule matches:} The next time, it could be possible that a rule can fire, is when something in the buffers changed. This only can happen, after the next event has been performed. So the next \verb|fire| event will be added to the queue by \verb|after_next_event| which has been described above.
 \end{enumerate}
  \end{enumerate}
 \item Go to point 1. This is performed until there are no events in the queue.
\end{enumerate}


The following parts are necessary to implement this cycle:

\paragraph{Start Next Cycle} 

The constraint \verb|nextcyc| leads the system to remove the next event from queue and perform it. Performing is done by a \verb|call_event| constraint:

\begin{lstlisting}
% After an event has been performed, nextcyc is triggered. 
%This leads to the next event in the queue to be performed.
nextcyc <=> de_q(Evt), call_event(Evt).
\end{lstlisting}

\paragraph{Call an Event} 

Event calling just takes a queue element and sets the current time to the time of the event and performs a Prolog \verb|call|. Additionally, a message is printed to the screen. After the event has been executed, the next cycle is initiated.

If the queue element is \verb|nil| (so no event has been in the queue), the computation is finished and the current time is removed.

\begin{lstlisting}
% no event in queue -> do nothing and remove current time
call_event(nil) \ now(_) <=> write('No more events in queue. End of computation.'),nl.

call_event(q(Time,Priority,Evt)), now(Now) <=> 
  Now =< Time | 
  now(Time),
  write(Now:Priority),
  write(' ... '),write('calling event: '), write(Evt),nl,
  call(Evt),
  nextcyc.
\end{lstlisting}

\paragraph{Changing the Buffer System}

For each buffer action, add a \verb|do_buffer_action| constraint, that actually performs the code specified in the former action. Modify the action as follows:

\begin{lstlisting}
% Schedule buffer_action
buffer_action(BufName, Chunk) <=> 
  get_now(Now),
  Time is Now + Duration, 
  add_q(Time, Priority, do_buffer_action(BufName, Chunk)). 
\end{lstlisting}

with appropriate values for \verb|Duration| and \verb|Priority|.

\paragraph{Production Rules}

As in the last version of the production system, each rule has the following structure:

\begin{lstlisting}
rule @
  {conditions} \ fire <=> {actions}, schedule_fire.
\end{lstlisting}

where schedule fire is defined as:

\begin{lstlisting}
schedule_fire <=> 
  get_now(Now),
  add_q(Now,0,fire).
\end{lstlisting}

As the last production rule, there has to be:

\begin{lstlisting}
no-rule @ 
  fire <=> no_rule.
\end{lstlisting}

which removes the fire constraint if still present and states that no rule has been fired (since the fire constraint is still present). In this case, a new \verb|fire| event is scheduled after the next event:

\begin{lstlisting}
no_rule <=> 
  write('No rule matches -> Schedule next conflict resolution event'),nl,
  after_next_event(do_conflict_resolution).
\end{lstlisting}

\section{Configuration}


\section{Subsymbolic Layer}

\subsection{Activation of Chunks}

\subsection{Production Utility}

