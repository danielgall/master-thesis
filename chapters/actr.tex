\chapter{Description of ACT-R}
\label{actr_description}

Adaptive Control of Thought-Rational  (ACT-R) is a cognitive architecture, that allows to implement cognitive models that are executable by a computer to produce experimental results that can be compared to experimental data from experiments that have been conducted with humans.

Because of the underlying theory which is the basis for the ACT-R cognitive architecture, modeling is facilitated, since the underlying concepts have not to be modelled again and again. On the other hand, it constrains the modeling process to, ideally, only plausible models.

When talking about ACT-R, one can refer to the theory or the implementation. The theory gives a view which abstracts from implementational details that may be concerned when talking about implementation \FIXME{source}. In this work, implementation always refers to the vanilla Lisp implementation that can be downloaded from \cite{actr_homepage}.

In this chapter, a short overview over the theory of ACT-R is given. First, the description is informal to provide a general image of how ACT-R works. Then, some important parts of the system are defined more formally in chapter \ref{implementation}, as soon as it is needed in the implementation. All of the information in this chapter refers to the theory. Implementation is discussed in chapter \ref{implementation}. A lot of the information in this chapter is based on \cite{anderson_how_2007, anderson_integrated_2004, taatgen_modeling_2006}, where a much more comprehensive discussion of the ACT-R theory including complex examples, referrings to the neuro-biology and the reasons why this particular modeling of human cognition has been chosen. In this work, only the basic concepts of ACT-R are presented.

\section{Procedural and Declarative Knowledge}

A central idea of ACT-R is the distinction between \emph{declarative} and \emph{procedural knowledge.} The declarative knowledge consists of simple facts, whereas the procedural knowledge contains information on what to do with those facts.

\subsection{Modular organization}

This approach leads to a modular organization of ACT-R with modules for each purpose needed to simulate human cognition. Figure \ref{fig:modular_organization} provides an overview of some of the default modules of ACT-R. For example, the declarative module stores the factual information (the declarative knowledge), the visual module perceives and processes the visual field, the procedural module holds the procedural information and controls the computational process. 

Each module is independent from the other modules and computations in the modules can be performed parallel to other modules, for instance: The declarative module can search a specific fact while the visual module processes the visual field. Additionally, within one module computations are executed massively parallel, e.g., the visual module can process the entire visual field at once to determine the location of a certain object, which implies the processing of a huge amount of data at a time.

However, each module can perform its computation only locally and has no access to computations of other modules. To communicate, modules have associated \emph{buffers}, where they can put a limited amount of information -- one primitive knowledge element -- and the procedural module can access each of these buffers. The information in a buffer could be one single fact retrieved from declarative memory or one visual object from the visual field perceived by the visual module. Information between modules is exchanged by the procedural module taking information from one buffer and putting it into another (with an optional computation on the way). This leads to a serial bottleneck in the computation, since every communication between modules has to go its way through the procedural module.

In figure \ref{fig:recognize_act} the general computational process is illustrated by showing the \emph{recognize-act-cycle}: The procedural information is stored as rules that have a \emph{condition} and an \emph{action}. The condition refers to the so-called \emph{working memory}, which basically is the content of all the buffers. In the recognize-phase of the cycle, a suitable rule that matches the current state of the working memory is searched. If the condition of a rule holds, it \emph{fires} and performs its actions -- this is the act-phase of the cycle. Those actions can cause changes on the buffers, so the next rule may match the current state in the next recognize-part of the cycle. In the following sections, some of the modules and their precise interaction will be described in more detail.

\subsection{Declarative Knowledge}

The declarative module organizes the factual knowledge as an associative memory. I.e., it consists of a set of concepts that are connected to each other in a certain way. Such elementary concepts are represented in form of chunks that can be seen as basic knowledge elements. They can have names, but those names are not critical for the description of the facts and just for readability in the theory. So, the definition of a chunk is based only on its connections. 

Chunks can have slots that are connected to other chunks or elements. Such an element can be regarded as a chunk without any slots. For instance, the fact $5 + 2 = 7$ can be modeled as a chunk that is connected to the numbers 5, 2 and 7 (see figure \ref{fig:chunk_addition_fact}). Notice that in the figure each slot has an individual name. This is necessary to distinguish the connections of the chunks, otherwise the summands would be indistinguishable from the sum in the example.

Thus, chunks are defined by their name and the values of their slots. When talking about chunk descriptions, often the term \emph{slot-value pairs} is used especially for partial chunk descriptions, i.e. descriptions which do not have a value for all possible slots. This simply refers to an arbitrary chunk that has the specified values in its slots (and the others are ignored).

Each chunk is associated with a chunk-type that determines the slots a chunk can have. For example, the fact in figure \ref{fig:chunk_addition_fact} has the type \verb|addition-fact|. All chunks of this type must provide the slots \verb|arg1|, \verb|arg2| and \verb|sum|.

\label{millers_number}
For the chunk-types there is no upper limit of slots they can define. However, it is suggested to limit the number of slots to Miller's Number of $7 \pm 2$, for the reason of plausibility \cite[230]{stewart_deconstructing_2007}. 

\subsubsection{Buffers}

As mentioned before, modules communicate through buffers by putting a limited amount of information into their associated buffers. More precisely, each buffer can hold only \emph{one chunk at a time}.

For example, the declarative module has the retrieval buffer associated with it, which can hold one specific declarative chunk. The declarative module can put chunks into the buffer that can be processed by the procedural module, which is described in the next section.

\subsection{Procedural Knowledge}
\label{procedural_knowledge}

Procedural Knowledge in ACT-R is formulated as a set of condition-action rules. Each rule defines in its condition-part the circumstances under which it can be applied. Those conditions refer to the current chunks in the respective buffer. The condition-part of a rule defines which kind of chunk with which slot values must be present in which buffer for the rule to fire. For example, one rule in the process of adding the numbers 5 and 2 could have the conditions that there is a chunk of type \verb|addition-fact| in the retrieval buffer with 5 and 2 in its argument-slots and specify certain actions if this is the case.

If the chunks in the buffers match all the conditions stated in a rule, it can be applied (``fired''), which leads its action-part to be performed. Possible actions are changes of some of the values in the chunk of a buffer, the clearing of a buffer or a buffer request, which leads the corresponding module to put a certain chunk into the requested buffer. Buffer requests are also stated in form of a (partial) chunk description\footnote{A partial chunk description is just a chunk description that does not specify all slots that are available as defined in the chunk-type.} where chunk-type and slots encode the query of the request. So all the arguments and even the task which should be performed by the module are specified through a chunk representation. The actual semantics of a request depends on the module. For example, the declarative module will search a chunk that matches the chunk in the description of the request. One production rule, for instance, in the process of adding the numbers 5 and 2 could be, if the wrong \verb|addition-fact| chunk is stored in the retrieval buffer, a retrieval request will be performed, which states that the declarative module should put a chunk into the retrieval buffer, that has 5 and 2 in its argument slots and is of type \verb|addition-fact|. After the successful performance of the request, a chunk with 5 and 2 in its argument slots will be stored in the retrieval buffer, that also has a value for the sum. The actions are described in more detail in the following section.

Although the term \emph{module} is used for the procedural system, it differs a lot from the other modules: In contrast to other modules, the procedural module has no own buffers, but can access the buffers of all the other modules. ``It really is just a system of mapping cortical buffers to other cortical buffers'' \cite[p. 54]{anderson_how_2007}.

The procedural system can only fire one rule at once and it takes 50\,ms for a rule to fire \cite[p. 54]{anderson_how_2007}. After firing the selected rule, the next recognize cycle starts and a suitable rule will be detected and caused to fire. During this time, other modules may perform requests triggered by the action of the last rule. Sometimes, rules have to wait for results of certain modules and they cannot fire before those results are available. Those two facts illustrate how the procedural module can become a serial bottleneck in the computation process.

\subsubsection{Description of Procedural Actions}
\label{description_of_proc_actions}

In this section, the actions that can be performed by a production rule are described in more detail than before. The information in this section has been taken from \FIXME{source} and is -- in this degree of detail -- not part of the theory, but focuses more on the implementation to give a more detailed understanding of the concepts needed in chapter~\ref{implementation}.

\begin{description}
 \item[Buffer Modification:] 
 
 An in-place operation, that overwrites the slot values of a chunk in a buffer with the specified values in the action of the rule.
 
 \item[Buffer Request:] 
 
 A buffer request will cause the corresponding module to calculate some kind of result that will be placed into the requested buffer. The input values of this computation are given as chunks with a type and slot-value pairs specified in the request. For instance, the declarative module could search for a chunk that has the specified values in its slots.
 
 The execution of the request is independent from the execution of production rules and after the request has been stated by the procedural module, it can begin with the next recognize-cycle while the requested module calculates its result.
 
 Before the request is performed, the corresponding buffer will be cleared.
 
 \item[Buffer Clearing:] 
 
 If a buffer is cleared, its containing chunk will be placed into the declarative memory from where it can be retrieved later on. The clearing of a buffer with the implicit storing of the chunk in the declarative memory is an implementational detail which is very important for further considerations.
\end{description}

\subsubsection{Chunks as Central Data Structure}

As may have become obvious in the previous sections, chunks are the central data structures in ACT-R. They are used to model factual knowledge in the declarative memory, but are also used for communication: Requests are stated as chunks that encode the input of the request, for instance a chunk pattern for a result chunk the declarative memory should retrieve. The result of a request is a chunk placed into a buffer and even the procedural system, which technically is separated from the declarative knowledge, tries to match the chunks in the buffers in the condition part. Additionally, the action of a rule is specified by slot-value pairs that are basically just partial chunk descriptions. 

\subsubsection{Process of Rule Selection and Execution}
\label{process_of_rule_selection_and_execution}

\FIXME{add sources}

As stated above, the procedural module can execute only one rule at a time. If no rule has been selected to fire -- so no rule is in progress -- the procedural module is \emph{free} and therefore can select a matching rule according to the recognize-act-cycle. If a rule has been selected, the module is \emph{busy} and cannot choose another rule to fire. Between selection and firing of a rule the module has to wait $50\,\mathrm{ms}$. Then all in-place actions of the rule like modifying or clearing a buffer are performed. Afterwards, the requests are stated and the module is free. However, the requested modules most likely will take a certain time to perform the request. During this time the procedural module can select and fire the next matching rule nevertheless.

If at a certain time the procedural module is free, but there are no matching rules, the module waits until the system reaches a state where a rule matches. This is possible, since requests can take a certain time in which the procedural module is free and cannot find a matching rule. If the request has been performed, it usually causes a change of buffers. When the content of a buffer has changed, this could provoke the next rule to match and fire.

\subsection{Goal Module}

An essential part of human cognition is the ability to keep track of the current goal to achieve and to subordinate all actions to the goal \cite[p. 1041]{anderson_integrated_2004}. For complex cognitive tasks, several rules have to be applied in series and intermediate results must be stored (without changing of the environment). Another important aspect is that complex tasks may consist of several subgoals which have to be achieved to accomplish the main goal. For instance, if one wants to add two multi-digit numbers, he would add the columns and remember the results as intermediate results in each step. In ACT-R, the goal module with its goal buffer is used for this purpose: It is able to keep track of the current goal, introduce subgoals and remember intermediate results in its buffer. 

\subsubsection{Working memory}

The goal module and buffer are often referred to as \emph{working memory} \cite[1041]{anderson_integrated_2004}, but actually, as stated in \cite{anderson_working_1996}, it also can have another meaning: The usual definition in production systems is that everything which is present to the production rules and can match against them is part of the working memory. With this definition, all chunks in the buffers form the working memory.

In this work, the term \emph{working memory} will be used in this second meaning, since it discusses the topic from a computer science view and the second definition is related to production rule systems. When talking about the content of the goal buffer, this will be remarked explicitly.

\subsection{Other Modules}

In figure \ref{fig:modular_organization} some more modules are shown. In the following, a short description of some of those modules is given.

\subsubsection{The Outside World}

Since human cognition is embodied, there must be a way to interact with the outside world to simulate human cognition in realistic experiments. Therefore, ACT-R offers \emph{perceptual/motor modules} like the manual module for control of the hands, the visual module for perceiving and processing the visual field or the aural module to perceive sounds in the environment. Like with every other module, communication is achieved through the buffers of those modules. In the following, the visual module is described to exemplify the functionality of perceptual modules.

\paragraph{The Visual Module} The visual system of ACT-R separates vision into two parts: visual location and visual objects \cite[p. 1039]{anderson_integrated_2004}. There are two buffers for those purposes: the \emph{visual-location} buffer and the \emph{visual} buffer, which represents the visual objects \cite[unit~2]{actr_tutorial}. In the visual module it is not encoded how the light falls on the retina, but a more attentional approach has been chosen \cite[p. 1039]{anderson_integrated_2004}. 

Requests to the \emph{visual-location buffer} specify a series of constraints in form of slot-value pairs and the visual module puts a chunk representing the location of an object meeting those constraints into the visual-location buffer. Possible constraints are properties of objects like the color or the spatial location. The visual system can process such requests in parallel, i.e. that the whole visual field is processed massively parallel and, for example, the time of finding one green object surrounded by blue objects is constant, regardless of the number of blue objects. If more than one object meets the constraints, one of them will be chosen at random \cites[1039]{anderson_integrated_2004}[68]{anderson_how_2007}.

Requests to the \emph{visual-object system} specify a visual location and the visual module will move its attention to that location, create a new chunk representing the object at that location and put that chunk into the visual buffer \cite[unit 2, chapter 2.5.3]{actr_tutorial}. 

These two kinds of requests to the visual module are summarized in table~\ref{tab:visual_module_requests}.

\begin{table}[hbt]
\caption{Requests to the visual module}
\label{tab:visual_module_requests}
\begin{center}
\begin{tabular}{|l|ll|}
\hline
 & Visual location buffer & Visual (object) buffer\\
\hline
Input & Object Constraints & Visual location\\
Output & Visual location & Visual object\\
\hline
\end{tabular}
\end{center}
\end{table}

The visual system and its capabilities are described in detail in \cite[unit 2]{actr_tutorial} where also the implementational details of the system are regarded.

\subsubsection{The Imaginal Module}

The imaginal module is capable of creating new chunks. This is useful, if for instance the visual module produces a lot of new information in sequence (like reading a sequence of letters), but the visual-object buffer can hold only one chunk at once. To solve this problem, all the information could be stored in the slots of the goal chunk. However, since a goal chunk with a large amount of slots seems to be unplausible\footnote{As described in section \ref{millers_number}, one should stick to $7 \pm 2$ slots for each chunk.} and the number of read instances would have to be known in advance due to the static chunk-type definition, a better way to deal with this problem is to create new knowledge elements.

This task can be achieved by using the imaginal module: On a request, it creates a new chunk of the type and with the slots stated in the request and puts it into its \emph{imaginal buffer}. Since the chunk in a buffer is stored in the declarative memory when the buffer is cleared\footnote{see section \ref{description_of_proc_actions}}, an unlimited amount of data can be produced and remembered by stating retrieval requests later on.

It is important to mention that it takes the imaginal module $.2\,\mathrm{ms}$ to create a chunk. This amount of time is constant, but can be set by the modeler. Additionally, the imaginal module can only produce one chunk at a time\footnote{like every module can only handle one request at a time}.

The imaginal module is described in \cite[unit 2]{actr_tutorial}.

\subsection{Example: Counting}
\label{example_counting}

The first ACT-R example model deals with the process of counting. This model relies on count facts a person has learned, e.g. ``the number after $2$ is $3$''. To model this in ACT-R, a chunk-type for those facts has to be defined: A chunk of type \emph{count-fact} has the slots \emph{first} and \emph{second}. The chunks in figure \ref{fig:example_counting_chunks} of this type model the facts that $3$ is the successor of $2$ and $4$ is the successor of $3$.

The next step is to define the goal chunk stored in the goal buffer. In this chunk it somehow has to be encoded that the current goal is to count. This can be modeled in ACT-R by the chunk-type. To track the current number in the counting process as an intermediate result, the goal chunk could have a slot which always holds the current number that has been counted to. This leads to a goal chunk as illustrated in figure \ref{fig:example_counting_goal_chunk}, where the current number is $2$. In this example we assume that the model starts with this goal chunk in the goal buffer and the first count fact has been retrieved:

\parbox{100mm}{\textbf{goal buffer:} goal-chunk of type count\\
\noindent\hspace*{20mm} current-number $2$}

\parbox{100mm}{\textbf{retrieval buffer:} b of type count-fact\\
\noindent\hspace*{20mm} first $2$\\
\noindent\hspace*{20mm} second $3$}

This notation indicates that the goal buffer holds a chunk with the name \emph{goal-chunk} of the type \emph{count}, which has the slot \emph{current-number} with the value $2$ (the same is valid analogously for the retrieval buffer).

Now the rules to implement counting can be defined as:

\begin{center}
\begin{tikzpicture}[node distance=0.5cm]
\node (count-rule) [rule, rectangle split, rectangle split parts=4, rectangle split part fill={Uulmin, Uulmin!45,Uulmin!45,Uulmin!80,Uulmin!80}] {
        \textbf{count-rule}
        \nodepart{second} IF the goal is to count, the current number is $n$
        \nodepart{third}AND the retrieval buffer holds a chunk of type \emph{count-fact} with the \emph{first} value $n$ and the \emph{second} value $m$
        \nodepart{fourth}THEN set the current number in the goal to $m$
                    AND send a retrieval request for a chunk that has $m$ in its \emph{first} slot
    };
\end{tikzpicture}
\end{center}

The rule matches the initial state: In the goal there is a chunk of type \emph{count}, that indicates that the goal is to count, the current number $n$ is $2$. In the retrieval buffer, there is a \emph{count-fact} with the \emph{first} number $n = 2$ and the \emph{second} number $m = 3$. 

After applying this rule, the current number will be $3$ and the next fact in the retrieval buffer will be a \emph{count-fact} with the \emph{first} value $3$ and a value in the \emph{second} slot, which will be the next number in the counting process. This illustrates the functionality of module requests: In the request a (potentially partial) chunk definition is stated and the corresponding module puts the result of the request in a fully defined chunk of some appropriate type into its buffer. For the declarative module, the request specifies the chunk-type and some slot values which describe the chunk that the module should be looking for. The result is a fully described chunk of that type with values for all slots, that describe an actual chunk from the declarative memory. \FIXME{chunks are copies!! describe somewhere}

The count-rule will be applicable as long as there are \emph{count-facts} in the declarative memory. Figure \ref{fig:example_counting_execution} illustrates the counting process.

In this example, the rules have been defined in a very informal way. In the following chapters which deal with implementation, a formalization of such rules will be discussed, that defines clearly what kinds of rules are allowed. Furthermore, it introduces a formalism to describe such rules uniquely and less verbosely. The following chapters will refer to this example and refine it gradually.

The example also uses the concept of \emph{variables}, which will be introduced more formally in chapter \ref{implementation} when talking about implementation. Variables allow rule conditions to act like patterns that can match various system states instead of defining a rule for each state, since computation is the same regardless of the actual values in the buffers.


\FIXME{figures}


\section{Serial and Parallel Aspects of ACT-R}
\label{serial_parallel_aspects}

In the previous sections there were some remarks on the serial and parallel aspects of ACT-R. According to \cite[p. 68]{anderson_how_2007}, four types of parallelism and seriality can be distinguished:

\begin{description}
 \item[Within-Module Parallelism:] As mentioned above, one module is able to explore a big amount of data in parallel. For example, the visual module can inspect the whole visual field or the declarative module performs a massively parallel search over all chunks.
 \item[Within-Module Seriality:] Since modules have to communicate, they have a limited amount of buffers and each of those buffers can only hold one chunk. For example, the visual module only can concentrate on one single visual object at one visual location, the declarative module only can have one single concept present, the production system can fire only one rule at a time, \dots 
 \item[Between-Module Parallelism:] Modules are independent of each other and their computations can be performed in parallel.
 \item[Between-Module Serialism:] However, if it comes to communication, everything must be exchanged via the procedural module that has access to all the buffers. Sometimes, the production system has to wait for a module to finish, since the next computation relies on this information. So, modules may have to wait for another module to finish its computation before they can start with theirs triggered by a production rule that states a request to those modules.
\end{description}

The procedural module is the central serial bottleneck in the system, since the whole communication between modules is going through the production system and the whole computation process is controlled there. The fact that only one rule can fire at a time leads to a serial overall computation. Another serial aspect is that some computations need to wait for the results of a module request. If no other rule matches in the time while the request is performed, the whole system has to wait for this calculation to finish. After the request, the module puts the result in its buffer and the rule needing the result of the computation can fire and computation is continued.

\section{Subsymbolic layer}
\label{subsymbolic_layer}

The previously discussed aspects of the ACT-R theory are part of the so-called symbolic layer. This layer only describes discrete knowledge structures without dealing with more complex questions like: 

\begin{itemize}
\item How long does it take to retrieve a certain chunk? 
\item Forgetting of chunks
\item If more than one rule matches, which one will be taken?
\end{itemize}

Therefore, ACT-R provides a subsymbolic layer that introduces ``neural-like activation processes that determine the availability of [\dots] symbolic structures'' \cite{anderson_implications_2000}.

\subsection{Activation of Chunks}
\label{activation}

The activation $A_i$ of a chunk $i$ is a numerical value that determines if and how fast a chunk can be retrieved by the declarative module. Suppose there are two chunks that encode addition facts for the same two arguments (let them be 5 and 2), but with different sums (6 and 7), for example. This could be the case, if, e.g., a child learned the wrong fact about the sum of 5 and 2. When stating a module request for an addition fact that encodes the sum of 5 and 2, somehow one of the two chunks has to be chosen by a certain method, since they are both matching the request. This is determined by the activation of the chunks: The chunk with the higher activation will be chosen.

Additionally, a very low chunk activation can prevent a chunk from being retrieved: If the activation $A_i$ is less than a certain \emph{threshold} $\tau$, the chunk $i$ cannot be found.

At last, activation determines also how fast a chunk is being retrieved: The higher the activation, the shorter the retrieval time.

\subsubsection{Base-Level Activation}
\label{base_level_activation}

The activation $A_i$ of a chunk $i$ is defined as:

\begin{equation}
 \label{eq:activation_equation_simpl}
 A_i = B_i + \Gamma
\end{equation}

where $B_i$ is the \emph{base-level activation} of the chunk $i$. $\Gamma$ is a context component that will be described later on. Equation \eqref{eq:activation_equation_simpl} is a simplified variant of the \emph{Activation Equation}.

The base-level activation is a value associated with each chunk and depends on how often a chunk has been practiced and when this practice has been performed. A chunk is \emph{practiced} when it is retrieved. Hence, $B_i$ of chunk $i$ is defined as:

\begin{equation}
\label{eq:base_level_learning}
B_i = \mathrm{ln}\left(\sum_{j=1}^n{t_j^{-d}}\right)
\end{equation}

where $t_j$ is the time since the $j$th practice, $n$ the number of overall practices of the chunk and $d$ is the decay rate that describes how fast the base-level activation decreases if a chunk has not been practiced (how fast a chunk will be forgotten). Usually, $d$ is set to $0.5$ \cite[p. 1042]{anderson_integrated_2004}. Equation \eqref{eq:base_level_learning} is called \emph{Base-Level Learning Equation}, as it defines the adaptive learning process of the base-level value.

This equation is the result of a rational analysis by Anderson and Schooler. It reflects the log odds that a chunk will reappear depending on when it has appeared in the past \cite[33]{taatgen_modeling_2006}. This analysis led to the \emph{power law of practice} \cite[1042]{anderson_integrated_2004}. In \cite[8--11]{anderson_implications_2000} equation \eqref{eq:base_level_learning} is motivated in more detail by describing the power law of learning/practice, the power law of forgetting and the multiplicative effect of practice and retention with some data. Shortly, it states, that if a particular fact is practiced, there is an improvement of performance which corresponds to a power law. At the same time, performance degrades with time corresponding to a power law. Additionally, they state that if a fact has been practiced a lot, it will not be forgotten for a longer time.

\subsubsection{Activation Spreading}

In ACT-R, the basic idea of activation is that it consists of two parts: The base-level component described above, and a context component. Every chunk that is in the current context has a certain amount of activation that can spread over the declarative memory and enhance activation of other chunks that are somehow connected to those chunks in the context. The activation equation \eqref{eq:activation_equation_simpl} is extended as follows:

\begin{equation}
\label{eq:activation_equation}
 A_i = B_i + \sum_{j \in C}{W_j S_{ji}} + \varepsilon
\end{equation}

where $W_j$ the \emph{attentional weighting} of chunk $j$, $S_{ji}$ the \emph{associative strength} from chunk $j$ to chunk $i$ and $C$ is the \emph{current context}\label{current_context}, usually defined as the set of all chunks that are in a buffer \cites[1042]{anderson_integrated_2004}[33]{taatgen_modeling_2006}[unit 5]{actr_tutorial}. $\varepsilon$ is a noise value ``generated according to a logistic distribution'' \cite[unit 4, p. 4]{actr_tutorial}. Figure \ref{fig:chunk_activation} illustrates the addition-fact $5 + 2 = 7$ with the corresponding quantities introduced in the last equation. 

The values for $W_j$ determines how much activation can come from a single source of activation from the current context. A source of activation is a chunk in the goal buffer or in all buffers\footnote{This is called the current context: Usually it means the set of all chunks in all buffers, but there are definitions in literature, that only call the chunk in the goal buffer current context.}, depending on the version of the ACT-R theory \cites[1042]{anderson_integrated_2004}[33]{taatgen_modeling_2006}[unit 5, p. 1]{actr_tutorial}. To limit the total amount of source of activation, $W_j$ is set to $\frac{1}{n}$, where $n$ is the number of sources of activation. With this equation, the total amount of activation that can spread over declarative memory is limited, since the more chunks are in the current context, the less important becomes a particular connection between a chunk from the context with a chunk from declarative memory.

Figure \ref{fig:activation_spreading} illustrates the activation spreading process.

\paragraph{Strength of Association and Fan effect}

In equation \eqref{eq:activation_equation} the strength of association $S_{ji}$ from a chunk $j$ to a chunk $i$ is used to determine the activation of a chunk $i$.  In the ACT-R theory, the value of $S_{ji}$ is determined by the following rule: If chunk $j$ is not a value in the slots of chunk $i$ and $j \neq i$, then $S_{ji}$ is set to 0. Otherwise $S_{ji}$ is set to: 

\begin{equation}
\label{eq:assoc_strength}
S_{ji} = S - \mathrm{ln}(\mathrm{fan}_j)
\end{equation}

where $\mathrm{fan}_j$ is the number of facts associated to term $j$ \cite[1042]{anderson_implications_2000}. In more detail: ``$\mathrm{fan}_j$ is the number of chunks in declarative memory in which $j$ is the value of a slot plus one for chunk $j$ being associated with itself'' \cite[unit 5, p. 2]{actr_tutorial}. Hence, equation \eqref{eq:assoc_strength} states that the associative strength from chunk $j$ to $i$ decreases the more facts are associated to $j$.

This is due to the \emph{fan effect:} The more facts a person studies about a certain concept, the more time he or she needs to retrieve a particular fact of that concept \cite[186]{anderson_fan_1999}. This has been demonstrated in an experiment presented in \cite{anderson_fan_1999}, where every participant studied facts about persons and locations like:

\begin{itemize}
 \item A hippie is in the park.
 \item A hippie is in the church.
 \item A captain is in the bank.
 \item \dots
\end{itemize}

For every person the participants studied either one, two or three facts. Afterwards, they were asked to identify targets, that are sentences they studied, and foils, i.e. sentences constructed from the same persons and locations, but that were not in the original set of sentences. Figure \ref{fig:fan_network} represents an example chunk network of the studied sentences (based on \cite[fig.~1]{anderson_fan_1999}).

``The term \emph{fan} refers to the number of facts associated with a particular concept'' \cite[186]{anderson_fan_1999}. In figure \ref{fig:fans}, some facts are shown with their fan, $S_{ji}$ and $B_i$ values.

The result of the experiment was, that the more facts are associated with a certain concept, the higher was the retrieval time for a particular fact about that concept.

In the ACT-R theory, this result has been integrated in the calculation of the strengths of association: In equation \eqref{eq:assoc_strength} the associative strength decreases with the number of associated elements. The value $S$ is a model-dependent constant, but in many models estimated about 2 \cite[1042]{anderson_integrated_2004}. Modelers should take notice of setting $S$ high enough that all associative strengths in the model are positive \cite[unit 5, p. 3]{actr_tutorial}.

\subsubsection{Latency of Retrieval}

As mentioned before, the activation of a chunk affects if the chunk can be retrieved (depending on a threshold and the activation values of the other matching chunks). In addition, activation also has an effect on the retrieval time of a chunk:

\begin{equation}
\label{eq:retrieval_latency}
T_i = F \cdot \mathrm{e}^{-A_i}
\end{equation}

where $T_i$ is the \emph{latency} of retrieving chunk $i$, $A_i$ the activation of this chunk, as defined in equation \eqref{eq:activation_equation}, and $F$ the \emph{latency factor}, which is usually estimated to be

\begin{equation}
F \approx 0.35\mathrm{e}^\tau
\end{equation}

where $\tau$ is the retrieval threshold as mentioned in section \ref{activation}, but $F$ can also be set individually by the modeller. Nevertheless, in \cite[1042]{anderson_integrated_2004} it is stated that the relationship of the retrieval threshold and the latency factor in equation \eqref{eq:retrieval_latency} seems to be suitable for a lot of models.

\subsection{Production Utility}
\label{production_utility}

For the production system, there is the subsymbolic concept of \emph{production utilities} to deal with competing strategies. For instance, if a child learns to add numbers, it may have learned different strategies to compute the result: One could be counting with the fingers and the other could be just retrieving a fact for the addition from declarative memory. If the child now has the goal to add two numbers, it somehow has to decide which strategy it will choose, since both of them match the context.

In ACT-R, the production utility is a number attached to each production rule in the system. Just like with activation of chunks, the production rule with the highest utility will be chosen, if there is more than one matching rule. The utilities can be set statically by the modeler, but they can also be learned automatically by practice.

In the current version of the ACT-R theory, a reinforcement learning rule based on the Rescorla-Wagner learning rule \cite{rescorla_wagner_1972} has been introduced. The utility $U_i$ of a production rule $i$ is defined as:

\begin{equation}
\label{eq:utility_learning}
U_i(n) = U_i(n - 1) + \alpha \left(R_i(n) - U_i(n - 1)\right)
\end{equation}

where $\alpha$ is the \emph{learning rate} which is usually set around .2 and $R_i(n)$ is the reward the production rule $i$ receives at its $n$\textsuperscript{th} application \cite[160--161]{anderson_how_2007}. This leads the utility of a production rule being gradually adjusted to the average reward the rule receives \cite[6--7]{actr_tutorial}. 

Usually, rewards can occur at every time and it is not clear which production rule will be strengthened by the reward. In \cite[161]{anderson_how_2007} an example is described, where a monkey receives a squirt of juice a second after he presses a button. The question now is, which production rule is rewarded, since between the reward and the firing of a rule there always is a break. In ACT-R, every production that has been fired since the last reward event will be rewarded, but the more time lies between the reward and the firing of the rule, the less is the reward this particular rule receives. The reward for a rule is defined as the amount of external reward minus the the time from the rule to the reward. This implies, that the reward has to be measured in units of time, e.g., how much time is a monkey willing to spend to get a squirt of juice? \cite[161]{anderson_how_2007}

In implementations of ACT-R, rewards can be triggered by the user at any time or can be associated with special production rules that model the successful achievement of a goal (they check, if the current state is a wanted state and then trigger a reward, so every rule that has led to the successful state will be rewarded).

It is important to mention that by the definition of the reward for a production rule, rules also can get a negative reward, if their selection was too long ago. If one wants to penalize all rules since the last reward, a rule that distributes a reward of 0 can be triggered, which leads all rules applied before being rewarded with a negative amount of reward \cite[unit 6, p. 8]{actr_tutorial}.

\section{Learning}

Learning in ACT-R can be divided into four types depending on the involvement of the symbolic or subsymbolic layer and the declarative or the procedural module. Table~\ref{tab:learning_types} names the four types that are described in this section.

\begin{table}[hbt]
\caption{ACT-R's Taxonomy of Learning \cite[92--95]{anderson_how_2007}}
\begin{center}
\begin{tabular}{|l|ll|}
\hline
 & Declarative & Procedural\\
\hline
Symbolic & Fact learning & Skill acquisition\\
Subsymbolic & Strengthening & Conditioning\\
\hline
\end{tabular}
\end{center}
\end{table}


\subsection{Symbolic Layer}

Symbolic learning somehow influences the objects of the symbolic layer, i.e. chunks and production rules, in a way that new objects are created or objects are merged. Those learning possibilities are described in the following.

\subsubsection{Fact Learning}



\subsubsection{Skill acquisition}

\subsection{Subsymbolic Layer}

The concepts introduced in section~\ref{subsymbolic_layer} are a kind of learning: The practice of particular facts strengthens the chunks encoding this fact and chunks that are not practiced are forgotten over time\footnote{This is the concept of base-level learning as described in section~\ref{base_level_activation}}. Additionally, associative weights are learned from the current context. These processes adapt to the problems a particular human mind is confronted with and work autonomously.

The same is valid for production rules: Over time, the experience tells us, which strategies might be successful in certain situations and which are not. This process is also called \emph{conditioning} and described in equation~\eqref{eq:utility_learning}.


\cite[chapter 4]{whitehill_understanding}
\FIXME{mention experiment environment}
