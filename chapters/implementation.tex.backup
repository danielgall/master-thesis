\chapter{Transformation of ACT-R to CHR}

After the comprehensive but at some point informal overview of the ACT-R theory in chapter \ref{actr_description}, this chapter presents a possible implementation of the described concepts of the ACT-R theory in CHR.

For the implementation, some special cases and details that are not exactly defined in theory have to be considered. Hence, some concepts of the theory that are implemented in this work are formalized first. The implementation in form of CHR rules sticks to those formalisms and is often very similar to them.

Additionally, the implementation is described incrementally, ie. first, a very minimal subset of ACT-R is presented that will be refined gradually with the progress of this chapter. In the end, an overview of the actual implementation as a result of this work is given.

Some of the definitions in this chapter result directly from the theory, some of them needed a further analysis of the official ACT-R 6.0 Reference Manual \cite{actr_reference} or the tutorials \cite{actr_tutorial}. 

\section{Declarative and Procedural Knowledge}

The basic idea of the implementation is to represent declarative knowledge, working memory etc. as constraints and to translate the ACT-R production rules to CHR rules. This approach leads to a very compact and direct translation of ACT-R models to Constraint Handling Rules.

In addition to the production rules there will be rules that implement parts of the framework of ACT-R, for example rules that implement basic chunk operations like modifying or deleting chunks from declarative memory or a buffer. Those parts of the system are described as well as the central data structures and the translation.

First, a formalization of declarative knowledge in form of chunk networks and their implementation in CHR is given. Then, the working memory -- also referred to as the buffer system -- is explored and the implementation is discussed. After those definitions of the basic data structures of ACT-R, the procedural system is described including the translation of ACT-R production rules to CHR rules using the previously defined data structures.

Furthermore, the reproduction of ACT-Rs modular architecture is shown and the implementation of the declarative module is presented.

After this overview of the basic concepts of ACT-R, the description goes into more detail about timing issues and the subsymbolic layer.

\section{Chunk Stores}

Since chunks are the central data-structure of ACT-R used for representation of declarative knowledge and to exchange information between modules and to state requests, this section first deals with this central part of ACT-R.

\subsection{Formal Representation of Chunks}

In multiple parts of ACT-R it is necessary to store chunks and then operate on then. Hence, the abstract data structure of such a chunk store is defined.

Since chunk stores have been referred to as networks in the previous chapters, the general idea of this definition of a chunk store bases upon a relation that represents such a network.

\begin{definition}[chunk-store]
A \emph{chunk-store} $\Sigma$ is a tuple $(C,E,\mathcal{T},HasSlot,Isa)$, where $C$ is a set of chunks and $E$ a set of primitive elements, with $C \cap E = \emptyset$. $V = C \cup E$ are the \emph{values} of~$\Sigma$ and $\mathcal{T}$ a set of chunk-types. A chunk-type $(T,S) \in \mathcal{T}$ is a tuple with a type name $T$ and a set of slots $S$. The set of all slot-names is $\mathcal{S}$. 

$HasSlot \subseteq C \times \mathcal{S} \times V$ and $Isa \subseteq C \times T$ are relations and are defined as follows:

\begin{itemize}
 \item $c \enspace Isa \enspace T \Leftrightarrow$ chunk $c$ is of type $T$.
 \item $(c,s,v) \in HasSlot \Leftrightarrow v$ is the value of slot $s$ of $c$. This can also be written as $c \overset{s}{\longrightarrow} v$ and is spoken ``$c$ is connected to $v$'' or ``$v$ is in the slot $s$ of $c$''.
\end{itemize}


The function $slots: C \rightarrow \mathcal{S} \times V$ is defined as $slots(c) = \{ (s,v) | (c,s,v) \in HasSlot \}$ and $slots: \mathcal{T} \rightarrow \mathcal{S}$ as $slots((T,S)) = S$.

A chunk-store is \emph{type-consistent}, if $\forall(c,s,v) \in HasSlot: c \enspace Isa \enspace (T,S) \Rightarrow \exists s' \in S: s=s'$ and $\forall c \in C: \enspace c \enspace Isa \enspace (T,S) \Rightarrow \forall s \in S: \exists (c',s',v) \in HasSlot: c=c', s=s'$.
\end{definition}

\begin{definition}[abstract methods of a chunk store]
\label{def:abstract_methods_chunk_store}
The following methods can be defined over a chunk store $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$:

\begin{description}
 \item[$\mathtt{chunk-type(name slot_1 slot_2 \dots slot_n)}$] adds the type $T = (\mathtt{name},\{\mathtt{slot1}, \dots, \mathtt{slotn}\})$ to the store, ie. $\mathcal{T'} = \mathcal{T} \cup \{T\}$. 
 \item[$\mathtt{add-chunk(name isa type slot_1 val_1 \dots slot_n val_n)}$] adds a new chunk to the store, ie. $C' = C \cup \{ \mathtt{name} \}$, $Isa' = Isa \cup (\mathtt{name}, (\mathtt{type}, slots(\mathtt{type}))$ and $HasSlot' = \bigcup_{i = 1}^n{\mathtt{(slot_i,val_i)}} \cup HasSlot.$ Note, that due to the expansion of $C$, the condition that $C$ and $E$ have to be disjoint may be violated. To fix this violation, the element can be removed from $E$: $E' = (E \cup C) - (E \cap C).$ 
 
 Additionally, a valid mechanism to restore type-consistency may be introduced: It might happen, that not all slots are specified in the \verb|add-chunk| method. Since it is claimed by the definition of $HasSlot$ that for all slots $s$ of a chunk $c$ there must be a $(c,s,v) \in HasSlot$, in implementations the unspecified slots are initialized as empty slots, represented by the empty value \verb|nil|.
\end{description} 
\end{definition}

\FIXME{add other methods. describe empty chunks?}

\begin{example}
 The addition-fact chunk in figure \ref{fig:chunk_addition_fact} and its chunk-type are defined as follows:\\
 \verb|chunk-type(addition-fact arg1 arg2 sum)|\\
 \verb|add-chunk(a isa addition-fact arg1 5 arg2 2 sum 7)|.
 
 This leads to the following chunk-store: 
 \begin{align*}
 (\{a\}, \{2,5,7\},\\ 
 \{(addition-fact, \{arg1, arg2, sum\})\},\\
 \{(a,arg1,5), (a,arg2,5), (a,sum,7)\},\\
 \{(a, addition-fact)\}).
 \end{align*}
 
 $slots(a) = \{(arg1,5), (arg2,2), (sum,7)\}$ and $slots((addition-fact,\{arg1, arg2, sum\}) = \{arg1, arg2, sum\}$. Hence, the store is type-consistent.
\end{example}

\begin{example}
 \FIXME{refer to empty chunks}
\end{example}


\subsection{Representation of Chunks in CHR}

Declarative knowledge is represented as a network of chunks, defined by the two relations $Isa$, specifying the belonging of a chunk to a type, and $HasSlot$, specifying the slot-value pairs of a chunk. Those relations can be translated directly into CHR by defining the following constraints representing the relations and sets:

\begin{lstlisting}
:- chr_constraint chunk_type(+).
% chunk_type(ChunkTypeName)

:- chr_constraint chunk_type_has_slot(+,+).
% chunk_type_has_slot(ChunkTypeName, SlotName).
\end{lstlisting}

The \verb|chunk_type/1| constraint represents the set $\mathcal{T}$ of chunk-types in the store, but refers only to the chunk-type names. The set of slots of a chunk-type is specified by the \verb|chunk_type_has_slot/2| constraint\footnote{For a chunk-type $T \in \mathcal{T}$, with $T = (t, S)$, there exists a \texttt{chunk\_type(t)} and for every slot $s \in S$ there is a \texttt{chunk\_type\_has\_slot(t,s)} in the constraint store.}.

For the chunks:

\begin{lstlisting}
:- chr_constraint chunk(+,+).
% chunk(ChunkName, ChunkType)

:- chr_constraint chunk_has_slot(+,+,+).
% chunk_has_slot(ChunkName, SlotName, Value)
\end{lstlisting}

The \verb|chunk/2| constraint represents both the set $C$ of chunks and the $Isa$ relation, since the presence of a constraint \verb|chunk(c,t)| signifies, that chunk \verb|c| is of a type $T = (\mathtt{t},S)$.

The $HasSlot$ relation is represented by the \verb|chunk_has_slot(c,s,v)| constraint, which really is just a direct translation of an element $(c,s,v) \in HasSlot$.

Note that all values in the just presented constraints have to be ground. This is a demand claimed by the original ACT-R implementation and makes sense, since each value in a slot of a chunk is a real, ground value and the concept of variables does not have an advantage in this context, because every element that can be stored in the brain is known by the brain.

Additionally, from the definition of a chunk store it is known, that the $HasSlot$ and the $Isa$ relations have to be left-complete. \FIXME{correct expression! correct definitions!} Therefore, for every chunk \verb|c| in the store, exactly one \verb|isa(c,t)| constraint has to be in the store. For each \verb|chunk_type_has_slot(t,s)| constraint, a \verb|chunk_has_slot(c,s,v)| constraint has to be defined. If one wants to express, that a chunk has an empty slot, he might use \verb|nil| for the value to indicate that. Note that \verb|nil| must not be a chunk name or chunk-type name.

\subsubsection{Distinction of Elements and Chunks}

A chunk store distinguishes between a set of chunks $C$ and a set of elements $E$. For implementational reasons it can be helpful if there are only chunks in the system, because elements just behave like chunks with no slots. Hence, a chunk-type \verb|chunk| with no slots will be added automatically to the store. Each element $e \in E$ and added as a chunk of type \verb|chunk| to the set of chunks $C$. After this operation $E = \emptyset$, and for every former element $e$ of $E$: $e \in C$, $(e,(chunk,\emptyset)) \in Isa$.

\subsubsection{Simple Implementation of the Default Methods}
\label{chunk_specification}

To implement the methods in definition~\ref{def:abstract_methods_chunk_store}, first a data type for chunk specifications has to be introduced. From this specification the correct constraints modeling the chunk-store are added or modified.

The straight-forward definition of a data type for chunk specifications is just to use the specification like in definition~\ref{def:abstract_methods_chunk_store}: Since \verb|(name isa type slot_1 val_1 \dots slot_n val_n)| is just a list in LISP and specifies a chunk uniquely, a similar Prolog term can be used:

\begin{lstlisting}
:- chr_type chunk_def ---> nil; chunk(any, any, slot_list).
:- chr_type list(T) ---> []; [T | list(T)].
% a list of slot-value pairs
:- chr_type slot_list == list(pair(any,any)).
:- chr_type pair(T1,T2) ---> (T1,T2).
\end{lstlisting}

This definition states that a chunk is either \verb|nil|, ie. an empty chunk, or a term \verb|chunk(Name, Type, SVP)|, where \verb|SVP| is a list of slot-value pairs. This is the direct translation of the chunk-specification used in the definition, amended by the \verb|nil| construct, that may be needed for later purposes.

The default methods can be implemented as follows:

\paragraph{add\_chunk}

This method creates a the chunks and elements of the chunk store. The set $E$ of elements is minimal, ie. only elements that appear in the slots of a chunk but are not chunks themselves are members of $E$. However, the set $E$ is never constructed explicitly, but represented by chunks of the special type \verb|chunk| that provides no slots. So each value in the slot of a chunk that is added to the store and that is not an element of the chunk store yet, gets its own chunk of type \verb|chunk|. As soon as a chunk with the name of such a primitive element is added to the store, the chunk of type \verb|chunk| is removed from the store.

\begin{lstlisting}[caption={rules for \texttt{add\_chunk}}]
% empty chunk will not be added
add_chunk(nil) <=> true.
  
% initialize all slots with nil
add_chunk(chunk(Name,Type, _)), chunk_type_has_slot(Type,S) ==> 
  chunk_has_slot(Name,S,nil).

% chunk has been initialized with empty slots -> actually add chunk
add_chunk(chunk(Name,Type, Slots)) <=>
  do_add_chunk(chunk(Name,Type,Slots)).
\end{lstlisting}

First, all \verb|chunk_type_has_slot| constraints are added to the store and initialized with \verb|nil| as slot value. This leads to complete chunk specifications that are consistent to the type as demanded by a type-consistent chunk-store.

If all slots have been initialized, \verb|do_add_chunk| performs the actual setting of the real slot values:
  
\begin{lstlisting}  
% base case
do_add_chunk(chunk(Name, Type, [])) <=> chunk(Name, Type). 

% overwrite slots with empty values
chunk(V,_) \ do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=>
  chunk_has_slot(Name, S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).

% overwrite slots with empty values  
do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=> 
  V == nil | % do not add chunk(nil,chunk)
  chunk_has_slot(Name, S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).  

% overwrite slots with empty values  
do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)  <=> 
  V \== nil |
  chunk_has_slot(Name, S,V), 
  chunk(V,chunk), % no chunk for slot value found => add chunk of type chunk 
  
do_add_chunk(_) <=> false.
\end{lstlisting}

The first rule is the base case, where no slots have to be added any more. Then, as a last step the actual \verb|chunk| constraint of the chunk that is added to the store is created.

The second rule deals with the case, that a slot-value pair has to be added with a value that is already described by a chunk. Then the \verb|nil|-initialized slot of this chunk is removed and replaced by another slot containing the actual value.

The next rule ensures that the helper chunk specification \verb|nil| will not get a chunk in the store, even if it is in the slots of a chunk.




\begin{lstlisting}
% delete chunk of Type chunk, if real chunk is added
add_chunk(chunk(Name,_,_)) \ chunk(Name,Type) <=> 
  Type == chunk |
  true.
\end{lstlisting}


\FIXME{add very simple solution}

\begin{lstlisting}[caption={rules for \texttt{add\_chunk\_type}}]
add_chunk_type(CT, []) <=> 
  chunk_type(CT).
add_chunk_type(CT, [S|Ss]) <=> 
  chunk_type_has_slot(CT, S), 
  add_chunk_type(CT, Ss).
\end{lstlisting}

\FIXME{add duplicate handling}




\subsubsection{Checking Type-Consistency}

\FIXME{missing}

\section{Procedural Module}

The part of the system, where the computations are performed, is the procedural module. It is the central component, that holds all the production rules, the working memory (in the buffer system) and organizes communication between modules (through buffers and requests). In the following, all of those subcomponents of the procedural module are described.

\subsection{Buffer System}

The buffer system can be regarded as a chunk-store, that is enhanced by buffers. A buffer can hold only one chunk at a time. The procedural module has a set $B$ of buffers, a chunk-store $\Sigma$ and a relation between the buffers and the chunks in $\Sigma$.

\begin{definition}[buffer system]
\label{def:buffer_system}
A \emph{buffer system} is a tuple $(B,\Sigma,Holds)$, where $B$ is a set of buffers, $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$ a type-consistent chunk-store and $Holds \subseteq B \times (C \cup \{ \mathtt{nil} \})$ a unique and complete relation, that assigns every buffer at most one chunk that it holds. If a buffer $b$ is empty, ie. it does not hold a chunk, then $(b,\mathtt{nil}) \in Holds$.

A buffer system is \emph{consistent}, if every chunk that appears in $Holds$ is a member of $C$ and $\Sigma$ is consistent.

A buffer system is \emph{clean}, if its chunk-store only holds chunks which appear in $Holds$.
\end{definition}

For the implementation of a buffer system, the code of a chunk-store can be extended by a \verb|buffer/2| constraint, that encodes the set $B$ and the relation $Holds$ at once, since the relation is complete by definition\footnote{$\forall b \in B \enspace \exists c \in (C \cup \{ \mathtt{nil} \}): (b,c) \in Holds$}.

\subsubsection{Destructive Assignment and Consistency}
\label{destructive_assignment}

The demand of $Holds$ being unique is a form of destructive assignment as described in \cite[p. 32]{fru_chr_book_2009}, ie. if a new chunk is assigned to a buffer, the old \verb|buffer| constraint is removed and a new \verb|buffer| constraint is introduced, holding the new chunk:

\begin{lstlisting}
set_buffer(b, c) \ buffer(b, _) <=> buffer(b, c).
\end{lstlisting}

This rule ensures that only one \verb|buffer| exists for each buffer in $B$.

At the beginning of the program, a \verb|buffer| constraint has to be added for all the available buffers of the modules. This problem is discussed at a later point. \FIXME{add reference}

In addition, if a new chunk is introduced in a buffer, it also has to be present in the chunk-store, since the production system relies on the knowledge about the chunks in its buffers and chunks are essentially defined by their slots (\emph{consistency property} in definition~\ref{def:buffer_system}). Hence, every time a chunk is stored in a buffer, the \verb|add_chunk| method described in definition~\ref{def:abstract_methods_chunk_store} has to be called. This process is discussed later when talking about buffer requests in section~\ref{buffer_requests}.

\subsubsection{Buffer States}

Another formal detail of the buffer system is that buffers can have various states: \emph{busy}, \emph{free} and \emph{error}. A module is busy, if it is completing a request and free otherwise.

Since a module can only handle one request at a time and requests may need a certain time (like the retrieval request for example), the procedural module could state another request to a busy module. This is called \emph{jamming} which leads to error messages and should be avoided. One technique to avoid module jamming is to \emph{query} the buffer state in the conditional part of a production rule \cite[unit 2, p. 9]{actr_tutorial}. The possibility to query buffer states is discussed in the next section.

A buffer's state is set to \emph{error}, if a request was unsuccessful because of an invalid request specification or, in case of the declarative module for instance, a chunk that could not be found.

In CHR, a buffer state can be represented by a \verb|buffer_state(b,s)| constraint, which signifies that buffer \verb|b| has the state \verb|s|. Since every buffer has exactly one state all the time, it is required, that for every buffer there is such a constraint and it is ensured, that only one \verb|buffer_state| constraint is present for each buffer. This can be achieved by the destructive assignment method described in section~\ref{destructive_assignment}. 

At the beginning of the program, when a buffer is created (a \verb|buffer| constraint is placed into the store), a corresponding \verb|buffer_state| constraint has to be added. The initial state can be set to \verb|free|, since no request is being computed at the time of creation.

\subsection{Production Rules}

Production rules consist of a \emph{condition} part and an \emph{action} part. Syntactically, in ACT-R the condition is separated from the action by \verb|==>|. Additionally, each production rule has a name. Thus, a rule is defined by:

\begin{verbatim}
(p name condition* ==> action*)
\end{verbatim}

The condition part is also called the \emph{left hand side} of a rule (LHS) and the action part is called \emph{right hand side} (RHS).

\subsubsection{The Left Hand Side of a Rule}

Generally, a condition is either a \emph{buffer test}, ie. a specification of slot-value pairs that are checked against the chunk in the specified buffer or a \emph{buffer query}, ie. a check of the state of a buffer's module (either busy, free or error). A buffer test on the LHS of a rule is indicated by a \verb|=| followed by the buffer name of the tested buffer; a query is indicated by a \verb|?| in front of the buffer name.

The LHS of a rule may contain bound or unbound variables: \verb|=varname| is a variable with name \verb|varname|.

If the chunks in the buffers pass all buffer tests specified by the rule, the rule can fire, ie. its right hand side will be applied. The LHS is a conjunction of buffer tests, ie. there is no specific order for the tests \cite[p. 165]{actr_reference}.

\begin{example}[counting example -- left hand side]
The left hand side of the counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  ... )
\end{lstlisting}

The condition part consists of two buffer tests:

\begin{enumerate}
 \item The goal buffer is tested for a chunk of type \verb|count| and a slot with name \verb|number|. The value of the slot is bound to the variable \verb|=n|.
 \item The retrieval buffer is tested for a chunk of type \verb|count-fact| that has the variable \verb|=n| in its \verb|first| slot (with the same value as the \verb|number| slot of the chunk in the goal buffer, since \verb|=n| has been bound to that value), and another value in its second slot which is bound to the variable \verb|=m|.
\end{enumerate}

\end{example}

\subsubsection{The Right Hand Side of a Rule}

For the right hand side of a rule the following actions are allowed:

\begin{description}
 \item[Buffer Modification] 
 \item[Buffer Request]
 \item[Buffer Clearing]
\end{description}


\begin{example}[counting example]
\label{ex:counting}
The counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  =goal>
    number =m
  +retrieval>
    isa    count-fact
    first  =m
)
\end{lstlisting}

\FIXME{add description}

\end{example}

\subsubsection{Direct Translation of Buffer Tests}

An ACT-R production rule of the form

\begin{verbatim}
(p name
  =buffer1>
    isa    type1
    slot11 val11
    ...
    slot1n val1n
  ...
  =bufferk>
    isa    typek
    slotk1 valk1
    ...
    slotkm valkm
==>
... )
\end{verbatim}

states formally, that:

If $buffer1 Holds c \wedge c Isa type1 \wedge slot_{1,1}=val_{1,1} \wedge \dots$ \FIXME{extend} is true, then the rule matches and the RHS should be performed.

This can be directly translated into a CHR rule:

\begin{verbatim}
name @
  buffer(buffer1,C1),
  chunk(C1,type1),
  chunk_has_slot(C1,slot11,val11),
  ...
  chunk_has_slot(C1,slot1n,val1n),
  ...
  buffer(bufferk,Ck),
  chunk(Ck,typek),
  chunk_has_slot(Ck,slotk1,valk1),
  ...
  chunk_has_slot(Ck,slotkm,valkm)
==>
  ...
\end{verbatim}

This rule checks the buffer system for the existence of a buffer specified in the request holding a certain chunk and then checks the chunk store of the buffer system for that chunk with the type and slots specified in the ACT-R rule.

If the values in the slot tests are variables, they can be directly translated to Prolog variables.

The CHR rule only fires, if all the checked buffers hold chunks that meet the requirements specified in the slot tests of the ACT-R rule. Since those slot-tests are just a conjunction of relation-membership tests and the CHR rule is a translation of these tests into constraints, both are equivalent. In detail: \FIXME{geht besser}

\begin{itemize}
 \item If a checked buffer \verb|b| holds no chunk, the constraint \verb|buffer(b,nil)| will be present, but the chunk store will not hold any of the required \verb|chunk| or \verb|chunk_has_slot| constraints and the rule will not fire.
 \item If a checked buffer \verb|b| holds a chunk, but the chunk does not meet one of the requirements in its slots, the rule does not fire.
 \item The rule only fires, if for all checked buffers there are valid \verb|buffer|, \verb|chunk| and \verb|chunk_has_slot| constraints present that meet all the requirements specified by the ACT-R rule.
 \item Variables on the LHS of a rule are bound to the values of the actual constraints that are tried for the matching. This corresponds to the semantics of a ACT-R production rule with variables on the LHS.
\end{itemize}

\FIXME{ist die begründung schlüssig? evtl section über variablen hier einfügen}
\FIXME{add some words about double chunk checks}

\begin{example}[counting example in CHR -- simple]
The production rule in example~\ref{ex:counting} can be translated to:

\begin{lstlisting}
count-rule @
  buffer(goal,C1), 
    chunk(C1,count),
    chunk_has_slot(number,N),
  buffer(retrieval,C2),
    chunk(C2,count-fact),
    chunk_has_slot(first,N),
    chunk_has_slot(second,M)
==>
  buffer_change(goal    number =m
  +retrieval>
    isa    count-fact
    first  =m
)
\end{lstlisting}

\end{example}


\subsection{Translation of Buffer Queries}

A buffer query

\begin{lstlisting}
...
?buffer>
  state  bstate 
...
==> ...
\end{lstlisting}

on the LHS of a production rule can be translated to the following CHR rule head:

\begin{lstlisting}
...
buffer_state(buffer,bstate) 
...
==> ...
\end{lstlisting}






\subsubsection{The Production Rule Grammar}

The discussed concepts lead to the following grammar for production rules, which is a simplified version of the actual grammar used in the original ACT-R implementation \cite[p. 162]{actr_reference}. 


\begin{lstlisting}
production-definition ::= (p name condition* ==> action*)
name ::= a symbol that serves as the name of the production for reference
condition ::= [ buffer-test | query ]
action ::= [buffer-modification | request | buffer-clearing | output | ]
buffer-test ::= =buffer-name> isa chunk-type slot-test*
buffer-name ::= a symbol which is the name of a buffer
chunk-type ::= a symbol which is the name of a chunk-type in the model
slot-test ::= {slot-modifier} slot-name slot-value
slot-modifier ::= [= | - | < | > | <= | >=]
slot-name ::= a symbol which names a possible slot in the specified chunk-type
slot-value ::= a variable or any Lisp value
query ::= ?buffer-name> query-test*
query-test ::= {-} queried-item query-value
queried-item ::= a symbol which names a valid query for the specified buffer
query-value ::= a bound-variable or any Lisp value
buffer-modification ::= =buffer-name> slot-value-pair*
slot-value-pair ::= slot-name bound-slot-value
bound-slot-value ::= a bound variable or any Lisp value
request ::= +buffer-name> isa chunk-type request-spec*
request-spec ::= {slot-modifier} slot-name slot-value
request-parameter ::= a Lisp keyword naming a request parameter provided by the buffer specified
buffer-clearing ::= -buffer-name>
variable ::= a symbol which starts with the character =
output ::= !output! [ output-value ]
output-value ::= any Lisp value or a bound-variable
bound-variable ::= a variable which is used in the buffer-test conditions of the production (including a
variable which names the buffer that is tested in a buffer-test or dynamic-buffer-test) or is bound with
an explicit binding in the production
\end{lstlisting}

Some of the details in this grammar that have not been discussed yet are presented in the following.

\subsubsection{The Order of Rule Applications}

\subsubsection{Bound and Unbound Variables}

\subsubsection{Slot Modifiers}

In ACT-R, slot-tests can be preceded by \emph{slot modifiers}. Those modifiers allow to specify tests like inequality (\verb|-|) or arithmetic comparisons (\verb|<, >, <=, >=|) of the slot value of a chunk with the specified variable or value. Since the slots in a chunk store are always fully defined with ground values, those tests are decidable.

If no slot modifier is specified in a slot test, the default modifier \verb|=| is used, that states that the chunk in the specified buffer must have the specified value in the specified slot. This default semantics has been used in the previous sections when translating simple ACT-R rules to CHR and is performed automatically by the matching of CHR.

To translate the other slot modifiers to CHR, another CHR mechanism can be used: Guards. Since the allowed modifiers are all default built-in constraints\footnote{ie. Prolog predicates}, a slot test with a modifier

\begin{lstlisting}
...
=buffer>
  ...
  ~slot  val
...
==>
\end{lstlisting}

where \verb|~| stands for a modifier in \{ \verb|=,-,<,>,<=,>=| \}can be translated as follows:

\begin{lstlisting}
buffer(buffer,C),
  ...
  chunk_has_slot(C,slot,V),
  ...
==>
  V # val |
  ...
\end{lstlisting}

where \verb|#| is the placeholder for the built-in constraint that computes the test specified by \verb|~| and \verb|V| is a fresh variable that has not been used in the rule, yet.

For arithmetic slot modifiers the values being compared have to be numbers. If a value is not a number, the arithmetic test will fail and the rule cannot be applied \cite{actr_reference}.

Note, that slot tests with modifiers other than \verb|=| do not bind variables, but only perform simple checks, like it is with guards in CHR. If \verb|val| is an unbound variable and is never bound to a value on LHS, the default implementation throws a warning, and the rule will not match. Therefore, to handle this case, the rule translation scheme has to be amended with an additional guard check \verb|ground(Val)|, where \verb|Val| is the Prolog variable that replaces each occurrence of the variable \verb|val|.

As with normal slot tests, it is important to mention that if there are several tests on the same slot, the \verb|chunk_has_slot| constraint must appear only once on the LHS of the CHR rule, since every slot-value pair is unique in the constraint store. Ie., if the first slot test of a particular slot appears on the LHS of the ACT-R rule, a \verb|chunk_has_slot| constraint has to be added to the LHS of the CHR rule. For every other occurrence of this slot in a slot test, only guard checks are added.

\begin{example}
To clarify the details of the matching concept in ACT-R, here are some examples and their behaviour:

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
\end{lstlisting}

will throw a warning when loading the model. When running it, the rule will never fire, since no chunk value will match the inequality to the unbound variable \verb|bar|.

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
  eggs   =bar
\end{lstlisting}

will fire, if there is a chunk whose value in \verb|eggs| is different from the value in \verb|spam|.

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
\end{lstlisting}

matches for every value of the spam slot. The translation to CHR is:

\begin{lstlisting}
buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar),
==>
  Bar=Eggs |
  ...
\end{lstlisting}

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
  ham   =eggs
\end{lstlisting}

will match all chunks which have the same value in \verb|spam| and \verb|ham|. \FIXME{CHR translation???}

\end{example}


\subsubsection{Empty Slots}

An important special case in the semantics of ACT-R production rules is, that if there is a slot test specified, then a potential chunk only matches, if it really has a value in this slot. Chunks that have \verb|nil| in a slot specified in a buffer test, will not match the test. Hence, variables can not be used to test if two slots have the same value and the value is \verb|nil|, since every positive slot test involving \verb|nil| fails automatically \cite[p. 164, section ``Variables'', last sentence]{actr_reference}.

In CHR this special case can be handled, by adding a guard for each variable occurring in a positive slot-test checking that this variable does not equal \verb|nil|.

For negated slot tests, this is not the case: 

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  4
\end{lstlisting}

matches also a chunk with an empty \verb|spam| slot (\verb|nil| in its \verb|spam| slot).



\subsubsection{Outputs}

The production system of ACT-R also provides methods to produce side-effects. In this work, only a subset of those methods is concerned: the outputs. Outputs can appear on the right hand side of an ACT-R rule:

\begin{lstlisting}
=buffer>
  isa  foo
==>
  !output! (a1 a2 a3)
\end{lstlisting}

The argument of such an output call is a list of Lisp-symbols, so it is possible to hand variables or terms.

This mechanism can be translated to Prolog directly:

\begin{lstlisting}
output([]) :-
  nl.
output([X|Xs]) :-
  write(X),
  output(Xs).
\end{lstlisting}

The \verb|X| have to be Prolog terms.

In ACT-R, function calls like \verb|!eval!| or \verb|!bind!| are allowed, but they are ignored in this work.

\section{Modular Organization}

The term \emph{module} is highly overloaded: In ACT-R it describes independent parts of human cognition, whereas in the world of programming the term is used in a slightly different manner. In the following, implementational modules will always be named explicitly as \emph{Prolog modules}.

Nevertheless, the modular organization of ACT-R with its independent modules can be implemented by defining a Prolog module for each ACT-R module and adding some other modules around them. In the following, the concept of Prolog modules is explained.

\subsection{Prolog Modules}

Defining a new module creates a new namespace for all CHR constraints and Prolog predicates, which is illustrated in the following example:

\begin{example}[Prolog Modules and CHR]

In this example, two modules \verb|mod1| and \verb|mod2| are defined, with partially overlapping constraints. \verb|mod2| exports the constraint \verb|c|. In the following, the behaviour an interaction of the modules is explored.

\begin{lstlisting}[caption={Definition of Module 1},label=lst:mod1]
:- module(mod1,[]).
:- use_module(library(chr)).

:- use_module(mod2).

:- chr_constraint a/0, b/0.

a <=> c.
\end{lstlisting}

\begin{lstlisting}[caption={Definition of Module 2},label=lst:mod2]
:- module(mod2,[c/0]).
:- use_module(library(chr)).

:- use_module(mod1).

:- chr_constraint a/0, b/0, c/0. 

a <=> b.
b <=> mod1:a.
\end{lstlisting}


In this definition, two new modules \verb|mod1| and \verb|mod2| are created and only the \verb|c| constraint of \verb|mod2| is exported, indicated by the lists in the module definitions.

The CHR constraint \verb|a| in listing~\ref{lst:mod1} is internally represented as \verb|mod1:a|, so it lives in its own namespace and does not pollute other namespaces. The constraint can appear on the right hand side of rules of other modules, but has to be called explicitly with its full namespace identifier. In line~8 of listing~\ref{lst:mod2}, the presence of the local \verb|a| constraint leads the rule to fire and \verb|mod2:a| is replaced by \verb|mod2:b|, which leads the rule in line~9 to fire and replaces the local \verb|mod2:b| constraint by an external \verb|mod1:a| constraint. So, external constraints can be called by their complete identifiers.

However, on the left hand side of a rule, only the constraints local to the current module can appear. 

Exported constraints can only appear once in a program, since they can be called without their namespace definition, which is demonstrated in line~8 of listing~\ref{lst:mod1}, where \verb|mod2:c| is called in \verb|mod1| without referring to \verb|mod2| explicitly.
\end{example}

\subsection{Interface for Module Requests}

The architecture of ACT-R provides an infrastructure for the procedural module to state requests to all the other modules. To implement this concept as general as possible, an interface has to be defined, which allows the adding of new modules to the system by just implementing this interface.

\begin{lstlisting}[caption={Simple Interface Module},label=lst:interface_module]
module_request(+BufName,+Chunk,-ResChunk,-ResState)
\end{lstlisting}

The arguments of such a request are:

\begin{description}
 \item[BufName] The name of the requested buffer, eg. \verb|retrieval|.
 \item[Chunk] A chunk specification that represents the arguments of the request. The form of the allowed chunk specifications and the semantics of the request are module-dependent. For example: \verb|chunk(_,t,[(foo,bar),(spam,eggs)])| could describe a chunk, that should be retrieved from declarative memory.
\end{description}

The request provides the following result:

\begin{description}
 \item[ResChunk] The resulting chunk in form of a chunk specification. The actual result and its semantics depend on the particular module.
 \item[ResState] The state of the buffer after the request. For example, if no matching chunk could be retrieved from declarative memory, the state would be \verb|error|.
\end{description}

This interface will be extended later on.

\subsection{Components of the Implementation}

uml component diagram + discussion



\section{Declarative Module}

The Declarative Module is a \emph{chunk store}, that additionally implements the \emph{module} interface. Therefore some rules to handle requests that find certain chunks in the chunk store have to be implemented. 

\subsection{Retrieval Requests}

A retrieval request gets an incomplete chunk specification as input and returns a chunk, whose slots match the provided chunk pattern.

\subsubsection{Chunk Patterns}

The chunk patterns are transmitted in form of chunk specifications as defined in section~\ref{chunk_specification}. Since those specifications may be incomplete, variables are considered as place-holders for values in the result. The result always is a complete and ground chunk specification, because every chunk in a chunk store has to be defined completely; empty slots are indicated by the value nil.

\begin{example}
In this example some possible requests are discussed.

\begin{enumerate}
 \item Request:
\begin{lstlisting}
chunk(foo,bar,_)        
\end{lstlisting}

A chunk with name \verb|foo|, type \verb|bar| and arbitrary slot values is requested.

 \item Request:
\begin{lstlisting}
chunk(_,bar,_)        
\end{lstlisting}

This request is satisfied by every chunk of type \verb|bar|.

 \item Request:
\begin{lstlisting}
chunk(_,t,[(foo,bar),(spam,eggs)])        
\end{lstlisting}

The most common case of requests is a specification of the type and a (possibly incomplete) number of slot-value pairs for that type. If a type does not provide a specified slot, the request is invalid and no chunk will be returned.

\end{enumerate}

\end{example}

\subsubsection{Finding Chunks}

In this section, a CHR constraint \verb|find_chunk/3| will be defined, that produces a \verb|match_set/1| constraint for each chunk that matches a specified pattern. Eventually, the match set will be collected and returned.

\begin{lstlisting}
find_chunk(N1,T1,Ss), chunk(N2,T2) ==> 
  unifiable((N1,T1),(N2,T2),_), 
  nonvar(Ss) | 
  test_slots(N2,Ss), 
  match_set([N2]).
  
find_chunk(N1,T1,Ss), chunk(N2,T2) ==> 
  unifiable((N1,T1),(N2,T2),_), 
  var(Ss) | 
  test_slots(N2,[]), 
  match_set([N2]).

find_chunk(_,_,_) <=> true.
\end{lstlisting}

First, for each chunk in the store, whose name and type is unifiable with the specified name and type, will be part of the initial match set. If in the chunk specification the name and type are variables, each chunk will match. For the unification test, the \verb|unifiable/3| predicate of Prolog is used, because the unification should not be performed but only tested. 

If name and type match the pattern, then the slots have to be tested.

The rule in line~7 is for chunk specifications that do not specify the slots. In this case, no slots have to be tested. If all chunks have been tested or no chunk matches at all, the process is finished (rule in line ~13).

After adding each matching candidate to the match set, whose name and type have already been checked, the match set is pruned from chunks that have non-matching slot values:

\begin{lstlisting}
test_slots(_,[]) <=> true.

chunk_has_slot(N,S,V1), match_set([N]) 
\ test_slots(N,[(S,V2)|Ss]) <=> 
  unifiable(V1,V2,_) | 
  test_slots(N,Ss).

chunk_has_slot(N,S,V1) 
\ test_slots(N,[(S,V2)|_]), match_set([N]) <=> 
    \+unifiable(V1,V2,_) | 
    true.

test_slots(N,_) \ match_set([N]) <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more and the test is finished and has been successful.

In line~3, the rule applies, if there is at least one slot \verb|(S,V2)| that has to be tested and a $HasSlot$ relation of the kind \verb|N| $\xrightarrow[]{\mathtt{S}}$ \verb|V1| with the slot \verb|S| to be tested, that is still in the match set, so no conflicting slot has been found yet. If the values \verb|V1| and \verb|V2| are unifiable, ie. the both are the same constant or at least one is a variable, then the test passes and the chunk \verb|N| remains in the match set and the rest of the slot tests are performed.

The second rule is applied, if the guard of the first rule did not hold, so the values \verb|V1| and \verb|V2| are not unifiable, but there is a connection \verb|N| $\xrightarrow[]{\mathtt{S}}$ \verb|V1| and in the request it has been specified that the value of slot \verb|S| has to be \verb|V2|. In this case, \verb|V1| $\neq$ \verb|V2|, so the test fails and the chunk \verb|N| has to be removed from the match set, since one of its slots does not match.

If both of the first two rules cannot be applied, the chunk does not provide a slot that, however, has been specified in the request. Hence, the chunk does not match. \FIXME{make simpagation rule to simplification rule?}

If those rules have been applied exhaustively, only the matching chunks will remain in the match set: If there would be an outstanding slot test, one of the rules would be applicable and the chunk would be removed from the match set, if the test fails (and the test would also be removed, because it has been performed). If the test is successful, the chunk will remain part of the match set, but the test will be removed. So the match set is correct and complete.

However, since the match set is distributed over a set of \verb|match_set| constraints, it would be desirable to collect all those matches in one set. This can be triggered by a \verb|collect_matches/1| constraint, that gets the complete match set in its arguments:

\begin{lstlisting}
collect_matches(_) \ match_set(L1), match_set(L2) <=> 
  append(L1,L2,L), 
  match_set(L).
  
collect_matches(Res), match_set(L) <=> Res=L.

collect_matches(Res) <=> Res=[].
\end{lstlisting}

The first rule merges two match sets to one singe merge set containing a list with all the chunks of the former sets, if the \verb|collect_matches| trigger is present. 

In the second rule, if no two match sets are in the store, the result of the \verb|collect_matches| operation is the match set. The same applies for the last rule, where no match set is in the store and therefore the result is empty.

Note, that this implies, that the rules have to be applied from top to bottom, left to right\footnote{This is called the refined operational semantics of CHR}.

The symbolic layer does not implement any rule for which chunk will be returned, if there are more than one in the match set. In this implementation, the first chunk in the list is chosen. The module request is now implemented as follows:

\begin{lstlisting}
module_request(retrieval,chunk(Name,Type,Slots),ResChunk,ResState) <=> 
  find_chunk(Name,Type,Slots),
  collect_matches(Res),
  first(Res,Chunk),
  return_chunk(Chunk,ResChunk),
  get_state(ResChunk,ResState).
\end{lstlisting}

where \verb|first(L,E)| gets a list \verb|L| and returns its first element \verb|E| or \verb|nil|, if the list was empty.

With \verb|return_chunk/2| and \verb|get_state/2|, the actual results of the request are computed:

By now, the variable \verb|Chunk| holds the name of the chunk to return, but in the specification of the module request, a complete chunk specification is demanded. \verb|return_chunk/2| is defined as a default method of a chunk store and gets a chunk name as its first argument and returns a chunk specification created from the values in the chunk store as its second argument. \FIXME{add return chunk to default methods of chunk store}

The resulting state of the request is computed as follows: If the result chunk is \verb|nil|, then no chunk was in the match set, so the state of the declarative module will be \verb|error|. In any other case, the state is \verb|free| after the request has been performed.

\subsection{Chunk Merging}

\section{Initialization}

In the examples the models had to be run by stating complex queries which create all necessary buffers and add all chunk types and chunks to the declarative memory manually. In the original ACT-R implementation, the command \verb|run| is used to run a model. This behaviour can be transferred to the CHR implementation easily by adding a \verb|run| constraint and a rule for this constraint, that performs all the initialization work.

\FIXME{modify count example from above}

\section{Timing in ACT-R}

So far, the execution order of the production rules has been controlled by the \verb|fire| constraint -- a phase constraint that simulated the occupation of the production system while a rule is executed.

However, certain buffer actions like buffer requests may take some time until they are finished. The procedural system is free to fire the next rule after all actions have been started\footnote{see chapters \ref{serial_parallel_aspects} and \ref{process_of_rule_selection_and_execution}} and the requests are performed in parallel to that.

Additionally, for the simulation it may be interesting to explore how much time certain actions have taken, especially when it comes to the subsymbolic layer.

Those aspects cannot be implemented easily using the current approach with phase constraints. Hence, the idea of introducing a central scheduling unit is a possible solution of those requirements: The unit has a serialized ordered list of events with particular timings. If a new event is scheduled, the time it is executed must be known. The scheduling unit inserts the event at the right position of the list preserving the ordered time condition. Figure~\ref{fig:scheduler} illustrates this approach.

The system just removes such events from the queue and executes them, which leads to new events in the queue. The queue organizes the right order of the events.

With this approach, the simulation of a parallel execution of ACT-R can be achieved: Each buffer action on the RHS of a rule just schedules an event that actually performs the action at a specified time (the current time plus its duration). 

The heart of the scheduler is a \emph{priority queue} which is described in the next section.

\subsection{Priority Queue}

A \emph{priority queue} is an abstract data structure that serves objects by their priority. It provides the following abstract methods:

\begin{description}
 \item[enqueue with priority] An object with a particular priority is inserted to the queue. 
 \item[dequeue highest priority] The object with the highest priority is removed from the queue and returned.
\end{description}

\subsubsection{Objects}

In the implementation of the scheduler, the priority queue holds objects \verb|q(Time,Priority,Event)|. The priority of such a queue object is composed from the \verb|Time| and the \verb|Priority|. The order between the elements is defined as follows:

\begin{definition}[ordered time-priority condition]
\verb|q(T1,P1,E1)| $\prec$ \verb|q(T2,P2,E2)|, if \verb|T1| $<$ \verb|T2|. In the case that \verb|T1 = T2|, then \verb|q(T1,P1,E1)| $\prec$ \verb|q(T2,P2,E2)| if \verb|P1| $>$ \verb|P2|. So, events with smaller times will be returned first. If two events appear at the same time, it is possible to define a priority and the event with the higher priority will be returned first. 
\end{definition}

\subsubsection{Representation of the Queue}

The representation of the priority queue is inspired by \cite[38\psqq]{fru_chr_book_2009}: An order constraint \verb|A --> B| is introduced, which states that \verb|A| will be returned before \verb|B| (or \verb|B| is the direct successor of \verb|A|). The beginning of the queue will be defined by a start symbol \verb|s|, so the first real element is the successor of s. A possible queue could be:

\begin{lstlisting}
s         --> q(1,0,e1)
q(1,0,e1) --> q(3,7,e2)
q(3,7,e2) --> q(3,2,e3)
\end{lstlisting}

This queue achieves the ordered time-priority condition, since the queue objects are in the correct order according to their times and priorities. It is also consistent in a sense that it has no gaps and no object has more than one successor.

In general, there can be defined some rules to make such a queue consistent, ie. every object only has one successor and the queue achieves the time-priority condition:

\begin{lstlisting}
A --> A <=> true.

_ --> s <=> false.

A --> B, A --> C <=>
  leq(B,C) |
  A --> B,
  B --> C.
\end{lstlisting}

The first rule states, that if an object is its own successor, this information can be deleted. The second rule states, that nothing can be the predecessor of the start symbol. The last rule is the most important one: If one object has two successors, then these connections have to be divided into two connections according to the defined time-priority condition. This condition can be implemented as follows:

\begin{lstlisting}
leq(s,_).

% Time1 < Time2 -> event with time1 first, priority does not matter
leq(q(Time1,_,_), q(Time2,_,_)) :- 
  Time1 < Time2.

% same time: event with higher priority first
leq(q(Time,Priority1,_), q(Time,Priority2,_)) :- 
  Priority1 >= Priority2.
\end{lstlisting}

The first predicate states that the start symbol is is less than every other object. The other two rules implement the time-priority condition directly.

Note that two objects are considered the same, iff. their time, priority and event are syntactically the same. If an object is altered in one of the \verb|-->| constraints, it has to be edited in every other occurrence in the   list to avoid gaps.

Another important property is, that the list does not have any gaps, so it must be possible to track the queue from every element backwards to the start symbol. This condition is not achieved by the rules above, but since a priority queue only offers two mechanisms to modify it, a lot of those problems can be avoided:

\begin{description}
 \item[add\_q(Time,Priority,Event)] Enqueues an object with the specified properties. Ie., a new \verb|q(Time,Priority,Event)| object will be created and the following constraint will be added: \verb|s --> q(Time,Priority,Event)|. The rules presented above will lead to a linear, serialized list achieving the time-priority condition without gaps.
\begin{lstlisting}
add_q(Time,Priority,Evt) <=>
  s --> q(Time,Priority,Evt).
\end{lstlisting}
 \item[de\_q(X)] Dequeues the first element of the queue according to the time-priority condition and binds its value to \verb|X|.
\begin{lstlisting}
de_q(X), s --> A, A --> B <=>
  X = A,
  s --> B.

de_q(X), s --> A <=>
  X = A.  
  
de_q(X) <=> X = nil.
\end{lstlisting}

The first object just is the successor of \verb|s|, since the list has been constructed preserving the correct order and the property, that everything starts at \verb|s|. If the first object has a successor, this object is the new first object. If there are no order constraints left, the queue is empty and \verb|de_q| returns \verb|nil|.

\end{description}

\subsubsection{Special Operation for ACT-R}

In this implementation, another default method is added to the priority queue: 

\begin{description}
 \item[after\_next\_event(E)] Adds the event \verb|E| to the queue, after the first event without destroying the consistency and the time-priority condition of the queue.
\end{description}

To implement this method, the time and priorities have to be set such that the time-priority condition does hold:

\begin{lstlisting}
s --> q(Time,P1,E1) \ after_next_event(Evt) <=> 
  NP1 is P1 + 2, % increase priority of first event, so it still has highest priority
  P is P1 + 1, % priority of event that is added, ensured that it is higher than of the former second event (because it is P1+1)
  de_q(_), % remove head of queue
  add_q(Time,NP1,E1), % add head of queue again with new priority. Will be first again, because it has old prio (which is higher than prio of all successors)
  add_q(Time,P,Evt). % add new event. Will be < than Prio of head but it is ensured that it is higher than prio of second event
\end{lstlisting}

If the first event is \verb|q(Time,P1,E1)| and a new event \verb|Evt| has to be added after this event, the times of the two events are the same, the priority of the first event is \verb|P1 + 2| and the priority of the new event is \verb|P1 + 1|. The first event is removed from the queue and would be added with its new priority to the queue again, as it is with the new event. 

This is correct: The first event will be the first event again, because its old priority was higher than any other priority at that time point and since the new priority is even higher than that, no other event from the queue will have a higher priority. The new event also has a higher priority than every other event in the queue, but a lower priority than the first event, so it will be added after the first event.

By the \verb|de_q| and \verb|add_q| actions it is ensured, that no garbage of the old event remains in the queue and the events are added correctly through a official method of the queue.

\subsection{Scheduler}

The scheduler component is a own module that manages events by feeding a priority queue and controls the recognize-act cycle. It also holds the current time of the system. 

\subsubsection{Current Time}

The current time can be saved in a \verb|now/1| constraint. It is important that there is only one such constraint and that time increases monotonically.

Other modules can access the time only by a \verb|get_now/1| that only returns the current time saved in the \verb|now/1| constraint. The current time cannot be set from outside, but is determined by the last event dequeued from the priority queue.

\subsubsection{Recognize-Act Cycle}

As described before, the procedural module can only fire one rule at a time. When executing the RHS of a rule, all its actions are added to the scheduler with the time point when their execution is finished. For example: If on the RHS of the firing rule a retrieval request has to be performed, an event will be added to the priority queue with the time $Now + Duration$, so the chunk retrieved from the declarative memory will be written to the retrieval buffer at this time point.

After all events of the RHS have been added to the scheduler, the procedural module is free again and therefore the next rule can fire. The event of firing will be added to the priority queue as well by the \verb|fire| constraint at the end of each production rule. The rule will be added at the current time point, but with low priority, since it has to be ensured, that every action of the previously executed rule has been performed yet (in the sense that a corresponding event has been added at the specified time point). In many cases, no other rule will be applicable at this time, because most of the meaningful production rules have to wait for the results of the production rule before. 

Many of the buffer actions are performed immediately, so an event with the current time point is added for the buffer modifications or clearings. They are performed in a certain order defined by their priority as shown in table~\ref{tab:action_priorities}. The request actions are performed at last, but they perform a buffer clearing immediately and then start their calculation which can take some time. 

If no rule is applicable, the next time that a rule could be applicable is after having performed the next event. So, the next \verb|fire| event is scheduled directly after the first event in the queue. This simulates the behaviour that the procedural module stays ready to fire the next rule, without polling at every time point if a rule is applicable, but only reacting on changes to the buffer system. 


The following enumeration summarizes the recognize-act cycle with a scheduler:

\begin{enumerate}
 \item The next event is removed from the queue, the current time is set to the time of the event and the event is performed.
 \begin{enumerate}
 \item The dequeued event is a \verb|fire| constraint: The rule that matches all its conditions is fired and removes the \verb|fire| constraint.
 \item The actions of the rule are scheduled in the queue. Modifications and Clearings have the current time point, requests have a time point in the future depending on the module.
 \item The last action of the rule is to add a \verb|fire| constraint to the queue with the current time point and a low priority. This simulates that the procedural module is free again, after all in-place actions of a rule have been fired.
 \item There are two possibilities:
 \begin{enumerate}
  \item \emph{The next rule matches:} It will be performed like the last rule.
  \item \emph{No rule matches:} The next time, it could be possible that a rule can fire, is when something in the buffers changed. This only can happen, after the next event has been performed. So the next \verb|fire| event will be added to the queue by \verb|after_next_event| which has been described above.
 \end{enumerate}
  \end{enumerate}
 \item Go to point 1. This is performed until there are no events in the queue.
\end{enumerate}


The following parts are necessary to implement this cycle:

\paragraph{Start Next Cycle} 

The constraint \verb|nextcyc| leads the system to remove the next event from queue and perform it. Performing is done by a \verb|call_event| constraint:

\begin{lstlisting}
% After an event has been performed, nextcyc is triggered. 
%This leads to the next event in the queue to be performed.
nextcyc <=> de_q(Evt), call_event(Evt).
\end{lstlisting}

\paragraph{Call an Event} 

Event calling just takes a queue element and sets the current time to the time of the event and performs a Prolog \verb|call|. Additionally, a message is printed to the screen. After the event has been executed, the next cycle is initiated.

If the queue element is \verb|nil| (so no event has been in the queue), the computation is finished and the current time is removed.

\begin{lstlisting}
% no event in queue -> do nothing and remove current time
call_event(nil) \ now(_) <=> write('No more events in queue. End of computation.'),nl.

call_event(q(Time,Priority,Evt)), now(Now) <=> 
  Now =< Time | 
  now(Time),
  write(Now:Priority),
  write(' ... '),write('calling event: '), write(Evt),nl,
  call(Evt),
  nextcyc.
\end{lstlisting}

\paragraph{Changing the Buffer System}

For each buffer action, add a \verb|do_buffer_action| constraint, that actually performs the code specified in the former action. Modify the action as follows:

\begin{lstlisting}
% Schedule buffer_action
buffer_action(BufName, Chunk) <=> 
  get_now(Now),
  Time is Now + Duration, 
  add_q(Time, Priority, do_buffer_action(BufName, Chunk)). 
\end{lstlisting}

with appropriate values for \verb|Duration| and \verb|Priority|.

\paragraph{Production Rules}

As in the last version of the production system, each rule has the following structure:

\begin{lstlisting}
rule @
  {conditions} \ fire <=> {actions}, schedule_fire.
\end{lstlisting}

where schedule fire is defined as:

\begin{lstlisting}
schedule_fire <=> 
  get_now(Now),
  add_q(Now,0,fire).
\end{lstlisting}

As last production rule, there has to be a rule:

\begin{lstlisting}
no-rule @ 
  fire <=> no_rule.
\end{lstlisting}

which removes the fire constraint if still present and states that no rule has been fired (since the fire constraint is still present). In this case, a new \verb|fire| event is scheduled after the next event:

\begin{lstlisting}
no_rule <=> 
  write('No rule matches -> Schedule next conflict resolution event'),nl,
  after_next_event(do_conflict_resolution).
\end{lstlisting}

\section{Configuration}


\section{Subsymbolic Layer}

\subsection{Activation of Chunks}

\subsection{Production Utility}

