\chapter{Implementation of ACT-R in CHR}
\label{implementation}

After the overview of the ACT-R theory in chapter \ref{actr_description}, this chapter gives a more detailed survey and presents a possible implementation of the described concepts of the ACT-R theory in CHR, inspecting some implementational details of the theory and formalizing some basic concepts. Note that this work only regards the fundamental concepts of ACT-R and abstracts from some details. For example, the experiment environment as described in section~\ref{experiment_environment} is ignored.

For the implementation, some special cases and details that are not exactly defined in theory have to be considered. Hence, some concepts of the theory that are implemented in this work are formalized first. The implementation in form of CHR rules sticks to those formalisms and is often very similar to them.

Additionally, the implementation is described incrementally, i.e. first, a very minimal subset of ACT-R is presented that will be refined gradually with the progress of this chapter. In the end, an overview of the actual implementation as a result of this work is given. Some of the definitions in this chapter result directly from the theory, some of them needed a further analysis of the official ACT-R 6.0 Reference Manual \cite{actr_reference} or the tutorials \cite{actr_tutorial}. 

\section{Declarative and Procedural Knowledge}

The basic idea of the implementation is to represent declarative knowledge, working memory etc. as constraints and to translate the ACT-R production rules to CHR rules. This approach leads to a very compact and direct translation of ACT-R models to Constraint Handling Rules.

In addition to the production rules there will be rules that implement parts of the framework of ACT-R, for example rules that implement basic chunk operations like modifying or deleting chunks from declarative memory or a buffer. Those parts of the system are described as well as the central data structures and the translation.

First, a formalization of declarative knowledge in form of chunk networks and their implementation in CHR is given. Then, the working memory -- also referred to as the buffer system -- is explored and the implementation is discussed. After those definitions of the basic data structures of ACT-R, the procedural system is described including the translation of ACT-R production rules to CHR rules using the previously defined data structures. Furthermore, the reproduction of ACT-R's modular architecture is shown and the implementation of the declarative module is presented. After this overview of the basic concepts of ACT-R, the description goes into more detail about timing issues and the subsymbolic layer.

\section{Chunk Stores}
\label{implementation:chunk_stores}

Since chunks are the central data-structure of ACT-R used for representation of declarative knowledge, to exchange information between modules and to state requests, this section first deals with this essential part of ACT-R.

\subsection{Formal Representation of Chunks}

In multiple parts of ACT-R it is necessary to store chunks and then operate on them. Hence, the abstract data structure of such a chunk store is defined. Since chunk stores have been referred to as networks in the previous chapters, the general idea of this definition of a chunk store is based upon a relation that represents such a network.

\begin{definition}[chunk-store]
A \emph{chunk-store} $\Sigma$ is a tuple $(C,E,\mathcal{T},\rel{HasSlot},\rel{Isa})$, where $C$ is a set of chunks and $E$ a set of primitive elements both identified by unique names, with $C \cap E = \emptyset$. The \emph{values} of $\Sigma$ are defined by the set $V = C \cup E \cup \{ \mathtt{nil} \}$. $\mathcal{T}$ is a set of chunk-types. A chunk-type $T = (t,S) \in \mathcal{T}$ is a tuple with a \emph{unique}\footnote{$\forall (t,S), (t',S') \in \mathcal{T}: t = t' \Rightarrow S = S'$} type name $t$ and a set of slots $S$. The set of all slot-names is $\mathcal{S}$. 

$\rel{HasSlot} \subseteq C \times \mathcal{S} \times V$ and $\rel{Isa} \subseteq C \times \mathcal{T}$ are relations and are defined as follows:

\begin{itemize}
 \item $c \enspace \rel{Isa} \enspace T \Leftrightarrow$ chunk $c$ is of type $T$.
 \item $(c,s,v) \in \rel{HasSlot} \Leftrightarrow v$ is the value of slot $s$ of $c$. This can also be written as $c \overset{s}{\longrightarrow} v$ and is spoken ``$c$ is connected to $v$'' or ``$v$ is in the slot $s$ of $c$''.
\end{itemize}

The $\rel{Isa}$ relation has to be right-unique and left-total, so each chunk has to have exactly one type. The following functions are defined:
\begin{align*}
\fun{slots}: C \rightarrow \mathcal{S} \times V &\\
\fun{slots}(c) = \{ \enspace (s,v) \enspace | \enspace (c,s,v) \in HasSlot \enspace \}&\\
\\
\fun{slots}: \mathcal{T} \rightarrow \mathcal{S} &\\
      \fun{slots}((t,S)) = S&
\end{align*}
A chunk-store is \emph{type-consistent}, iff $\forall (c,(t,S)) \in \rel{Isa}: \forall s \in S \enspace \exists ! (c,s,v) \in \rel{HasSlot}$. So every chunk must have exactly one value for each slot of its type and only describe slots of its type. Empty slots are represented by the value \lstinline|nil|. Since every chunk has exactly one type, this is valid for all chunks in the store.

%iff $\forall(c,s,v) \in HasSlot: c \enspace Isa \enspace (T,S) \Rightarrow \exists s' \in S: s=s'$ and $\forall c \in C: \enspace c \enspace Isa \enspace (T,S) \Rightarrow \forall s \in S: \exists (c',s',v) \in HasSlot: c=c', s=s'$. 

\end{definition}


\begin{definition}[abstract methods of a chunk store]
\label{def:abstract_methods_chunk_store}
The following methods can be defined over a chunk store $\Sigma = (C, E, \mathcal{T}, \rel{HasSlot}, \rel{Isa})$:

\begin{description}
 \item[\texttt{chunk-type(name slot\textsubscript{1} \dots slot\textsubscript{n})}] is a method for defining a new type $T = (\mathtt{name},\{\mathtt{slot_1}, \dots, \mathtt{slot_n}\})$ which is added to the store, i.e. $\mathcal{T'} = \mathcal{T} \cup \{T\}$. 
 \item[\texttt{add-chunk(name isa type slot\textsubscript{1} val\textsubscript{1} \dots slot\textsubscript{n} val\textsubscript{n})}] adds a chunk specified by a name and a list of slot-value pairs to the store, i.e. $C' = C \cup \{ \mathtt{name} \}$, $\rel{Isa'} = \rel{Isa} \enspace \cup \enspace (\mathtt{name}, (\mathtt{type}, slots(\mathtt{type}))$ and $\rel{HasSlot'} = \bigcup_{i = 1}^n{\mathtt{(name,slot_i,val_i)}} \enspace \cup \enspace \rel{HasSlot}.$ Note that due to the expansion of $C$, the condition that $C$ and $E$ have to be disjoint may be violated. To fix this violation, the element can be removed from $E$: $E' = (E \cup C) - (E \cap C).$ 
 
 Additionally, a valid mechanism to restore type-consistency may be introduced: It might happen that not all slots are specified in the call of the \lstinline|add-chunk| method. Since it is claimed by the definition of $\rel{HasSlot}$ that for all slots $s$ of a chunk $c$ there must be a $(c,s,v) \in \rel{HasSlot}$, in implementations the unspecified slots are initialized as empty slots, represented by the empty value \lstinline|nil|. Furthermore, slots specified in the call of the method that are not a member of the chunk's type should cause an error to preserve type-consistency.
  \item[\texttt{alter-slot(name slot\textsubscript{1} val\textsubscript{1} \dots slot\textsubscript{n} val\textsubscript{n})}] changes the values of the specified slots of a chunk identified by its name to new values. Only existing slots can be altered, but the list of slot-value pairs may be a partial chunk-description. The values of the slots not in the list remain at their old values.
  \item[\texttt{remove-chunk(name)}] removes the chunk with the given name from $C$ and all of its occurrences in $\rel{Isa}$ and $\rel{HasSlot}$.
  \item[\texttt{return-chunk(name)}] gets a chunk name as input and returns a chunk specification, i.e. the name, type and all slot-value pairs of this chunk in the store.
\end{description} 
\end{definition}

\begin{example}
 \label{ex:addition_fact_formal}
 The addition-fact chunk in figure \ref{fig:chunk_addition_fact} and its chunk-type are defined as follows:
 
\begin{lstlisting}
chunk-type(addition-fact arg1 arg2 sum)
add-chunk(a isa addition-fact arg1 5 arg2 2 sum 7)
\end{lstlisting}
 
 This leads to the following chunk-store: 
 \begin{align*}
 (\{a\}, \{2, 5, 7\},\\ 
 \{(\var{addition\mbox{-}fact}, \{\var{arg_1}, \var{arg_2}, \var{sum}\})\},\\
 \{(a, \var{arg_1}, 5), (a, \var{arg_2}, 2), (a, \var{sum}, 7)\},\\
 \{(a, \var{addition\mbox{-}fact)}\}).
 \end{align*}
 Type consistency is checked as follows:
 \begin{align*}
 \fun{slots}(a) &= \{(\var{arg_1}, 5), (\var{arg_2}, 2), (\var{sum}, 7)\}\\
 \fun{slots}((\var{addition\mbox{-}fact},\{\var{arg_1}, \var{arg_2}, \var{sum}\}) &= \{\var{arg_1}, \var{arg_2}, \var{sum}\}
 \end{align*}
 Since the chunk $a$ defines values for all of the possible slots of the type $\var{addition\mbox{-}fact}$ and only those slots, the store is type-consistent.
\end{example}

\subsection{Representation of Chunks in CHR}

Declarative knowledge is represented as a network of chunks, defined by the two relations $\rel{Isa}$, specifying the belonging of a chunk to a type, and $\rel{HasSlot}$, specifying the slot-value pairs of a chunk. Those relations can be translated directly into CHR by defining the following constraints representing the relations and sets:

\begin{lstlisting}
:- chr_constraint chunk_type(+).
% chunk_type(ChunkTypeName)

:- chr_constraint chunk_type_has_slot(+,+).
% chunk_type_has_slot(ChunkTypeName, SlotName).
\end{lstlisting}

The \lstinline|chunk_type/1| constraint represents the set $\mathcal{T}$ of chunk-types in the store, but refers only to the chunk-type names. The set of slots of a chunk-type is specified by the \lstinline|chunk_type_has_slot/2| constraint, i.e. for a chunk-type $T \in \mathcal{T}$, with $T = (t, S)$, there exists a \texttt{chunk\_type(t)} and for every slot $s \in S$ there is a constraint \lstinline|chunk_type_has_slot(t,s)| in the constraint store.

For the chunks, the following constraints are defined:

\begin{lstlisting}
:- chr_constraint chunk(+,+).
% chunk(ChunkName, ChunkType)

:- chr_constraint chunk_has_slot(+,+,+).
% chunk_has_slot(ChunkName, SlotName, Value)
\end{lstlisting}

The \lstinline|chunk/2| constraint represents both the set $C$ of chunks and the $Isa$ relation, since the presence of a constraint \lstinline|chunk(c,t)| signifies that chunk \lstinline|c| is of a type $T = (\mathtt{t},S)$. The $HasSlot$ relation is represented by the \lstinline|chunk_has_slot(c,s,v)| constraint, which really is just a direct translation of an element $(c,s,v) \in HasSlot$.

Note that all values in the just presented constraints have to be ground. This is a demand claimed by the original ACT-R implementation and makes sense, since each value in a slot of a chunk is a real, ground value and the concept of variables does not have an advantage in this context, because every element that can be stored in the brain is assumed to be known by the brain.

Additionally, from the definition of a chunk store it is known that the $Isa$ relation has to be left-total. Therefore, for every chunk \lstinline|c| in the store, exactly one \lstinline|isa(c,t)| constraint has to be in the store. Due to type-consistency, for each \lstinline|chunk_type_has_slot(t,s)| constraint a \lstinline|chunk_has_slot(c,s,v)| constraint has to be defined. If it should be expressed that a chunk has an empty slot, the special chunk name \lstinline|nil| can be used as slot value to indicate that. Note that \lstinline|nil| must not be the name of a regular chunk or chunk-type.

\begin{example}
\label{ex:addition_fact_chr}
The chunk and chunk-type in example~\ref{ex:addition_fact_formal} are represented as:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)
\end{lstlisting}
\end{example}


\subsubsection{Distinction of Elements and Chunks}
\label{distinction_elements_chunks}

A chunk store distinguishes between a set of chunks $C$ and a set of elements $E$. For implementational reasons it can be helpful if there are only chunks in the system, because elements just behave like chunks with no slots. Hence, a chunk-type \lstinline|chunk| with no slots will be added automatically to the store. Each element $e \in E$ is added as a chunk of type \lstinline|chunk| to the set of chunks $C$. After this operation $E = \emptyset$, and for every former element $e$ of $E$: $e \in C$, $(e,(\var{chunk},\emptyset)) \in \rel{Isa}$. So $E$ is now represented by $\{ c \in C \enspace | \enspace c \enspace \rel{Isa} \enspace (\val{chunk},\emptyset) \}$ in the implementation.

\begin{example}
The chunk representation from example~\ref{ex:addition_fact_chr} is changed to:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk_type(chunk)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)

chunk(5,chunk)
chunk(2,chunk)
chunk(7,chunk)
\end{lstlisting}
\end{example}


\subsubsection{Simple Implementation of the Default Methods}
\label{chunk_specification}

To implement the methods in definition~\ref{def:abstract_methods_chunk_store}, first a data type for chunk specifications has to be introduced. From this specification the correct constraints modeling the chunk-store are added or modified. This data type is necessary to allow communication between implementationally independent modules which do not share a joint memory of constraints (or data in general) as the ACT-R theory suggests (see section~\ref{actr:modular_organization}). The modular organization and the communication between modules is described in section~\ref{implementation:modular_organization}. 

The straight-forward definition of a data type for chunk specifications is just to use the specification like in definition~\ref{def:abstract_methods_chunk_store}: In both ACT-R and the aforementioned definition, chunks are defined by a term \lstinline[language=,mathescape]|(name isa type slot$_\mathtt{1}$ val$_\mathtt{1}$ ... slot$_\mathtt{n}$ val$_\mathtt{n}$)| which basically is just a list in Lisp and specifies a chunk uniquely. Hence, a similar Prolog term can be used:

\begin{lstlisting}
:- chr_type chunk_def ---> nil; chunk(any, any, slot_list).
:- chr_type list(T) ---> []; [T | list(T)].
:- chr_type slot_list == list(pair(any,any)).
:- chr_type pair(T1,T2) ---> (T1,T2).
\end{lstlisting}

By the \lstinline|:- chr_type| directive, new types can be defined. For example, the definition of \lstinline|list| states that a list of type \lstinline|T| is either empty (\lstinline|[]|) or a term \lstinline+[X|Xs]+ where \lstinline|X| is a value of type \lstinline|T| and \lstinline|Xs| is a list of type \lstinline|T| itself. The first definition states that the type \lstinline|chunk_def| can be either the atom \lstinline|nil| or a term of the form \lstinline|chunk(Name,Type,SVP)| where \lstinline|Name| and \lstinline|Type| can be of any type and \lstinline|SVP| is a \lstinline|slot_list| which is an alias for a list of pairs and describes a list of slot-value pairs, i.e. a Prolog list of terms \lstinline|(S,V)|, where \lstinline|S| is the name of a slot and \lstinline|V| is an identifier for the value for this slot. This is the direct translation of the chunk-specification used in the definition, amended by the \lstinline|nil| construct, that may be needed for later purposes. 

The defined types can be used in the definitions of CHR constraints. The arguments of these constraints are then checked at runtime for the correct types. For example, the directive \lstinline|:- chr_constraint a(pair,any)| states that the constraint \lstinline|a| is expected to have a pair as its first argument and any type as second argument. The default methods can be implemented as follows:

\paragraph{add\_chunk} 

This method creates the chunks and elements of the chunk store. The set $E$ of elements is minimal, i.e. only elements that appear in the slots of a chunk but are not chunks themselves are members of $E$. However, the set $E$ is never constructed explicitly, but represented by chunks of the special type \lstinline|chunk| that provides no slots. So each value in the slot of a chunk that is added to the store and that is not an element of the chunk store yet, gets its own chunk of type \lstinline|chunk|. As soon as a chunk with the name of such a primitive element is added to the store, the chunk of type \lstinline|chunk| is removed from the store.

\begin{lstlisting}[caption={Rules for \texttt{add\_chunk}}, label=lst:add_chunk_rules]
% empty chunk will not be added
<<add_chunk(nil)>> <=> true.
  
% initialize all slots with nil
<<add_chunk(chunk(Name,Type, _)), chunk_type_has_slot(Type,S)>> ==> 
  chunk_has_slot(Name,S,nil).

% chunk has been initialized with empty slots -> actually add chunk
<<add_chunk(chunk(Name,Type, Slots))>> <=>
  do_add_chunk(chunk(Name,Type,Slots)).
\end{lstlisting}

First, all \lstinline|chunk_type_has_slot| constraints are added to the store and initialized with \lstinline|nil| as slot value. This leads to complete chunk specifications that are consistent to the type as demanded by a type-consistent chunk-store.

If all slots have been initialized, \lstinline|do_add_chunk| performs the actual setting of the real slot values:
  
\begin{lstlisting}[caption={Additional rules for adding chunks}]  
% base case
<<do_add_chunk(chunk(Name, Type, []))>> <=> 
  chunk(Name, Type). 

% overwrite slots with empty values
<<chunk(V,_) \ do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=>
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).

% overwrite slots with empty values  
<<do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=> 
  <<<V == nil>>> | % do not add chunk(nil,chunk)
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).  

% overwrite slots with empty values  
<<do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=> 
  <<<V \== nil>>> |
  chunk_has_slot(Name,S,V), 
  chunk(V,chunk), % no chunk for slot value found => add chunk of type chunk 
  
<<do_add_chunk(_)>> <=> false.
\end{lstlisting}

The first rule is the base case, where no slots have to be added any more. Then, as a last step the actual \lstinline|chunk| constraint of the chunk that is added to the store is created. The second rule deals with the case, that a slot-value pair has to be added with a value that is already described by a chunk. Then the \lstinline|nil|-initialized slot of this chunk is removed and replaced by another slot containing the actual value. 

The next rule ensures that the helper chunk specification \lstinline|nil| will not get a chunk in the store, even if it is in the slots of a chunk. Otherwise, if the value of the slot to be added is not \lstinline|nil|, the next rule can fire and the value of the previously \lstinline|nil|-initialized slot will be replaced with the actual value. Additionally, since the first rule obviously did not fire for this constellation, \lstinline|V| is a value different from \lstinline|nil| that does not have a chunk in the store. Hence, it must be a primitive element. Thus a new chunk of type \lstinline|chunk| is added to the store for this value as described in section~\ref{distinction_elements_chunks} (see page~\pageref{distinction_elements_chunks}). If no rule matches, the user tried to create a chunk with slots that are not specified in the chunk-type. This leads to an error.

On top of the rules in listing~\ref{lst:add_chunk_rules}, there must be added a rule that deletes a primitive element (i.e. a chunk of type \lstinline|chunk|), if the user introduces a real chunk with the name of this element:

\begin{lstlisting}[caption={Clean up primitive elements}]  
% delete chunk of Type chunk, if real chunk is added
<<add_chunk(chunk(Name,_,_))>> \ <<chunk(Name,Type)>> <=> 
  <<<Type == chunk>>> |
  true.
\end{lstlisting}


\paragraph{add\_chunk\_type}

The following rules create a new chunk type:

\begin{lstlisting}[caption={rules for \texttt{add\_chunk\_type}}]
<<add_chunk_type(CT, [])>> <=> 
  chunk_type(CT).
<<add_chunk_type(CT, [S|Ss])>> <=> 
  chunk_type_has_slot(CT, S), 
  add_chunk_type(CT, Ss).
\end{lstlisting}

\paragraph{alter\_slot}

This method replaces the value of an existing slot for a given chunk, but only if it is a valid slot for the chunk-type of the altered chunk.

\begin{lstlisting}
<<alter_slot(Chunk,Slot,Value), chunk_has_slot(Chunk,Slot,_)>> <=>
  chunk_has_slot(Chunk,Slot,Value).  
<<alter_slot(Chunk,Slot,Value)>> <=> false.
\end{lstlisting}

The first rule replaces the existing \lstinline|chunk_has_slot| constraint by a new one. This is called \emph{destructive assignment} as described in \cite[32]{fru_chr_book_2009}. The second rule only matches, if the first did not match (due to the refined operational semantics of CHR). This is only the case, if it is tried to alter a slot with a non-existing \lstinline|chunk_has_slot| constraint. However, since the chunk descriptions are complete, the slot cannot be valid for the type of the chunk and the altering has to fail.

\paragraph{remove\_chunk}

This method removes all occurrences of a chunk from the store. I.e., all \lstinline|chunk| and \lstinline|chunk_has_slot| constraints the chunk is involved in are removed.

\begin{lstlisting}
<<remove_chunk(Name)>> \ <<chunk(Name, _)>> <=> true.
<<remove_chunk(Name)>> \ <<chunk_has_slot(Name, _, _)>> <=> true.
<<remove_chunk(_)>> <=> true.
\end{lstlisting}

\paragraph{return\_chunk}

This method creates a chunk specification as defined in section~\ref{chunk_specification} from the chunk name of a chunk in the store.

\begin{lstlisting}[caption={rules for \texttt{return\_chunk}}]
<<chunk(ChunkName, ChunkType)>> \ <<return_chunk(ChunkName,Res)>> <=> 
  <<<var(Res)>>> | 
  build_chunk_list(chunk(ChunkName, ChunkType, []),Res).

<<chunk_has_slot(ChunkName, S, V)>> \ <<build_chunk_list(chunk(ChunkName, ChunkType, L), Res)>> <=> 
  <<<\+member((S,V),L)>>> | 
  build_chunk_list(chunk(ChunkName, ChunkType, [(S,V)|L]),Res).
  
build_chunk_list(X,Res) <=> Res=X.
\end{lstlisting}

The first rule creates the initial chunk specification with name and type set, but without any slot specification. This initial representation is handed to the \lstinline|build_chunk_list| constraint. The second rule adds a slot-value pair from the store to the list of slot-value pairs in the specification and builds the next chunk specification from this new representation. In the last rule, the process terminates if no other rule can fire any more. Then the result is bound to the handed specification.

\subsubsection{Checking Consistency and Type-Consistency}

At the moment, there are no rules that check the consistency of the chunk store. However, if the default methods for adding chunks are used, a type-consistent store is built automatically, since every chunk has exactly one chunk-type.\footnote{left-totality and right-uniqueness of $\rel{Isa}$} Furthermore, all slots from its chunk-type are described and only those slots are described (satisfies type-consistency). Additionally, there are no two different slot descriptions for the same chunk and every chunk in the store is described\footnote{This is demanded by the type-consistency: Since $\rel{Isa}$ is left-total, every chunk is in the $\rel{Isa}$ relation. Type-consistency demands, that every chunk in the $\rel{Isa}$ relation has a value for all slots of its type.} (satisfies the definition of a chunk-store). Rules for checking those constraints could be added easily to the implementation.

\section{Procedural Module}
\label{implementation:procedural_module}

The part of the system, where the computations are performed, is the procedural module. It is the central component that holds all the production rules, the working memory (in the buffer system) and organizes communication between modules (through buffers and requests). In the following, all of those subcomponents of the procedural module are described.

\subsection{Buffer System}
\label{implementation:buffer_system}

The buffer system can be regarded as a chunk-store that is enhanced by buffers. A buffer can hold only one chunk at a time. The procedural module has a set $B$ of buffers, a chunk-store $\Sigma$ and a relation between the buffers and the chunks in $\Sigma$.

\begin{definition}[buffer system]
\label{def:buffer_system}
A \emph{buffer system} is a tuple $(B,\Sigma,Holds)$, where $B$ is a set of buffers, $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$ a type-consistent chunk-store and $Holds \subseteq B \times (C \cup \{ \mathtt{nil} \})$ a right-unique and left-total relation that assigns every buffer at most one chunk that it holds. If a buffer $b$ is empty, i.e. it does not hold a chunk, then $(b,\mathtt{nil}) \in Holds$.

A buffer system is \emph{consistent}, if every chunk that appears in $Holds$ is a member of $C$ and $\Sigma$ is a type-consistent chunk-store.

A buffer system is \emph{clean}, if its chunk-store only holds chunks which appear in $Holds$.
\end{definition}

For the implementation of a buffer system, the code of a chunk-store can be extended by a \lstinline|buffer/2| constraint that encodes the set $B$ and the relation $Holds$ at once, since the relation is complete by definition.\footnote{$\forall b \in B \enspace \exists c \in (C \cup \{ \mathtt{nil} \}): (b,c) \in Holds$}

\subsubsection{Destructive Assignment and Consistency}
\label{destructive_assignment}

The demand of $Holds$ being right-unique\footnote{$\forall b \in B \enspace \forall c, d \in (C \cup \{ \mathtt{nil} \}): (b,c), (b,d) \in Holds \Rightarrow b = c$} is a form of destructive assignment as described in \cite[p. 32]{fru_chr_book_2009}, i.e. if a new chunk is assigned to a buffer, the old \lstinline|buffer| constraint is removed and a new \lstinline|buffer| constraint is introduced, holding the new chunk:

\begin{lstlisting}
<<set_buffer(B, C) \ buffer(B, _)>> <=> buffer(B, C).
\end{lstlisting}

This rule ensures that only one \lstinline|buffer| constraint exists for each buffer in $B$. At the beginning of the program, a \lstinline|buffer| constraint has to be added for all the available buffers of the modules. This problem is discussed in section~\ref{initialization}.

In addition, if a new chunk is put into a buffer, it also has to be present in the chunk-store, since the production system relies on the knowledge about the chunks in its buffers and chunks are essentially defined by their slots (\emph{consistency property} in definition~\ref{def:buffer_system}). Hence, every time a chunk is stored in a buffer, the \lstinline|add_chunk| method described in definition~\ref{def:abstract_methods_chunk_store} has to be called. However, the chunks in the slots are not loaded, since they are not present for working memory. They only appear as primitive elements in the chunk-store. Figure~\ref{fig:buffer_system} shows a buffer system which has two buffers. One of the buffers holds a chunk. Note, that the values $v_1$ and $v_2$ might be chunks themselves. However, their slots are not loaded to the chunk store and hence they only appear as primitive elements.

\begin{figure}[htb]
\centering
\tikzstyle{buffer} = [rectangle, draw, fill=yellow!20, 
    text width=5em, text centered, rounded corners, minimum height=3em]
\tikzstyle{chunk} = [circle, draw, fill=blue!20, text centered, text width=1em]
\tikzstyle{line} = [draw, -latex]

\begin{tikzpicture}[node distance=3cm,auto]
\matrix[row sep = 1cm] {
\node  {$B = \{$}; & 
\node[buffer] (b1) {$b_1$}; &
& \node[buffer] (b2) {$b_2$}; 
& \node {$\}$};
\\
\node  {$C = \{$}; & 
\node[chunk] (c) {$c$};
\node[chunk, below left of=c] (t) {$T$}; 
\node[chunk, below of=c] (v1) {$v_1$}; 
\node[chunk, below right of=c] (v2) {$v_2$}; 
\node[below of=t, node distance=9mm] {\parbox{2cm}{\centering \rotatebox{270}{$\in$} \\\vspace{1mm}$\mathcal{T}$}};
\node[below of=v1, node distance=9mm] {\parbox{2.5cm}{\centering \rotatebox{270}{$\in$} \\\vspace{1mm}$C \cup E \cup \{ \mathtt{nil} \}$}};
\node[below of=v2, node distance=9mm] {\parbox{2.5cm}{\centering \rotatebox{270}{$\in$} \\\vspace{1mm}$C \cup E \cup \{ \mathtt{nil} \}$}};
&
 \node {$\}$};
&
\node (nil) {$\mathtt{nil}$}; 
\\
};

\path[line] (b1) -- node[left] {$Holds$} (c);
\path[line] (b2) -- node[right] {$Holds$} (nil);
\path[line] (c) -- node[left] {$Isa$} (t);
\path[line] (c) -- node[left, near end] {$HasSlot$} (v1);
\path[line] (c) -- node {$s_1$} (v1);
\path[line] (c) -- node[right] {$HasSlot$} (v2);
\path[line] (c) -- node[left] {$s_2$} (v2);
\end{tikzpicture}
\caption{A buffer system $(B,\Sigma,Holds)$ with two buffers $b_1, b_2 \in B$ and a chunk store $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$. The relations $Holds$, $Isa$ and $HasSlot$ are illustrated by arrows. The buffer $b_1$ holds a chunk $c$ of type $T = (t,\{s_1, s_2\})$ and with values $v_1$ and $v_2$. Buffer $b_2$ is empty. The buffer system is clean, since only the chunks which are held by a buffer are in the set of chunks $C$ of the chunk store.}
\label{fig:buffer_system}
\end{figure}


%This process is discussed later when talking about buffer requests in section~\ref{buffer_requests}.

\subsubsection{Buffer States}

Another formal detail of the buffer system is that buffers can have various states: \emph{busy}, \emph{free} and \emph{error}. Those states represent the status of the underlying system, for example the state of the retrieval buffer is based on the current action or result of the declarative module's retrieval system.

A module is busy, if it is completing a request and free otherwise. Since a module can only handle one request at a time and requests may need a certain time (like the retrieval request for example), the procedural module could state another request to a busy module. This is called \emph{jamming} which leads to error messages and should be avoided. One technique to avoid module jamming is to \emph{query} the buffer state in the conditional part of a production rule \cite[unit 2, p. 9]{actr_tutorial}. The possibility to query buffer states is discussed in the next section.

A buffer's state is set to \emph{error}, if a request was unsuccessful because of an invalid request specification or, in case of the declarative module for instance, a chunk that could not be found. In CHR, a buffer state can be represented by a \lstinline|buffer_state(b,s)| constraint, which signifies that buffer \lstinline|b| has the state \lstinline|s|. Since every buffer has exactly one state all the time, it is required, that for every buffer there is such a constraint and it is ensured, that only one \lstinline|buffer_state| constraint is present for each buffer. This can be achieved by the destructive assignment method described in section~\ref{destructive_assignment}. 

At the beginning of the program, when a buffer is created (a \lstinline|buffer| constraint is placed into the store), a corresponding \lstinline|buffer_state| constraint has to be added. The initial state can be set to \lstinline|free|, since no request is being computed at the time of creation.

\subsection{Production Rules}
\label{implementation:production_rules}

Production rules consist of a \emph{condition} part and an \emph{action} part. Syntactically, in ACT-R the condition is separated from the action by \lstinline|==>|. Additionally, each production rule has a name. Thus, a rule is defined by:

\begin{lstlisting}
(p name condition* ==> action*)
\end{lstlisting}

The condition part is also called the \emph{left hand side} of a rule (LHS) and the action part is called \emph{right hand side} (RHS).

\subsubsection{The Left Hand Side of a Rule}

Generally, a condition is either a \emph{buffer test}, i.e. a specification of slot-value pairs that are checked against the chunk in the specified buffer or a \emph{buffer query}, i.e. a check of the state of a buffer's module (either busy, free or error). A buffer test on the LHS of a rule is indicated by a \lstinline|=| followed by the buffer name of the tested buffer; a query is indicated by a \lstinline|?| in front of the buffer name. The LHS of a rule may contain bound or unbound variables: \lstinline|=varname| is a variable with name \lstinline|varname|.

If the chunks in the buffers pass all buffer tests specified by the rule, the rule can fire, i.e. its right hand side will be applied. The LHS is a conjunction of buffer tests, i.e. there is no specific order for the tests \cite[p. 165]{actr_reference}.

\begin{example}[counting example -- left hand side]
The left hand side of the counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  ... )
\end{lstlisting}

\enlargethispage{-\baselineskip}

The condition part consists of two buffer tests:

\begin{enumerate}
 \item The goal buffer is tested for a chunk of type \lstinline|count| and a slot with name \lstinline|number|. The value of the slot is bound to the variable \lstinline|=n|.
 \item The retrieval buffer is tested for a chunk of type \lstinline|count-fact| that has the variable \lstinline|=n| in its \lstinline|first| slot (with the same value as the \lstinline|number| slot of the chunk in the goal buffer, since \lstinline|=n| has been bound to that value), and another value in its second slot which is bound to the variable \lstinline|=m|.
\end{enumerate}
\end{example}

\subsubsection{The Right Hand Side of a Rule}

For the right hand side of a rule the following actions are allowed:

\begin{description}
 \item[Buffer Modifications] of the form
\begin{lstlisting}
=buffer>
  s  v
  ...
\end{lstlisting}

They are indicated by the buffer modifier \lstinline|=| right before the buffer name and are specified through a list of slot-value pairs. Note that this list can be incomplete and must not contain a \lstinline|isa| specification. It leads to all slots mentioned in the modification action of a buffer being replaced by the specified values.

 \item[Buffer Requests] of the form
\begin{lstlisting}
+buffer>
  s  v
  ...
\end{lstlisting}

Requests are indicated by the buffer modifier \lstinline|+| and specified by a list of slot-value pairs. A request will be sent to the module of the specified buffer which reacts to the transmitted chunk of the request specification (in form of the slot-value pairs). The semantics of a request depends on the module, but the buffer is always first cleared before stating the request.
 \item[Buffer Clearings] of the form
 
\begin{lstlisting}
-buffer>
\end{lstlisting}

Clearings are indicated by the buffer modifier \lstinline|-|. When a buffer is cleared, the chunk it contains will be removed from the chunk-store of the buffer system and then be added to the declarative memory. 
\end{description}

\enlargethispage{-2\baselineskip}

\begin{example}[counting example]
\label{ex:counting}
The counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  =goal>
    number =m
  +retrieval>
    isa    count-fact
    first  =m
)
\end{lstlisting}
\end{example}

\subsubsection{Direct Translation of Buffer Tests}

An ACT-R production rule of the form

\begin{lstlisting}[mathescape]
(p name
  =buffer$_\mathtt{1}$>
    isa   type$_1$
    slot$_\mathtt{1,1}$  val$_\mathtt{1,1}$
    ...
    slot$_\mathtt{1,n}$  val$_\mathtt{1,n}$
  ...
  =buffer$_\mathtt{k}$>
    isa   type$_\mathtt{k}$
    slot$_\mathtt{k,1}$  val$_\mathtt{k,1}$
    ...
    slot$_\mathtt{k,m}$  val$_\mathtt{k,m}$
==>
... )
\end{lstlisting}

states formally, that: If $\var{buffer_1} \enspace \rel{Holds} \enspace c_1 \enspace \wedge \enspace c \enspace \rel{Isa} \enspace \var{type_1} \enspace \wedge \enspace c_1 \xrightarrow{\var{slot}_{1,1}} \var{val}_{1,1} \enspace \wedge \enspace \dots \enspace \wedge \enspace \var{buffer_k} \enspace \rel{Holds} \enspace c_k \enspace \wedge \enspace c_k \enspace \rel{Isa} \enspace \var{type_k} \enspace \wedge \enspace \dots$ is true, then the rule matches and the RHS should be performed. This can be directly translated into a CHR rule:

\begin{lstlisting}[mathescape]
<<<name>>> @
  <<buffer(buffer$_\mathtt{1}$,C$_\mathtt{1}$),
  chunk(C$_\mathtt{1}$,type$_\mathtt{1}$),
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,1}$,val$_\mathtt{1,1}$),
  ...
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,n}$,val$_\mathtt{1,n}$),
  ...
  buffer(buffer$_\mathtt{k}$,C$_\mathtt{k}$),
  chunk(C$_\mathtt{k}$,type$_\mathtt{k}$),
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,1}$,val$_\mathtt{k,1}$),
  ...
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,m}$,val$_\mathtt{k,m}$)>>
==>
  ...
\end{lstlisting}

This rule checks the buffer system for the existence of a buffer holding a particular chunk and then checks the chunk store of the buffer system for that chunk with the type and slots specified in the ACT-R rule. The rule is a propagation rule, because the information of the chunk-store should not be removed. If the values in the slot tests are variables, they can be directly translated to Prolog variables.

The CHR rule only fires, if all the checked buffers hold chunks that meet the requirements specified in the slot tests of the ACT-R rule. Since those slot-tests are just a conjunction of relation-membership tests and the CHR rule is a translation of these tests into constraints, both are equivalent. In detail: 

\begin{itemize}
 \item If a checked buffer \lstinline|b| holds no chunk, the constraint \lstinline|buffer(b,nil)| will be present, but the chunk store will not hold any of the required constraints \lstinline|chunk| or \lstinline|chunk_has_slot| and the rule will not fire.
 \item If a checked buffer \lstinline|b| holds a chunk, but the chunk does not meet one of the requirements in its slots, the rule does not fire.
 \item The rule only fires, if for all checked buffers there are valid \lstinline|buffer|, \lstinline|chunk| and \lstinline|chunk_has_slot| constraints present that meet all the requirements specified by the ACT-R rule.
 \item Variables on the LHS of a rule are bound to the values of the actual constraints that are tried for the matching. After the matching, each variable from the rule has a ground value bound to it, because there are no variables in the implementation of the buffer store. This corresponds to the semantics of an ACT-R production rule with variables on the LHS.
\end{itemize}

\subsubsection{Translation of Actions}
\label{translation_of_actions}

For each action type a constraint

\begin{lstlisting}
buffer_action(buffer,chunk-specification)
\end{lstlisting}

and the corresponding rules that handle the action have to be added. Note that the buffer action is defined by the action name, the buffer name and a chunk specification. That is because actions in ACT-R are defined through a buffer modifier that specifies the action, the name of the buffer and a list of slot-value pairs. Hence, this is a direct translation to CHR.

\paragraph{Buffer Modifications}

The modification of a buffer takes an incomplete chunk specification and modifies the given slots of the chunk in the specified buffer. This can be implemented as follows:

\begin{lstlisting}
<<buffer(BufName, OldChunk)>> \ <<buffer_change(BufName, chunk(_,_,SVs))>> <=>
  alter_slots(OldChunk,SVs).
\end{lstlisting}

This implementation uses a generalization of the \lstinline|alter_slot| method as described in definition~\ref{def:abstract_methods_chunk_store} and section~\ref{chunk_specification}:

\begin{lstlisting}  
<<alter_slots(_,[])>> <=> true.
<<alter_slots(Chunk,[(S,V)|SVs])>> <=> 
  alter_slot(Chunk,S,V),
  alter_slots(Chunk,SVs). 
\end{lstlisting}

Note that types cannot be changed. This corresponds to the grammar definition of ACT-R as presented in section~\ref{implementation:production_rule_grammar}.

\paragraph{Buffer Clearings}

When clearing a buffer, the chunk that was stored in the buffer will be removed from the chunk store and \lstinline|nil| will be written to the store. Additionally, the chunk is written to declarative memory.

\begin{lstlisting}
<<buffer_clear(BufName), buffer(BufName, ModName, Chunk)>> <=> 
  write_to_dm(Chunk), 
  delete_chunk(Chunk), 
  buffer(BufName, nil).
\end{lstlisting}

\lstinline|write_to_dm| handles the writing of the chunk to the declarative memory:

\begin{lstlisting}
<<write_to_dm(ChunkName)>> <=> return_chunk(ChunkName, ResChunk), add_dm(ResChunk).
\end{lstlisting}

where \lstinline|add_dm| is basically just a global wrapper for the \lstinline|add_chunk| method of the declarative memory and will be explained in section~\ref{global_method_for_adding_chunks}.

\paragraph{Buffer Requests} The buffer requests have to be handled a little bit differently from the other actions. Therefore, they will be explained in section~\ref{interface_for_module_requests}. The changes to the buffer system are presented in section~\ref{how_the_buffer_system_states_a_request} and an example implementation of the module request interface for retrieval requests is given in section~\ref{retrieval_requests}.


\begin{example}[counting example in CHR -- simple]
The production rule in example~\ref{ex:counting} can be translated to:

\begin{lstlisting}
<<<count-rule>>> @
  <<buffer(goal,C1), 
    chunk(C1,count),
    chunk_has_slot(number,N),
  buffer(retrieval,C2),
    chunk(C2,count-fact),
    chunk_has_slot(first,N),
    chunk_has_slot(second,M)>>
==>
  buffer_change(goal,chunk(_,_,[(number,M)])),
  buffer_request(retrieval,chunk(_,count-fact,[first,M)])).
\end{lstlisting}

\end{example}


\subsubsection{Translation of Buffer Queries}

A buffer query

\begin{lstlisting}
...
?buffer>
  state  bstate 
...
==> ...
\end{lstlisting}

on the LHS of a production rule can be translated to the following CHR rule head:

\begin{lstlisting}
...
<<buffer_state(buffer,bstate)>> ... ==> ...
\end{lstlisting}

\subsection{The Production Rule Grammar}
\label{implementation:production_rule_grammar}

The discussed concepts lead to the following grammar for production rules, which is a simplified version of the actual grammar used in the original ACT-R implementation \cite[p. 162]{actr_reference}. Some of the details in this grammar that have not been discussed yet are presented in the following sections.


\begin{lstlisting}[caption={The ACT-R production rule grammar}, label=lst:production_rule_grammar, basicstyle={\sffamily}, morekeywords={::=}, columns=flexible, mathescape]
$\textrm{production-definition}$ ::= (p name condition$^\textrm{*}$ ==> action$^\textrm{*}$)
name ::= a symbol that serves as the name of the production for reference
condition ::= [ $\textrm{buffer-test}$ | query ]
action ::= [$\textrm{buffer-modification}$ | request | $\textrm{buffer-clearing}$ | output ]
$\textrm{buffer-test}$ ::= =$\textrm{buffer-name}$> isa $\textrm{chunk-type}$ $\textrm{slot-test}$$^\textrm{*}$
$\textrm{buffer-name}$ ::= a symbol which is the name of a buffer
$\textrm{chunk-type}$ ::= a symbol which is the name of a $\textrm{chunk-type}$ in the model
$\textrm{slot-test}$ ::= {$\textrm{slot-modifier}$} $\textrm{slot-name}$ $\textrm{slot-value}$
$\textrm{slot-modifier}$ ::= [= | - | < | > | <= | >=]
$\textrm{slot-name}$ ::= a symbol which names a possible slot in the specified $\textrm{chunk-type}$
$\textrm{slot-value}$ ::= a variable or any Lisp value
query ::= ?$\textrm{buffer-name}$> $\textrm{query-test}$$^\textrm{*}$
$\textrm{query-test}$ ::= {-} $\textrm{queried-item}$ $\textrm{query-value}$
$\textrm{queried-item}$ ::= a symbol which names a valid query for the specified buffer
$\textrm{query-value}$ ::= a $\textrm{bound-variable}$ or any Lisp value
$\textrm{buffer-modification}$ ::= =$\textrm{buffer-name}$> $\textrm{slot-value-pair}$$^\textrm{*}$
$\textrm{slot-value-pair}$ ::= $\textrm{slot-name}$ $\textrm{bound-slot-value}$
$\textrm{bound-slot-value}$ ::= a bound variable or any Lisp value
request ::= +$\textrm{buffer-name}$> isa $\textrm{chunk-type}$ $\textrm{request-spec}$$^\textrm{*}$
$\textrm{request-spec}$ ::= {$\textrm{slot-modifier}$} $\textrm{slot-value-pair}$
$\textrm{request-parameter}$ ::= a Lisp keyword naming a request parameter provided by the buffer specified
$\textrm{buffer-clearing}$ ::= -$\textrm{buffer-name}$>
variable ::= a symbol which starts with the character =
output ::= !output! [ $\textrm{output-value}$ ]
$\textrm{output-value}$ ::= any Lisp value or a $\textrm{bound-variable}$
$\textrm{bound-variable}$ ::= a variable which is used in the $\textrm{buffer-test}$ conditions of the production (including a variable which names the buffer that is tested in a $\textrm{buffer-test}$ or is bound with an explicit binding in the production
\end{lstlisting}

\subsubsection{The Order of Rule Applications}
\label{implementation:rule_application_order}

In the current translation scheme, the order of the rule applications does not match the semantics as described in the ACT-R theory.\footnote{see section~\ref{procedural_knowledge}} Consider the following rules in a compact notation:

\begin{lstlisting}
=b1>
  isa foo
  s1  v1
==>
=b1>
  s1  v2
=b2>
  s   x
\end{lstlisting}

and

\begin{lstlisting}
=b1>
  isa foo
  s1  v2
==>
=b2>
  s   y
=b1>
  s1  v3 % for termination
\end{lstlisting}

In the semantics of ACT-R, if the first rule matches, all the buffer modifications are performed first. After that, the procedural module can search for the next matching rule, which is the second one (due to the result of the first rule). This rule then would overwrite the value \lstinline|x| in the \lstinline|s| slot of buffer \lstinline|b2| with \lstinline|y|.

\begin{lstlisting}
<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)>>
==>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])).

<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)>>
==>
buffer_change(b2,chunk(_,_,[(s,y)])),
buffer_change(b1,chunk(_,_,[(s1,v3)])). % this is for termination
\end{lstlisting}

For the query

\begin{lstlisting}
?- chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c).
\end{lstlisting}

the result would be

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c2,s,x)
chunk_has_slot(c,s1,v3)
\end{lstlisting}

I.e., the buffer \lstinline|b2| holds the chunk with value \lstinline|x|. This is due to the fact, that after the first rule has modified the buffer \lstinline|b1|, the second rule matches and will be fired immediately, which then changes the value of \lstinline|b1| to \lstinline|y|. Afterwards, the second action of the first rule will be executed and the \lstinline|s| slot of the chunk in buffer \lstinline|b2| will be overwritten with \lstinline|x|.

Hence, somehow the fact that the procedural module is busy and cannot fire another rule has to be modeled. This can be achieved by a simple phase constraint \lstinline|fire| that will be added after the complete execution of a rule and will be removed as soon as a rule is executed.

For every production rule, the rule

\begin{lstlisting}
{ buffer_tests } ==> { actions }
\end{lstlisting}

has to be changed to a simpagation rule

\begin{lstlisting}
{ buffer_tests } \ <<fire>> <=> { actions }, fire.
\end{lstlisting}

It is important that the adding of \lstinline|fire| is the last action of a rule.

The example would be modified as follows:

\begin{lstlisting}
<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)
  \ fire>>
<=>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])),
fire.

<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)
  \ fire>>
<=>
buffer_change(b2,chunk(_,_,[(s,y)])),
fire.
\end{lstlisting}


The test query

\begin{lstlisting}
?- chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c), fire.
\end{lstlisting}

yields

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c,s1,v3)
chunk_has_slot(c2,s,y)
fire
\end{lstlisting}

The fire constraint has to be added at the end of the query. This ensures the correct semantics and a completely constructed buffer system.\footnote{This was actually the reason why in the first example without the \texttt{fire} constraint the buffer \texttt{b1} was created at the end of the query: If it would be created at an earlier point, the first rule would have matched immediately and the computation would have yielded a different result.}

In appendix~\ref{app:ex:rule_order} a minimal executable example is provided.

\subsubsection{Bound and Unbound Variables}
\label{bound_and_unbound_variables}

According to the ACT-R production rule grammar in listing~\ref{lst:production_rule_grammar}, unbound variables can only appear on the left hand side of a rule. Hence, no new variables are introduced on the right hand side. Since all the elements in the buffer store are completely described and ground, every variable on the LHS of a rule will be bound to a ground value. This simplifies the rule selection and application process a lot, since every value of the calculation is known after the matching. This enables simple implementations of arithmetic tests, for example (see section~\ref{slot_modifiers}).

\subsubsection{Duplicate Slot Tests}
\label{implementation:duplicate_slot_tests}

A problem that has not been addressed yet is that ACT-R allows buffer tests like the following:

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  spam
\end{lstlisting}

In the logical reading, this would signify that $buffer \enspace Holds \enspace c \enspace \wedge \enspace c \enspace Isa \enspace foo \enspace \wedge \enspace c \xrightarrow{bar} spam \enspace \wedge \enspace c \xrightarrow{bar} spam$ which is equivalent to the test with only one check of the \lstinline|bar| slot.\footnote{$x \wedge x = x$}

However, in CHR the following rule head resulting from the simple translation scheme would not match:

\begin{lstlisting}
buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,bar,spam),
  chunk_has_slot(C,bar,spam)
\end{lstlisting}

Because there are no two identical \lstinline|chunk_has_slot| constraints in the store, the rule could not fire. I.e. the list of slot tests in ACT-R is interpreted as a set of conditions, whereas CHR rules operate on a multi-set of constraints. However, the semantics of CHR can be changed to a set-based semantics. The first approach to implement a set-based semantics is to simply eliminate the duplicate test:

However, this does not do the trick for all possible cases. For example, suppose a test

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  =x
\end{lstlisting}

where the second test refers to a variable (or even both tests are variables). This problem could be solved by adding a guard to the rule from the simple translation:

\begin{lstlisting}
<<buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)>>
==> <<<spam == X>>> | ...
\end{lstlisting}

Since \lstinline|X| must be bound after the matching,\footnote{see section~\ref{bound_and_unbound_variables}} the test will always give the correct result. This also works for the first example, where the test would be \lstinline|spam == spam|, which is always true and hence could be reduced to the rule with the second test eliminated and no guard.\footnote{true guards can always be reduced}

It also works if the two slot-tests were contradictory, for example: 

\begin{lstlisting}
bar  spam
bar  eggs
\end{lstlisting}

would describe a rule that never can fire. The translation models exactly this behaviour:

\begin{lstlisting}
<<buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)>>
==> <<<spam == eggs>>> | ...
\end{lstlisting}

since the built-in syntactic-equality test of Prolog would never return true for those two constants.

This approach is essentially the same as \citeauthor{chr_lecture_chap6} suggests in chapter~6 of the accompanying slides to his book \cite{fru_chr_book_2009}: For each multi-headed rule, new rule variants are added. Those variants are produced by a pairwise unification of the constraints in the head which eliminates one of the unifiable head constraints \cite{chr_lecture_chap6}. For example, consider the rule:

\begin{lstlisting}
a(1,Y), a(X,2) ==> b(X,Y).
\end{lstlisting}

The constraints \lstinline|a(1,Y)| and \lstinline|a(X,2)| can be unified to \lstinline|a(1,2)|. Therefore the following rule is added:

\begin{lstlisting}
a(1,2) ==> b(1,2).
\end{lstlisting}

Since in ACT-R all variables in the head of a rule have to be bound, this scheme can be simplified to a simple guard-check and the elimination of duplicate slot tests. Hence, no rule variants have to be added, but the rules containing duplicate slot tests are modified.

\subsubsection{Slot Modifiers}
\label{slot_modifiers}

In ACT-R, slot-tests can be preceded by \emph{slot modifiers}. Those modifiers allow to specify tests like inequality (\lstinline|-|) or arithmetic comparisons (\lstinline|<, >, <=, >=|) of the slot value of a chunk with the specified variable or value. Since the slots in a chunk store are always fully defined with ground values, those tests are decidable.

If no slot modifier is specified in a slot test, the default modifier \lstinline|=| is used, that states that the chunk in the specified buffer must have the specified value in the specified slot. This default semantics has been used in the previous sections when translating simple ACT-R rules to CHR and is performed automatically by the matching of CHR.

To translate the other slot modifiers to CHR, another CHR mechanism can be used: Guards. Since the allowed modifiers are all default built-in constraints,\footnote{i.e. Prolog predicates} a slot test with a modifier

\begin{lstlisting}
...
=buffer>
  ...
  ~slot  val
...
==>
\end{lstlisting}

where \lstinline|~| stands for one of the modifiers in \{ \lstinline|=,-,<,>,<=,>=| \} can be translated as follows:

\begin{lstlisting}
<<buffer(buffer,C),
  ...
  chunk_has_slot(C,slot,V),
  ...>>
==>
  <<<V # val>>> |
  ...
\end{lstlisting}

where \lstinline|#| is the placeholder for the built-in constraint that computes the test specified by \lstinline|~| and \lstinline|V| is a fresh variable that has not been used in the rule, yet.

For arithmetic slot modifiers the values being compared have to be numbers. If a value is not a number, the arithmetic test will fail and the rule cannot be applied \cite{actr_reference}.

Note that slot tests with modifiers other than \lstinline|=| do not bind variables, but only perform simple checks, like it is with guards in CHR. If \lstinline|val| is an unbound variable and is never bound to a value on LHS, the default implementation throws a warning, and the rule will not match. Therefore, to handle this case, the rule translation scheme has to be extended by an additional guard check \lstinline|ground(Val)|, where \lstinline|Val| is the Prolog variable that replaces each occurrence of the variable \lstinline|val|.

As with normal slot tests, it is important to mention that if there are several tests on the same slot, the \lstinline|chunk_has_slot| constraint must appear only once on the LHS of the CHR rule, since every slot-value pair is unique in the constraint store. Ie., if the first slot test of a particular slot appears on the LHS of the ACT-R rule, a \lstinline|chunk_has_slot| constraint has to be added to the LHS of the CHR rule. For every other occurrence of this slot in a slot test, only guard checks are added.

\begin{example}
To clarify the details of the matching concept in ACT-R, here are some examples and their behaviour:

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
\end{lstlisting}

will throw a warning when loading the model. When running it, the rule will never fire, since no chunk value will match the inequality to the unbound variable \lstinline|bar|.

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
  eggs   =bar
\end{lstlisting}

will fire, if there is a chunk whose value in \lstinline|eggs| is different from the value in \lstinline|spam|.

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
\end{lstlisting}

matches for every value of the spam slot. The translation to CHR is:

\begin{lstlisting}
<<buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar)>>
==>
  <<<Bar=Eggs>>> | ...
\end{lstlisting}

In this case, a binding occurs in the guard, which is usually unwanted. However, since the \lstinline|Eggs| variable is unbound and therefore a fresh variable introduced in the guard, it is allowed and does not harm the matching process. It is even necessary to bind \lstinline|Eggs| to \lstinline|Bar| because of the semantics of the equivalent ACT-R rule. The following example is a little bit different: The rule

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
  ham   =eggs
\end{lstlisting}

will match all chunks which have the same value in \lstinline|spam| and \lstinline|ham|. This translates to

\begin{lstlisting}
<<buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar),
  chunk_has_slot(C,spam,Eggs)>>
==>
  <<<Bar==Eggs>>> | ...
\end{lstlisting}

Note that in this case, no binding occurs, since both, \lstinline|Bar| and \lstinline|Eggs|, already occur in the head of the rule and are bound to some value. Hence, the test in the guard can be reduced to a simple syntactic equality test without binding (\lstinline|==|).

\end{example}

\paragraph{Relation to Negation-as-Absence}

The concept of negation-as-absence as described in \cite[147\psqq]{fru_chr_book_2009} is provided by many production rule systems. It enables the programmer to negate a fact in the sense that the fact is not explicitly in the store and therefore the rule is applicable -- so the programmer asks for the absence of a particular fact.

At the first glance, the slot modifiers seem to implement this concept, but this is not the case: All negated slot tests in ACT-R can be reduced to simple built-in guard checks, because the chunks in the store are always described completely and the values are ground, so simple built-in checks work automatically. This also works for invalid slot-tests that ask for slots which are not offered by the chunk-type they ask for. Then there will never be a constraint matching the head of the rule due to type consistency. With these restrictions, ACT-R avoids the problems that come with negation-as-absence as they are explained in \cite[147\psqq]{fru_chr_book_2009} and the translation of such tests to CHR is very simple.

\subsubsection{Empty Slots}
\label{empty_slots}

An important special case in the semantics of ACT-R production rules is that if there is a slot test specified, a potential chunk only matches if it really has a value in this slot. Chunks that have \lstinline|nil| in a slot specified in a buffer test will not match the test. Hence, variables can not be used to test if two slots have the same value and the value is \lstinline|nil|, since every positive slot test involving \lstinline|nil| fails automatically \cite[p. 164, section ``Variables'', last sentence]{actr_reference}.

In CHR this special case can be handled by adding a guard for each variable occurring in a positive slot-test checking that this variable does not equal \lstinline|nil|. For negated slot tests, this is not the case: 

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  4
\end{lstlisting}

matches also a chunk with an empty \lstinline|spam| slot (\lstinline|nil| in its \lstinline|spam| slot).

\subsubsection{Outputs}

The production system of ACT-R also provides methods to produce side-effects. In this work, only a subset of those methods is concerned: the outputs. Outputs can appear on the right hand side of an ACT-R rule:

\begin{lstlisting}
=buffer>
  isa  foo
==>
  !output! (a1 a2 a3)
\end{lstlisting}

The argument of such an output call is a list of Lisp-symbols, so it is possible to hand variables or terms.

This mechanism can be translated to Prolog directly:

\begin{lstlisting}
output([]).
output([X|Xs]) :-
  write(X),nl,
  output(Xs).
\end{lstlisting}

The \lstinline|Xs| have to be Prolog terms. In ACT-R, function calls like \lstinline|!eval!| or \lstinline|!bind!| are allowed, but are ignored in this work.

\section{Modular Organization}
\label{implementation:modular_organization}

By now, all components of the implementation have been assumed to be in one file: buffer system, production rules, declarative memory, \dots This leads to problems like name space pollution and duplicate code, since, e.g. both the buffer system and the declarative memory use different chunk stores, which have the same behaviour but different data. It would be practical to reuse this code in both modules, but keeping the stores separated. Additionally, the code is better readable and it is easier to add new modules if a program is distributed over multiple files. Finally, the ACT-R architecture already proposes a modular organization, so it seems likely to adopt this idea of a modular architecture.

The term \emph{module} is highly overloaded: In ACT-R it describes independent parts of human cognition, whereas in the world of programming the term is used in a slightly different manner. In the following, implementational modules will always be named explicitly as \emph{Prolog modules}.

Nevertheless, the modular organization of ACT-R with its independent modules can be implemented by defining a Prolog module for each ACT-R module and adding some other modules around them. In the following, the concept of Prolog modules is explained.

\subsection{Prolog Modules}

Defining a new module creates a new namespace for all CHR constraints and Prolog predicates, which is illustrated in the following example:

\begin{example}[Prolog Modules and CHR]

In this example, two modules \lstinline|mod1| and \lstinline|mod2| are defined, with partially overlapping constraints. \lstinline|mod2| exports the constraint \lstinline|c|. In the following, the behaviour and interaction of the modules is explored.

\begin{lstlisting}[caption={Definition of Module 1},label=lst:mod1]
:- module(mod1,[]).
:- use_module(library(chr)).
:- use_module(mod2).
:- chr_constraint a/0, b/0.

<<a>> <=> c.
\end{lstlisting}

\begin{lstlisting}[caption={Definition of Module 2},label=lst:mod2]
:- module(mod2,[c/0]).
:- use_module(library(chr)).
:- use_module(mod1).
:- chr_constraint a/0, b/0, c/0. 

<<a>> <=> b.
<<b>> <=> mod1:a.
\end{lstlisting}


In this definition, two new modules \lstinline|mod1| and \lstinline|mod2| are created and only the \lstinline|c| constraint of \lstinline|mod2| is exported, indicated by the lists in the module definitions. The modules import each other.

The CHR constraint \lstinline|a| in listing~\ref{lst:mod1} is internally represented as \lstinline|mod1:a|, so it lives in its own namespace and does not pollute other namespaces. The constraint can appear on the right hand side of rules of other modules, but has to be called explicitly with its full namespace identifier. In line~8 of listing~\ref{lst:mod2}, the presence of the local \lstinline|a| constraint leads the rule to fire and \lstinline|mod2:a| is replaced by \lstinline|mod2:b|, which leads the rule in line~9 to fire and replaces the local \lstinline|mod2:b| constraint by an external \lstinline|mod1:a| constraint. So, external constraints can be called by their complete identifiers. However, on the left hand side of a rule, only the constraints local to the current module can appear. 

Exported constraints can only appear once in a program, since they can be called without their namespace definition, which is demonstrated in line~8 of listing~\ref{lst:mod1}, where \lstinline|mod2:c| is called in \lstinline|mod1| without referring to \lstinline|mod2| explicitly.
\end{example}

\subsection{Interface for Module Requests}
\label{interface_for_module_requests}

The architecture of ACT-R provides an infrastructure for the procedural module to state requests to all the other modules. To implement this concept as general as possible, an interface has to be defined which allows the adding of new modules to the system by just implementing this interface. Later on, the interface will be refined.

\begin{lstlisting}[caption={Simple Interface \emph{IModule}},label=lst:interface_module]
module_request(+BufName,+Chunk,-ResChunk,-ResState)
\end{lstlisting}

The arguments of such a request are:

\begin{description}
 \item[BufName] The name of the requested buffer, e.g. \lstinline|retrieval|.
 \item[Chunk] A chunk specification that represents the arguments of the request. The form of the allowed chunk specifications and the semantics of the request are module-dependent. For example: \lstinline|chunk(_,t,[(foo,bar),(spam,eggs)])| could describe a chunk, that should be retrieved from declarative memory.
\end{description}

The request provides the following result:

\begin{description}
 \item[ResChunk] The resulting chunk in form of a chunk specification. The actual result and its semantics depend on the particular module.
 \item[ResState] The state of the buffer after the request. For example, if no matching chunk could be retrieved from declarative memory, the state would be \lstinline|error|.
\end{description}

\subsection{Requests by the Buffer System}
\label{how_the_buffer_system_states_a_request}

Every module that can handle a request implements the interface in listing~\ref{lst:interface_module}. When the buffer system gets a call \lstinline|buffer_request(buffer,chunk-specification)|, it simply can call the \lstinline|module_request| method of the corresponding module. This can be achieved by \lstinline|ModName:module_request(...)|, where \lstinline|ModName| is the name of the corresponding module.

Hence, the buffer system must know which buffer belongs to which module. The \lstinline|buffer/2| constraint therefore has to be extended to a \lstinline|buffer/3| constraint, that also holds the module name of its module:

\begin{lstlisting}
buffer(BufName,ModName,Chunk)
\end{lstlisting}

A buffer request can now be handled as follows:

\begin{lstlisting}[caption={Retrieval Request in CHR}, label=lst:retrieval_request_symbolic]
<<buffer(BufName, ModName, _) \ buffer_request(BufName, Chunk)>> <=>
  set_buffer_state(BufName,busy),
  % clear buffer immediately
  buffer_clear(BufName), 
  % send request
  ModName:module_request(BufName, Chunk, ResChunk,ResState),
  
  % Apply result of the request
  % case 1: resulting state is error
  (ResState=error, 
  buffer(BufName, ModName, nil),
  set_buffer_state(BufName,error) ;
  
  % case 2: no errors occured
  ResState = free,
  ResChunk = chunk(ResChunkName,_,_),
  add_chunk(ResChunk), 
  buffer(BufName, ModName, ResChunkName),
  set_buffer_state(BufName,free)).
\end{lstlisting}

When getting a buffer request, the buffer state is set to \lstinline|busy| first. Then the buffer is cleared immediately, which leads the chunk in the buffer being added to the declarative memory. Then the module request is stated according to the interface. If the resulting state is \lstinline|error|, then the buffer gets this state and the content of the buffer is \lstinline|nil|, otherwise, if the resulting state is \lstinline|free|, the result will be added to the buffer and the state will eventually be set to \lstinline|free|.  It is important to mention, that the received chunk will be created explicitly in the chunk store of the buffer system and therefore is a copy of a possibly existing identical chunk in the module that has been requested.

\subsection{Components of the Implementation}
\label{implementation:components}

As mentioned before, the implementation is divided into modules which provide and require interfaces. Figure~\ref{fig:component_diagram} gives an overview of the architecture of the implementation as a component diagram. The main component is the \emph{model} which consists of \emph{user-defined rules}, that is the translated production rules as described in section~\ref{implementation:production_rules} and the ACT-R core. The core consists of the \emph{buffer system} (see section~\ref{implementation:buffer_system}) which implements a \emph{chunk-store} (see section~\ref{implementation:chunk_stores}) and a module \emph{stdlisp} which is capable of handling default lisp functions as described in section~\ref{lisp_functions}. The interface \emph{ICore} consists of the buffer interface -- which basically offers the access to the buffers and its contents for the matching and the buffer actions -- and the Lisp function interface as described in the aforementioned sections. Additionally, the core provides the constraints \lstinline|fire/0| and \lstinline|apply_rule/1| for reasons described in section~\ref{implementation:icore_interface} on page~\pageref{implementation:icore_interface}. Furthermore, the core uses the \emph{scheduler} module which provides the \emph{IScheduler} interface described in section~\ref{implementation:scheduler} and defined in definition~\ref{def:ischeduler}. The configuration and the \emph{IConfiguration} and \emph{IObserver} interfaces are described in section~\ref{configuration}. Finally, the interface \emph{IModule} which is implemented by every ACT-R module (and in this case especially by the \emph{declarative module}) is described in a simplified version in listing~\ref{lst:interface_module} and in its final version in listing~\ref{lst:imodule_final}.

It is important to mention, that in the figure, each component which is included in another component signifies that the corresponding Prolog file is textually included to the parent component. The interfaces in the figure indicate that the component is a Prolog module which is included by the use of \lstinline|use_module|. The constraints defined in such a standalone component are not accessible for the other components. An exception is the component of the \emph{user-defined rules} which -- in the current version -- textually includes the \emph{core}.

\begin{figure}[htbp]
\centering
 \begin{tikzpicture}
\begin{umlcomponent}{model}
  \umlbasiccomponent[y=1.5]{user-defined rules}
  \begin{umlcomponent}[x=5]{core}
    \begin{umlcomponent}[y=-3]{buffers}
        \umlbasiccomponent{chunk-store}
    \end{umlcomponent}
    \umlbasiccomponent[x=1.5,y=1]{stdlisp}
  \end{umlcomponent}
\end{umlcomponent}

\begin{umlcomponent}[y=-8, x=5]{declarative module}
        \umlbasiccomponent{chunk-store}
\end{umlcomponent}

\umlbasiccomponent[x=-0.8,y=-8]{scheduler}
\umlbasiccomponent[x=5, y=-12]{configuration}


%\umlrequiredinterface[distance=2cm, interface=IScheduler]{model}
%\umlprovidedinterface[interface=IScheduler]{scheduler}

\umlVHVassemblyconnector[interface=IScheduler, distance=3cm, with port, anchor1=south west, anchor2=north]{model}{scheduler}
\umlport{core}{west}
\umlassemblyconnector[anchor1=south west, anchor2=west]{model}{core}

\umlassemblyconnector[padding=2cm,with port, interface=IObserver, anchor1=south west,anchor2=-230]{declarative module}{configuration}
\umlassemblyconnector[with port, interface=IConfiguration, anchor1=south east, anchor2=-310]{declarative module}{configuration}
\umlVHassemblyconnector[with port, interface=IConfiguration, anchor1=240, anchor2=west]{model}{configuration}

\umlVHVassemblyconnector[anchor1=south, anchor2=70,with port, interface=IAddDM]{model}{declarative module}
\umlport{core}{295}
\umlassemblyconnector{model-south-port}{core-295-port}
\umlassemblyconnector{core-295-port}{buffers-south-port}
\umlVHVassemblyconnector[arm1=3.3cm]{core-295-port}{stdlisp-south-port}

\umlport{model}{250}

\umlport{buffers}{west}
\umlport{core}{217}
\umlHVassemblyconnector{buffers-west-port}{model-250-port}
\umlport{declarative module}{140}
\umlVHassemblyconnector[interface=IModule]{model-250-port}{declarative module-140-port}

\umlport{core}{155}
\umlport{user-defined rules}{east}
\umlHVHassemblyconnector[interface=ICore]{user-defined rules-east-port}{core-155-port}

\umlassemblyconnector[interface=IBuffers]{core-155-port}{buffers-north-port}
\umlport{stdlisp}{west}
\umlassemblyconnector[interface=ILispFunctions]{core-155-port}{stdlisp-west-port}

\end{tikzpicture} 
\caption{UML-Component Diagram of the implementation}
\label{fig:component_diagram}
\end{figure}


\section{Declarative Module}

The Declarative Module is a \emph{chunk store}, that additionally implements the \emph{module} interface. Therefore some rules to handle requests that find certain chunks in the chunk store have to be implemented. The chunk-store is separated from the buffer system which has its own chunk-store. Hence, all chunks requested by the buffer system from the declarative module are copies and therefore changes on those chunk do not affect the chunks in the declarative memory directly.

\subsection{Global Method for Adding Chunks}
\label{global_method_for_adding_chunks}

Since the declarative module is very important to the whole theory it is kind of a special module. Therefore, its Prolog module exports a predicate \lstinline|add_dm| that is just a wrapper for its chunk store. Hence, with the command \lstinline|add_dm| chunks can be added to the chunk store of the declarative module from every part of the program. This is e.g. used for the clearing of buffers in the buffer system, where the chunk of a buffer is written to declarative memory when the buffer is cleared. This is the implementation of the command:

\begin{lstlisting}
<<add_dm(ChunkDef)>> <=> add_chunk(ChunkDef).
\end{lstlisting}

\subsection{Retrieval Requests}
\label{retrieval_requests}

A retrieval request gets an incomplete chunk specification as input and returns a chunk whose slots match the provided chunk pattern.

\subsubsection{Chunk Patterns}

\enlargethispage{-\baselineskip}

The chunk patterns are transmitted in form of chunk specifications as defined in section~\ref{chunk_specification}. Since those specifications may be incomplete, variables are considered as place-holders for values in the result. The result always is a complete and ground chunk specification, because every chunk in a chunk store has to be defined completely; empty slots are indicated by the value nil.

\begin{example}
In this example, some possible requests are discussed.

\begin{enumerate}
 \item Request:
\begin{lstlisting}
chunk(foo,bar,_)        
\end{lstlisting}

A chunk with name \lstinline|foo|, type \lstinline|bar| and arbitrary slot values is requested.

 \item Request:
\begin{lstlisting}
chunk(_,bar,_)        
\end{lstlisting}

This request is satisfied by every chunk of type \lstinline|bar|.

 \item Request:
\begin{lstlisting}
chunk(_,t,[(foo,bar),(spam,eggs)])        
\end{lstlisting}

The most common case of requests is a specification of the type and a (possibly incomplete) number of slot-value pairs for that type. If a type does not provide a specified slot, the request is invalid and no chunk will be returned.
\end{enumerate}
\end{example}

\subsubsection{Finding Chunks}

In this section, a CHR constraint \lstinline|find_chunk/3| will be defined which produces a \lstinline|match_set/1| constraint for each chunk that matches a specified pattern. Eventually, the match set will be collected and returned.

\begin{lstlisting}
<<find_chunk(N1,T1,Ss), chunk(N2,T2)>> ==> 
  <<<unifiable((N1,T1),(N2,T2),_), 
  nonvar(Ss)>>> | 
  test_slots(N2,Ss), 
  match_set([N2]).
  
<<find_chunk(N1,T1,Ss), chunk(N2,T2)>> ==> 
  <<<unifiable((N1,T1),(N2,T2),_), 
  var(Ss)>>> | 
  test_slots(N2,[]), 
  match_set([N2]).
  
<<find_chunk(_,_,_)>> <=> true.
\end{lstlisting}

First, each chunk in the store whose name and type are unifiable with the specified name and type, will be part of the initial match set. If in the chunk specification the name and type are variables, each chunk will match. For the unification test, the \lstinline|unifiable/3| predicate of Prolog is used, because the unification should not be performed but only tested. If name and type match the pattern, then the slots have to be tested by \lstinline|test_slots/2|.

The rule in line~7 is for chunk specifications that do not specify the slots. In this case, no slots have to be tested. If all chunks have been tested or no chunk matches at all, the process is finished (rule in line ~13).

\looseness=-1 After adding each matching candidate to the match set whose name and type have already been checked, the match set is pruned from chunks that have non-matching slot values:

\begin{lstlisting}
<<test_slots(_,[])>> <=> true.

<<chunk_has_slot(N,S,V1), match_set([N]) \ test_slots(N,[(S,V2)|Ss])>> <=> 
  <<<unifiable(V1,V2,_)>>> | 
  test_slots(N,Ss).

<<chunk_has_slot(N,S,V1) \ test_slots(N,[(S,V2)|_]), match_set([N])>> <=> 
    <<<\+unifiable(V1,V2,_)>>> | 
    true.
    
<<test_slots(N,_) \ match_set([N])>> <=> true.
\end{lstlisting}

\FIXME{Zeilenreferenzen dynamisch, einzelnen Satz im ersten Absatz entfernen}

The first rule is the base case, where no slots have to be tested any more and the test is finished and has been successful.

In line~3, the rule is applicable if there is at least one slot \lstinline|(S,V2)| that has to be tested and a $HasSlot$ relation of the kind \lstinline|N| $\xrightarrow[]{\mathtt{S}}$ \lstinline|V1| with the slot \lstinline|S| to be tested, that is still in the match set, so no conflicting slot has been found yet. If the values \lstinline|V1| and \lstinline|V2| are unifiable, i.e. both are the same constant or at least one is a variable, the test passes and the chunk \lstinline|N| remains in the match set and the rest of the slot tests are performed.

\looseness=-1 The third rule in line~8 is applied if the guard of the first rule did not hold, so the values \lstinline|V1| and \lstinline|V2| are not unifiable, but there is a connection \lstinline|N| $\xrightarrow[]{\mathtt{S}}$ \lstinline|V1| and in the request it has been specified that the value of slot \lstinline|S| has to be \lstinline|V2|. In this case, \lstinline|V1| $\neq$ \lstinline|V2|, so the test fails and the chunk \lstinline|N| has to be removed from the match set, since one of its slots does not match.

If the last two rules cannot be applied, the chunk does not provide a slot that, however, has been specified in the request. Hence, the chunk does not match and the last rule therefore deletes it from the match set. \FIXME{make simpagation rule to simplification rule?}

If those rules have been applied exhaustively, only the matching chunks will remain in the match set: If there was an outstanding slot test, one of the rules would be applicable and the chunk would be removed from the match set, if the test fails (and the test would also be removed, because it has been performed). If the test is successful, the chunk will remain part of the match set, but the test will be removed. So the match set is correct and complete.

However, since the match set is distributed over a set of \lstinline|match_set| constraints, it would be desirable to collect all those matches in one set. This can be triggered by the constraint \lstinline|collect_matches/1|, which returns the complete match set in its arguments as soon as there is only one \lstinline|match_set| left:

\begin{lstlisting}
<<collect_matches(_) \ match_set(L1), match_set(L2)>> <=> 
  append(L1,L2,L), 
  match_set(L).
  
<<collect_matches(Res), match_set(L)>> <=> Res=L.

<<collect_matches(Res)>> <=> Res=[].
\end{lstlisting}

The first rule merges two match sets to one single merge set containing a list with all the chunks of the former sets, if the \lstinline|collect_matches| trigger is present. 

In the second rule, if there are no two match sets to merge in the store any more, the result of the \lstinline|collect_matches| operation is the remaining match set. The same applies for the last rule, where no match set is in the store and therefore the result is empty. Note that this implies that the rules have to be applied from top to bottom, left to right.\footnote{This is called the refined operational semantics of CHR}

The symbolic layer does not implement any rule stating which chunk will be returned if there is more than one chunk in the match set. In this implementation, the first chunk in the list is chosen. The module request is now implemented as follows:

\begin{lstlisting}
<<module_request(retrieval,chunk(Name,Type,Slots),ResChunk, ResState)>> <=> 
  find_chunk(Name,Type,Slots),
  collect_matches(Res),
  first(Res,Chunk),
  return_chunk(Chunk,ResChunk),
  get_state(ResChunk,ResState).
\end{lstlisting}

where \lstinline|first(L,E)| gets a list \lstinline|L| and returns its first element \lstinline|E| or \lstinline|nil| if the list is empty. 

With \lstinline|return_chunk/2| and \lstinline|get_state/2|, the actual results of the request are computed: By now, the variable \lstinline|Chunk| holds the name of the chunk to return, but in the specification of the module request, a complete chunk specification is demanded. \lstinline|return_chunk/2| is defined as a default method of a chunk store that gets a chunk name as its first argument and returns a chunk specification created from the values in the chunk store as its second argument.

The resulting state of the request is computed as follows: If the result chunk is \lstinline|nil|, no chunk was in the match set, so the state of the declarative module will be \lstinline|error|. In any other case, the state is \lstinline|free| after the request has been performed.

\subsection{Chunk Merging}

An important technique used in ACT-R's declarative memory module is chunk merging: If a chunk enters the chunk store and all of its slots and values are the same as of a chunk already in the store, then those two chunks get merged. Both names refer to the merged chunk.

If a chunk entering the declarative memory has the same name as a chunk that already is in the store, the new chunk first gets a new name. Then, if its slots are the same as the slots of the old chunk, they are merged and the new name is deleted.

\begin{lstlisting}
<<chunk(Name,Type) \ add_chunk(chunk(Name,Type,Slots))>> <=>
  <<<Type \== chunk>>> |
  add_chunk(chunk(Name:new,Type,Slots)).

% first check, if identical chunk exists
<<add_chunk(chunk(C,T,S))>> ==> 
  <<<T \== chunk>>> | 
  check_identical_chunks(chunk(C,T,S)).
\end{lstlisting}

The rules are added before the empty slot initialization in listing~\ref{lst:add_chunk_rules}. The first rule handles the case where a chunk with an already allocated name is added to the store. Then it gets a new name (which basically is just the old name extended by \lstinline|:new|) and tries to add this new chunk to the memory. 

The second rule adds an identity check for each chunk to be added except for primitive elements, since their slots are identical for every name, because every primitive element has no slots. Nevertheless they have to be distinguishable by their names and therefore cannot be merged.

The identity check is implemented as follows:

\begin{lstlisting}
<<check_identical_chunks(nil)>> <=> true.
<<chunk(NameOld,Type), check_identical_chunks(chunk(NameNew,Type,Slots))>> ==> 
  check_identical_chunks(chunk(NameNew,Type,Slots),NameOld).  
<<check_identical_chunks(_)>> <=> true.
\end{lstlisting}

The rule in line~3 adds for each identity check and each chunk in the store a pairwise identity check which is performed by the following rules:

\begin{lstlisting}
<<chunk(NameOld, Type) \ check_identical_chunks(chunk(NameNew, Type, []), NameOld)>> <=> 
  identical(NameOld,NameNew).
  
<<chunk(NameOld, Type), chunk_has_slot(NameOld, S, V) \ check_identical_chunks(chunk(NameNew, Type, [(S,V)|Rest]), NameOld)>> <=> 
  check_identical_chunks(chunk(NameNew,Type,Rest),NameOld).
  
<<chunk(NameOld, Type), chunk_has_slot(NameOld, S, VOld) \ check_identical_chunks(chunk(_, Type, [(S,VNew)|_]), NameOld)>> <=> 
  <<<VOld \== VNew>>> |
  true.
<<<remove_duplicates>>> @ <<identical(N,N)>> <=> true.

% abort checking for identical chunks if one has been found
<<<cleanup_identical_chunk_check>>> @ <<identical(NameOld,NameNew) \ check_identical_chunks(chunk(NameNew,_,_),NameOld)>> <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more. Then the chunks are identical and an \lstinline|identical/2| constraint is added to the store for those two chunks.

The next rule applies for an identity check for a slot-value pair that is successful, whereas the third rule handles the opposite case and aborts the check for this pair of chunks without adding an \lstinline|identical| constraint.

In the fourth rule redundant information is removed and the last rule aborts the identity check as soon as one matching chunk has been found.

Note that this implementation assumes that the chunk specification of the chunk entering the declarative memory is complete. If it is incomplete, the correct semantics of the adding is that all unspecified slots are empty so their values equal \lstinline|nil|. Nevertheless, this implementation would merge the chunk with a chunk that has values in those unspecified slots. This could be improved by completing the chunk specifications before checking for identical chunks in the store.

For the easier use of the identical constraint at other points, transitive identities can be reduced to the only real chunk in the store (the one with the \lstinline|chunk| constraint):

\begin{lstlisting}
<<<reduce>>> @ <<chunk(C1,_), identical(C1,C2) \ identical(C2,C3)>> <=> 
  identical(C1,C3).
\end{lstlisting}

Additionally, identical chunks should not be added to the store explicitly, since they are just a copy of another chunk and their name is a reference to this actual chunk. The helper chunks with the artificial \lstinline|:new| suffix are also not added to the store and their identical information is deleted in the end, since their nomenclature was only store internal, so only the original name must be kept:

\begin{lstlisting}
% do not add help chunks with :new tag and remove identical information
add_chunk(chunk(C:new,T,S)), identical(C,C:new) <=> true. 
% do not add identical chunk, but keep identical information
identical(C1,C2) \ add_chunk(chunk(C2,T,S)) <=> true. 
\end{lstlisting}

In the declarative module, the chunk search must be extended to find merged chunks by both names. This can be achieved as follows:

\enlargethispage{-\baselineskip}

\begin{lstlisting}
<<identical(C1,C2) \ find_chunk(C2,T2,Ss2)>> <=> 
  <<<ground(C2)>>> | 
  find_chunk(C1,T2,Ss2).
\end{lstlisting}

so the chunk search of a chunk that is only a pointer to another chunk can be reduced to the search of this chunk. \FIXME{maybe this can cause problems if a production rule refers to a particular name and gets a chunk with the name of its brother..}

The process of chunk merging is described in \cite[217, 71]{actr_reference} and \cite[3]{actr_tutorial}. The treatment of identical names is not described there, but has been tested in the original implementation: ACT-R handles those identical names similarly to this approach by adding a sequential number to the identical name. For example, the chunk with name \lstinline|a| would be called \lstinline|a-0| if there already was a chunk \lstinline|a| in the store.

\section{Initialization}
\label{initialization}

In the examples, the models had to be run by stating complex queries which create all necessary buffers and add all chunk types and chunks to the declarative memory manually. In the original ACT-R implementation, the command \lstinline|run| is used to run a model. This behaviour can be transferred easily to the CHR implementation by adding a \lstinline|run| constraint and a rule for this constraint, that performs all the initialization work.

\begin{lstlisting}
init @ 
  <<run>> <=> 
  add_buffer(retrieval,declarative_module),
  add_chunk_type(...),
  add_dm(...),
  goal_focus(...),
  fire.
\end{lstlisting}

This example assumes that there are implementation of the called methods that perform the partial initialization work. A typical initialization routine could create all buffers at first, then add all needed chunk-types (note, that this might include the artificial chunk-type \lstinline|chunk| as defined in section~\ref{distinction_elements_chunks} (see page~\pageref{distinction_elements_chunks}). Then the initial declarative memory chunks are added. The \lstinline|goal-focus| method selects a created chunk and copies it to the declarative memory. The adding of the \lstinline|fire| constraint eventually starts the computation after the initialization is finished as described in section~\ref{implementation:rule_application_order} (see page~\pageref{implementation:rule_application_order}).

\section{Timing in ACT-R}

So far, the execution order of the production rules has been controlled by the \lstinline|fire| constraint -- a phase constraint which so far has simulated the occupation of the production system while executing a rule.

However, certain buffer actions like buffer requests may take some time to finish. The procedural system is free to fire the next rule after all actions have been started\footnote{see chapters \ref{process_of_rule_selection_and_execution} and \ref{serial_parallel_aspects}} and the requests are performed in parallel to that. Additionally, for the simulation it may be interesting to explore how much time certain actions have taken, especially when it comes to the subsymbolic layer.

Those aspects cannot be implemented easily using the current approach with phase constraints. Hence, the idea of introducing a central scheduling unit is a possible solution of those requirements: The unit has a serialized ordered list of events with particular timings. If a new event is scheduled, the time when it is executed must be known. The scheduling unit inserts the event at the right position of the list preserving the ordered time condition. Figure~\ref{fig:scheduler:a} illustrates this approach.

\begin{figure}[hbt]
\centering
\subfigure[]{
\centering
\tikzstyle{event} = [circle, draw]
\tikzstyle{line} = [draw, -latex]
\tikzstyle{vecArrow} = [draw,thick, decoration={markings,mark=at position
   1 with {\arrow[semithick]{open triangle 60}}},
   double distance=1.4pt, shorten >= 5.5pt,
   preaction = {decorate},
   postaction = {draw,line width=1.4pt, white,shorten >= 4.5pt}]

\begin{tikzpicture}[node distance = 1.5cm, auto]
 \node[event] (e1) {\parbox{5mm}{\centering $e_1$\\ $t_1$}}; 
 \node[event, right of=e1] (e2) {\parbox{5mm}{\centering $e_2$\\ $t_2$}}; 
 \node[event, right of=e2] (e3) {\parbox{5mm}{\centering $e_3$\\ $t_3$}}; 
 \node[right of=e3] (dots) {\dots}; 
 \node[draw, rectangle, below of=e1, node distance=3cm] (sched) {
\begin{tikzpicture}
\node (exec) {execution};
 \node[event, below of=exec, node distance=8mm] (e) {\parbox{5mm}{\centering $e$}}; 
\end{tikzpicture}
};
\draw let 
  \p1 = (e1.west),
 \p2 = (dots.east)
in
node[node distance=2cm, minimum width=\x2-\x1] (times) at ({(\x2+\x1)/2},\y1-15mm) {$t_1 \le t_2 \le t_3 \le \dots$};
\node[draw, rectangle, right of=sched, node distance=2.5cm] (current) {\parbox{2cm}{\centering current time\\$T = t$}};

    % Draw edges
 \path[line] (e1) -- (e2);
 \path[line] (e2) -- (e3);
 \path[line] (e3) -- (dots);
\path[vecArrow] (e1) -- (sched);
\path[vecArrow] (sched) -- (current);
\end{tikzpicture}
\label{fig:scheduler:a}}
\qquad
\subfigure[]{
\centering
\tikzstyle{event} = [circle, draw]
\tikzstyle{line} = [draw, -latex]
\tikzstyle{vecArrow} = [draw,thick, decoration={markings,mark=at position
   1 with {\arrow[semithick]{open triangle 60}}},
   double distance=1.4pt, shorten >= 5.5pt,
   preaction = {decorate},
   postaction = {draw,line width=1.4pt, white,shorten >= 4.5pt}]

\begin{tikzpicture}[node distance = 1.5cm, auto]
 \node[event] (e2) {\parbox{5mm}{\centering $e_2$\\ $t_2$}}; 
 \node[event, right of=e2] (e3) {\parbox{5mm}{\centering $e_3$\\ $t_3$}}; 
 \node[right of=e3] (dots) {\dots}; 
 \node[draw, rectangle, below of=e2, node distance=3cm] (sched) {
\begin{tikzpicture}
\node (exec) {execution};
 \node[event, below of=exec, node distance=8mm] (e) {\parbox{5mm}{\centering $e_1$}}; 
\end{tikzpicture}
};

\node[draw, rectangle, right of=sched, node distance=2.5cm] (current) {\parbox{2cm}{\centering current time\\$T = t_1$}};

    % Draw edges
 \path[line] (e2) -- (e3);
 \path[line] (e3) -- (dots);
\path[vecArrow] (e2) -- (sched);
\path[vecArrow] (sched) -- (current);
\end{tikzpicture}
\label{fig:scheduler:b}}
\caption{Scheduling with an event queue. \subref{fig:scheduler:a} The scheduler stores the events $e_i$ with their corresponding times $t_i$ in a queue which is sorted by the times. Currently, the event $e$ is executed and the time $T$ is $t$. \subref{fig:scheduler:b} If the event $e$ has been executed completely, the next event -- the first event $e_1$ of the queue -- is removed. The current time is set to the time $t_1$ and the event is executed.}
\label{fig:scheduler}
\end{figure}

The system periodically removes the first event from the queue, sets the current time to the time of the event and executes it which may lead to new events in the queue. The queue organizes the right order of the events automatically. Figure~\ref{fig:scheduler:b} shows the effect of the removal to the queue and the system time.

With this approach, the simulation of a parallel execution of ACT-R can be achieved: Each buffer action on the RHS of a rule just schedules an event that actually performs the action at a specified time (the current time plus its duration). 

The central part of the scheduler is a \emph{priority queue} which manages a list of events and returns them by time. It is described in the next section.

\subsection{Priority Queue}

A \emph{priority queue} is an abstract data structure that serves objects by their priority. It provides the following abstract methods:

\begin{description}
 \item[enqueue with priority] An object with a particular priority is inserted to the queue. 
 \item[dequeue highest priority] The object with the highest priority is removed from the queue and returned.
\end{description}

\subsubsection{Objects}

In the implementation of the scheduler, the priority queue contains objects of the form \lstinline|q(Time,Priority,Event)|. The priority of such a queue object is composed from the \lstinline|Time| and the \lstinline|Priority|. An \lstinline|Event| is a Prolog goal, i.e. a built-in or a CHR constraint. The order between the elements is defined as follows:

\begin{definition}[ordered time-priority condition]
\label{def:time-priority-condition}
\lstinline|q(T1,P1,E1)| $\prec$ \lstinline|q(T2,P2,E2)|, i.e. the object \lstinline|q(T1,P1,E1)| is the predecessor of the object \lstinline|q(T2,P2,E2)|, if \lstinline|T1| $<$ \lstinline|T2|. In the case that \lstinline|T1 = T2|, then \lstinline|q(T1,P1,E1)| $\prec$ \lstinline|q(T2,P2,E2)| if \lstinline|P1| $>$ \lstinline|P2|. So, events with smaller times will be returned first. If two events appear at the same time, it is possible to define a priority and the event with the higher priority will be returned first. 
\end{definition}

\subsubsection{Representation of the Queue}

The representation of the priority queue is inspired by \cite[38\psqq]{fru_chr_book_2009}: An order constraint \lstinline|A --> B| is introduced, which states that \lstinline|A| will be returned before \lstinline|B| (or \lstinline|B| is the direct successor of \lstinline|A|). The beginning of the queue will be defined by a start symbol \lstinline|s|, so the first real element is the successor of \lstinline|s|. A possible queue could be:

\begin{lstlisting}
    s     --> q(1,0,e1)
q(1,0,e1) --> q(3,7,e2)
q(3,7,e2) --> q(3,2,e3)
\end{lstlisting}

This queue achieves the ordered time-priority condition, since the queue objects are in the correct order according to their times and priorities. It is also consistent in a sense that it has no gaps and no object has more than one successor.

In general, some rules to make such a queue consistent can be defined, i.e. every object only has one successor and the queue achieves the time-priority condition:

\begin{lstlisting}
<<A --> A>> <=> true.

<<_ --> s>> <=> false.

<<A --> B, A --> C>> <=>
  <<<leq(A,B),
  leq(B,C)>>> |
  A --> B,
  B --> C.
\end{lstlisting}

The first rule states, that if an object is its own successor, this information can be deleted. The second rule states, that nothing can be the predecessor of the start symbol. The last rule is the most important one: If one object has two successors, then these connections have to be divided into two connections according to the defined time-priority condition. This condition can be implemented as follows:

\begin{lstlisting}
leq(s,_).

% Time1 < Time2 -> event with time1 first, priority does not matter
leq(q(Time1,_,_), q(Time2,_,_)) :- 
  Time1 < Time2.

% same time: event with higher priority first
leq(q(Time,Priority1,_), q(Time,Priority2,_)) :- 
  Priority1 >= Priority2.
\end{lstlisting}

The first predicate states that the start symbol is less than every other object. The other two rules directly implement the time-priority condition as defined in definition~\ref{def:time-priority-condition}.

Note that two objects are considered the same, iff their time, priority and event are syntactically the same. If an object is altered in one of the \lstinline|-->| constraints, it has to be edited in every other occurrence in the   list to avoid gaps.

Another important property is, that the list does not have any gaps, so it must be possible to track the queue from every element backwards to the start symbol. This condition is not achieved by the rules above, but since a priority queue only offers two mechanisms to modify it, a lot of those problems can be avoided:

\begin{description}
 \item[add\_q(Time,Priority,Event)] Enqueues an object with the specified properties. I.e., a new \lstinline|q(Time,Priority,Event)| object will be created and the following constraint will be added: \lstinline|s --> q(Time,Priority,Event)|. The rules presented above will lead to a linear, serialized list achieving the time-priority condition without gaps.
\begin{lstlisting}
<<add_q(Time,Priority,Evt)>> <=>
  s --> q(Time,Priority,Evt).
\end{lstlisting}
 \item[de\_q(X)] Dequeues the first element of the queue according to the time-priority condition and binds its value to \lstinline|X|.
\begin{lstlisting}
<<de_q(X), s --> A, A --> B>> <=>
  X = A,
  s --> B.

<<de_q(X), s --> A>> <=>
  X = A.  
  
<<de_q(X)>> <=> X = nil.
\end{lstlisting}

The first object is just the successor of \lstinline|s|, since the list has been constructed preserving the correct order and the property, that everything starts at \lstinline|s|. If the first object has a successor, this object is the new first object. If there are no order constraints left, the queue is empty and \lstinline|de_q| returns \lstinline|nil|.
\end{description}

\subsubsection{Adding Events at Second Position}

In this implementation, another default method is added for the priority queue to insert an event which is the direct successor of the first event and hence avoids the default enqueuing methods. It sets the time and priority automatically according to the desired position of the new event:

\begin{description}
 \item[after\_next\_event(E)] Adds the event \lstinline|E| to the queue after the first event without destroying the consistency and the time-priority condition of the queue.
\end{description}

To implement this method, the time and priorities have to be set in a way that the time-priority condition does hold:

\begin{lstlisting}
<<s --> q(Time,P1,E1) \ after_next_event(Evt)>> <=> 
  NP1 is P1 + 2, % increase priority of first event, so it still has highest priority
  P is P1 + 1, % priority of event that is added, ensured that it is higher than of the former second event (because it is P1+1)
  de_q(_), % remove head of queue
  add_q(Time,NP1,E1), % add head of queue again with new priority. Will be first again, because it has old prio (which is higher than prio of all successors)
  add_q(Time,P,Evt). % add new event. Will be < than Prio of head but it is ensured that it is higher than prio of second event
\end{lstlisting}

If the first event is \lstinline|q(Time,P1,E1)| and a new event \lstinline|Evt| has to be added after this event, the times of the two events are the same, the priority of the first event is \lstinline|P1 + 2| and the priority of the new event is \lstinline|P1 + 1|. The first event is removed from the queue and would be added with its new priority to the queue again, as it is with the new event. 

This is correct: The first event will be the first event again, because its old priority was higher than any other priority at that point of time. Since the new priority is even higher than that, no other event from the queue will have a higher priority. The new event also has a higher priority than every other event in the queue, but a lower priority than the first event, so it will be added after the first event.

By the \lstinline|de_q| and \lstinline|add_q| actions it is ensured that no garbage of the old event remains in the queue and the events are added correctly through an official method of the queue.

\subsection{Scheduler}
\label{implementation:scheduler}

The scheduler component is an own module that manages events by feeding a priority queue and controls the recognize-act cycle. It also holds the current time of the system. 

\subsubsection{Current Time}

The current time can be saved in a \lstinline|now/1| constraint. It is important that there is only one such constraint and that time increases monotonically. Other modules can access the time only by a \lstinline|get_now/1| constraint that just returns the current time saved in the \lstinline|now/1| constraint. The current time cannot be set from outside, but is determined by the last event dequeued from the priority queue.

\subsubsection{Interface to the Scheduler}

\begin{definition}[IScheduler]
\label{def:ischeduler}
The \emph{IScheduler} interface provides the following methods:

\begin{description}
 \item[Queue Management] The methods \lstinline|add_q/3|, \lstinline|de_q/1| and \lstinline|after_next_event/1| which are described above provide access to the queue of the scheduler.
 \item[Timings] The setting and getting of the time by \lstinline|get_now/1| and \lstinline|now/1|. The latter one should only be used once in the initialization. The setting of the current time is managed by the scheduler automatically.
 \item[Start next cycle] The constraint \lstinline|nextcyc/0| is only used to initialize the first cycle and should not be used at a later point, since the management of the recognize-act-cycle is managed by the scheduler. 
 \item[No rule] If no rule was applicable, the procedural module can trigger the \lstinline|no_rule/0| constraint which has effects to the next conflict resolution event, as mentioned before.
\end{description}
\end{definition}

\subsubsection{Recognize-Act Cycle}
\label{implementation:scheduler:recognize-act}

As described before, the procedural module can only fire one rule at a time. When executing the RHS of a rule, all its actions are added to the scheduler with the time point when their execution is finished. For example: If on the RHS of the firing rule a retrieval request has to be performed, an event will be added to the priority queue with the time $Now + Duration$, so the chunk retrieved from the declarative memory will be written to the retrieval buffer at this time point.

After all events of the RHS have been added to the scheduler, the procedural module is free again and therefore the next rule can fire. The event of firing will be added to the priority queue as well by the \lstinline|fire| constraint at the end of each production rule. The rule will be added at the current time point, but with low priority, since it has to be ensured that every action of the previously executed rule has been performed yet (in the sense that a corresponding event has been added at the specified time point). In many cases, no other rule will be applicable at this time, because most of the meaningful production rules have to wait for the results of the preceding production rule. 

Many of the buffer actions are performed immediately, so for buffer modifications or clearings, an event with the current point of time is added to the queue. They are performed in a certain order defined by their priority as shown in table~\ref{tab:action_priorities}. The request actions are performed at last, but they perform a buffer clearing immediately and then start their calculation which can take some time. 

\begin{table}[htb]
\begin{center}
\caption{Priorities of buffer actions}
\label{tab:action_priorities}
\begin{tabular}{|l|l|}
\hline
Priority & Action\\
\hline
100 & Buffer modification\\
50 & Module requests\\
10 & Buffer clearings\\
\hline
\end{tabular}
\end{center}
\end{table}


If no rule is applicable, the next time for a possible application is after having performed the next event. So, the next \lstinline|fire| event is scheduled directly after the first event in the queue. This simulates the behaviour that the procedural module stays ready to fire the next rule, without polling at every time point if a rule is applicable, but only reacting on changes to the buffer system. 

The following enumeration summarizes the recognize-act cycle with a scheduler:

\begin{enumerate}
 \item The next event is removed from the queue, the current time is set to the time of the event and the event is performed.
 \begin{enumerate}
 \item The dequeued event is a \lstinline|fire| constraint: The rule that matches all its conditions is fired and removes the \lstinline|fire| constraint.
 \item The actions of the rule are scheduled in the queue. Modifications and Clearings have the current time point, requests have a time point in the future depending on the module.
 \item The last action of the rule is to add a \lstinline|fire| constraint to the queue with the current time point and a very low priority. This simulates that the procedural module is free again, after all in-place actions of a rule have been performed, so the next matching rule may fire.
 \item There are two possibilities:
 \begin{enumerate}
  \item \emph{The next rule matches:} It will be performed like the last rule.
  \item \emph{No rule matches:} The next possible time for a rule to fire is when something in the buffers has changed. This cannot happen until the next event has been performed. So the next \lstinline|fire| event will be added to the queue by \lstinline|after_next_event| which has been described above.
 \end{enumerate}
  \end{enumerate}
 \item Go to point 1. This is performed until there are no events in the queue.
\end{enumerate}


The following parts are necessary to implement this cycle:

\paragraph{Start Next Cycle} 

The constraint \lstinline|nextcyc| leads the system to remove the next event from the queue and perform it. Performing is done by a \lstinline|call_event| constraint:

\begin{lstlisting}
% After an event has been performed, nextcyc is triggered. 
%This leads to the next event in the queue to be performed.
<<nextcyc>> <=> de_q(Evt), call_event(Evt).
\end{lstlisting}

\paragraph{Call an Event} 

Event calling just takes a queue element and sets the current time to the time of the event and performs a Prolog \lstinline|call|. Additionally, a message is printed to the screen. After the event has been executed, the next cycle is initiated.

If the queue element is \lstinline|nil| (i.e. no event has been in the queue), the computation is finished and the current time is removed.

\begin{lstlisting}
% no event in queue -> do nothing and remove current time
<<call_event(nil) \ now(_)>> <=> write('No more events in queue. End of computation.'),nl.

<<call_event(q(Time,Priority,Evt)), now(Now)>> <=> 
  Now =< Time | 
  now(Time),
  write(Now:Priority),
  write(' ... '),write('calling event: '), write(Evt),nl,
  call(Evt),
  nextcyc.
\end{lstlisting}

\paragraph{Changing the Buffer System}
\label{changing_the_buffer_system}

For each buffer action, add a \lstinline|do_buffer_action| constraint, that actually performs the code specified in the former action. Modify the action as follows:

\begin{lstlisting}
% Schedule buffer_action
<<buffer_action(BufName, Chunk)>> <=> 
  get_now(Now),
  Time is Now + Duration, 
  add_q(Time, Priority, do_buffer_action(BufName, Chunk)). 
\end{lstlisting}

with appropriate values for \lstinline|Duration| and \lstinline|Priority|.

\paragraph{Production Rules}

As in the last version of the production system, each rule has the following structure:

\begin{lstlisting}
<<<rule>>> @
  {conditions} \ <<fire>> <=> 
    {actions}, 
    conflict_resolution.
\end{lstlisting}

where \lstinline|conflict_resolution/0| just schedules the next \lstinline|fire| event and is defined as:

\begin{lstlisting}
<<conflict_resolution>> <=> 
  get_now(Now),
  add_q(Now,0,fire).
\end{lstlisting}

As the last production rule, there has to be:

\begin{lstlisting}
<<<no-rule>>> @ 
  <<fire>> <=> 
    no_rule.
\end{lstlisting}

which removes the \lstinline|fire| constraint if still present and states that no rule has been fired, because otherwise the firing of a rule would have removed the \lstinline|fire| constraint. If no rule was applicable, a new \lstinline|fire| event is scheduled after the next event:

\begin{lstlisting}
<<no_rule>> <=> 
  write('No rule matches -> Schedule next conflict resolution event'),nl,
  after_next_event(do_conflict_resolution).
\end{lstlisting}

\section{Lisp Functions}
\label{lisp_functions}

In ACT-R, it is possible to call Lisp functions in the model definitions, for example to add chunk-types and declarative memory or to set configuration variables. Since those functions cannot be called in the CHR/Prolog environment, there has to be a mechanism to implement missing functions.

\subsection{General Translation}

Lisp functions are lists (indicated by round braces \lstinline|(| and \lstinline|)|), which have the functor as their first element and the function arguments in the rest of the list. Hence, each Lisp function \lstinline|(f arg1 arg2 ...)| called in the model definition of an ACT-R model is translated into the adding of a CHR constraint \lstinline|lisp_f([arg1, arg2, ...])|. For all used functions, there has to be a default implementation in the module \lstinline|std_lisp|. In this implementation, the concept is reduced to simple procedural calls ignoring return values, which is adequate for most of the pure ACT-R models without the experiment environment. Here is an example implementation of the Lisp function \lstinline|(chunk-type name slot1 slot2 ...)| which adds a new chunk-type to the system:

\begin{lstlisting}
lisp_chunktype([Type|Slots]) <=>
  % add type to buffer system (local module)
  add_chunk_type(Type,Slots),
  % add type to declarative module
  declarative_module:add_chunk_type(Type,Slots).
\end{lstlisting}

Note that this function adds the chunk-types both to the declarative module and the buffer system, since types are global to the system. Hence, every module with a chunk store should be added to the implementation of this Lisp function.

\subsection{Configuration Variables}
\label{configuration}

In ACT-R, configuration variables which control the behaviour of the architecture are set with the Lisp function \lstinline|(sgp :Var Val)|, which sets the variable \lstinline|Var| to \lstinline|Val|. To handle such configuration variables, a configuration module can be added to the CHR implementation that offers the \emph{IConfiguration} interface to set variables and to ask for their values:

\begin{definition}[IConfiguration]
\label{def:iconfiguration}
The interface \emph{IConfiguration} provides the following methods to access the configuration store:
\begin{description}
 \item[Set configuration variables] By calling \lstinline|set_conf(+Var,+Val)| the configuration variable \lstinline|Var| is set to the value \lstinline|Val|.
 \item[Get the value of a configuration variable] The call of \lstinline|get_conf(+Var,-Val)| binds the value of the configuration variable \lstinline|Var| to the argument \lstinline|Val|.
\end{description}
\end{definition}

The \lstinline|(sgp ...)| call can then be translated to:

\begin{lstlisting}
lisp_sgp([]) <=> true.
lisp_sgp([:,Var,Val|Rest]) <=>
  set_conf(Var,Val),
  lisp_sgp(Rest).
\end{lstlisting}

\subsubsection{The Observer Pattern}

Sometimes it is necessary for a module to get informed about the change of a configuration variable. Therefore, the configuration module implements the \emph{Observable} interface, which offers an abstract method \lstinline|add_config_observer(Module,Var)|. Thereby a module can register at the configuration module for update notifications of a particular variable. If the variable is changed by a \lstinline|set_conf| call, all observers of this variable can be notified by the following code:

\begin{lstlisting}
% collect observers
observer(Module,Var), set_conf(Var,_) ==> notify(Module,Var).

% actually set variable
set_conf(Var,Val), configuration(Var,_) <=> 
  configuration(Var,Val),
  notify_all(Var). % variable has been set -> perform pending notifications
notify_all(Var), notify(Module,Var) ==> 
  Module:update. % perform all pending notifications
notify_all(_) <=> true. % no notifications pending, clean up
\end{lstlisting}

The constraint \lstinline|observer(Module,Var)| states that the module \lstinline|Module| observes the variable \lstinline|Var|. The observer modules have to declare a \lstinline|update/0| constraint which may trigger some action related to the change of a configuration variable.

\section{Subsymbolic Layer}

So far, a translation scheme and a framework implementing the symbolic concepts of ACT-R has been presented. This section extends this implementation by the subsymbolic layer as described in section~\ref{subsymbolic_layer}.

\subsection{Activation of Chunks}

The activation of a chunk is a numerical value that determines if a chunk is retrieved and how long is the latency of the retrieval. The next sections describe how the concept can be implemented in CHR.

\subsubsection{Base-Level Learning}

One part of the activation value is the base-level activation of a chunk. The value is learned by the system and depends on practice as stated in equation~\eqref{eq:base_level_learning}:

\begin{equation*}
B_i = \mathrm{ln}\left(\sum_{j=1}^n{t_j^{-d}}\right) 
\end{equation*}

\paragraph{Presentations of a Chunk} 

To determine the base-level value of a chunk, the time points when it has been practiced have to be known. A chunk is considered as practiced when it enters the declarative memory either explicitly by calling \lstinline|add_dm| or implicitly by a buffer clearing. Additionally, if a chunk is merged with a chunk that enters the declarative memory, the original chunk is strengthened (so the chunk that has been in the declarative memory before is considered as presented). 

Hence, every time a chunk enters the declarative memory, the time of this event has to be stored. Therefore, a \lstinline|presentation/2| that holds the chunk name and the time of a presentation is introduced. To simplify the use of this constraint, the procedural constraint \lstinline|present/1|, that stores the presentation of a chunk at the current time, can be implemented as follows:

\begin{lstlisting}
<<chunk(Name,Type) \ present(chunk(Name,Type,_))>> <=> 
  getNow(Time),
  presentation(Name,Time).
\end{lstlisting}

The \lstinline|add_dm| command is extended by a presentation event:

\begin{lstlisting}
<<add_dm(ChunkDef)>> <=> 
  add_chunk(ChunkDef), 
  present(ChunkDef). 
\end{lstlisting}

If a chunk that is identical to a chunk already stored enters declarative memory, the original chunk is being strengthened by:

\begin{lstlisting}
<<identical(C1,C2) \ present(chunk(C2,_,_))>> <=> 
  present(C1).
\end{lstlisting}

\paragraph{Calculating the Base-Level Value}

Somewhere in the process of a request, the activation of a set of chunks has to be calculated. To trigger the calculation of the activation of one particular chunk, the trigger constraint \lstinline|calc_activation(Chunk,Activation)| which gets a chunk name and binds its activation value to the second argument is introduced:

\begin{lstlisting}
<<presentation(C,PTime), calc_activation(C,A)>> ==> 
  get_now(Now), 
  Time is Now - PTime, 
  base_level_part(C,Time,_,A).
  
calc_activation(_,_) <=> true.
\end{lstlisting}

These two rules produce for every presentation of the chunk a \lstinline|base_level_part| with the name of the chunk and the time since a particular presentation has happened. Additionally, two unbound variables are given to the part constraint: The first is a variable that will hold an intermediate result and the second is the actual activation value that is bound to the return value of the \lstinline|calc_activation| constraint.

Each of those \lstinline|base_level_part| constraints are part of the result which is the activation value of their chunk. The following rule converts the time $t_j$ to the value $t_j^{-d}$ as stated in equation~\eqref{eq:base_level_learning}:

\begin{lstlisting}
% if A and B not set: set B to Time^(-D). Time is the time since the presentation of this base_level_part
<<base_level_part(_,Time,B,A)>> ==>
  <<<var(A), var(B), 
  Time =\= 0>>> |
  get_conf(bll,D), % decay parameter
  B is Time ** (-D).
\end{lstlisting}

The result is bound to the variable \lstinline|B|. The rule can only be applied if the intermediate result \lstinline|B| and the result \lstinline|A| are not bound to any value. As soon as the intermediate result has been calculated, two \lstinline|base_level_part| constraints can be merged by adding their \lstinline|B| values up according to the base-level learning equation~\eqref{eq:base_level_learning}:

\begin{lstlisting}
% collect base level parts and add them together. Only if Bs are set
<<base_level_part(C,_,B1,A), base_level_part(C,_,B2,A)>> <=>
  <<<nonvar(B1), nonvar(B2), 
  var(A)>>> |
  B is B1+B2,
  base_level_part(C,_,B,A).
\end{lstlisting}

If this rule is applied to exhaustion, only one \lstinline|base_level_part| constraint will remain. Hence, below this rule, a rule for this single constraint can be introduced:

\begin{lstlisting}
% if B is set, A is not set and there are no more base_level_parts of this chunk: calculate actual base level activation and store it in A. Only possible if B is =\= 0.
<<base_level_part(_,_,B,A)>> <=>
  <<<var(A),nonvar(B), 
  B =\= 0>>> |
  A is log(B).
\end{lstlisting}

Note that the rule has to be executed after the last rule cannot be applied anymore, otherwise it would take an intermediate result as the actual result.

With this set of rules, the base-level activation can be calculated according to its definition. There are some special cases that can be handled implementation specifically (all cases where the guards prevent the rules from firing are such cases that may need some kind of special treatment).

\paragraph{Fan Values}

In the calculation process, the fan value $\mathrm{fan}_j$ of a chunk $j$ may be needed. This value is the number of chunks where $j$ appears in the slots plus one for the chunk itself. So, a chunk that does not appear in any slots has the fan value $1$, a chunk that appears in the slots of another chunk has the value $2$, etc. This can be achieved in CHR as follows:

\begin{lstlisting}
<<chunk(C,_)>> ==> fan(C,1).

<<chunk_has_slot(_,_,C), chunk(C,_)>> ==> fan(C,1).

<<fan(C,F1), fan(C,F2)>> <=> 
  F is F1+F2, 
  fan(C,F).
\end{lstlisting}

The first rule adds a fan of $1$ for each chunk. The next rule adds a fan of $1$ for a chunk \lstinline|C| for each slot where \lstinline|C| is the value. In the last rule, two fan values for one particular chunk are summed up to a single fan value. Note that this has to be considered when deleting a chunk: For every chunk in the slots of the deleted chunk, the fan value must be decreased by one.

As noted before in section~\ref{distinction_elements_chunks} on page~\pageref{distinction_elements_chunks}, primitive elements are stored as chunks of the type \lstinline|chunk| that has no slots. This is important for the fan calculation as it is presented here, since the fan value depends on the presence of a \lstinline|chunk| constraint to calculate the proper fan value. Otherwise, the fan value of primitive elements would always be off by one.

\paragraph{Associative Weights}

The activation calculation also depends on a contextual component, the associative weights. For a value $S_{ji}$, which describes the associative strength from a chunk $j$ to a chunk $i$, the following rules apply:

\begin{lstlisting}[escapeinside={(*@}{@*)}]
<<fan(J,F), chunk(I,_), chunk_has_slot(I,_,J) \ calc_sji(J,I,Sji)>> <=> 
  <<<I \== J>>> | 
  Sji is 2 - log(F).

<<calc_sji(_,_,Sji)>> <=> Sji=0. (*@\label{lst:sji:no_connection}@*)
\end{lstlisting}

The \lstinline|calc_sji(J,I,Sji)| gets a chunk \lstinline|J| and a chunk \lstinline|I|, calculates their associative weight from \lstinline|J| to \lstinline|I| and binds it to \lstinline|Sji|. The first rule can be applied if \lstinline|J| appears in the slots of chunk \lstinline|I|. Then, the associative weight is calculated according to equation~\eqref{eq:assoc_strength}:

\begin{equation*}
S_{ji} = S - \mathrm{ln}(\mathrm{fan}_j) 
\end{equation*}

The value of $S$ is assumed to be $2$ in this rule; a configurable constant for $S$ as described in section~\ref{configuration} can be introduced easily.

If \lstinline|J| does not appear in the slots of chunk \lstinline|I|, then $S_{\mathtt{JI}} := 0$ by definition (line~\ref{lst:sji:no_connection}).

\paragraph{Calculating the Overall-Activations}

The new constraint \lstinline|calc_activations/2| gets a list of chunks and a context and initiates the computation of the overall activation values of the chunks in the list regarding the context. Remember that for the associative weights, the current context plays a role, since all associative weights from the chunks (the $j$s) in the context to the chunk whose activation is calculated are summed up (see section~\ref{activation} for details).

\begin{lstlisting}[escapeinside={(*@}{@*)}]
<<calc_activations([],_)>> <=>
  true.
  
<<calc_activations([C|Cs],Context)>> <=> 
  calc_activation(C,B), 
  calc_activations(Cs,Context), 
  context(C,Context,Assoc), (*@\label{lst:calc_activations:context}@*)
  
  length(Context,N), (*@\label{lst:calc_activations:attentional1}@*)
  Assoc1 is 1/N * Assoc, (*@\label{lst:calc_activations:attentional2}@*)
  A is B + Assoc1, (*@\label{lst:calc_activations:final}@*)
  max(C,A). (*@\label{lst:calc_activations:max}@*)
\end{lstlisting}

The first rule is the base-case that simply finishes the calculation. The second rule takes the first chunk in the list and calculates its base-level activation \lstinline|B| by \lstinline|calc_activation|. The next line triggers the computation for the rest of the chunks in the list (using the same context).

For the chunk \lstinline|C| the context component, i.e. the associative weight, is calculated by the call of \lstinline|context(C,Context,Assoc)| in line~\ref{lst:calc_activations:context}, which binds the associative weight to \lstinline|Assoc|. I.e. the result of $\sum_{j \in C}{S_{ji}}$ ($C$ is the context as represented by \lstinline|Context|) is bound to the variable \lstinline|Assoc|.

Afterwards, the attentional weighting $W_j$ is considered in lines~\ref{lst:calc_activations:attentional1} and \ref{lst:calc_activations:attentional2}. The variable \lstinline|Assoc1| now holds the value of $W_j \cdot \sum_{j \in C}{S_{ji}}$. The overall activation of chunk \lstinline|C| is -- as defined in equation~\eqref{eq:activation_equation} -- calculated in line~\ref{lst:calc_activations:final} by adding the base-level activation to the sum of the associative weightings of the chunk. Eventually, in line~\ref{lst:calc_activations:max}, the activation of this chunk is added to the set of potential maximum candidates of all activation values. The maximum then is calculated as follows:

\begin{lstlisting}[caption={Calculate highest activation of all matching chunks}, label=lst:max_activation]
max(_,A1) \ max(_,A2) <=> 
  A1 >= A2 |
  true.
\end{lstlisting}

This deletes all potential candidates for the maximal activation value that have a smaller value than one of the other candidates. In \cite[19\psqq]{fru_chr_book_2009} this algorithm is presented in more detail.

\paragraph{Threshold and Maximum}

The request is only successful, if there is a matching chunk that has an activation higher than a specified threshold. In the following, it is assumed that the threshold is saved in a \lstinline|threshold/1| constraint.

In the last section, the chunk with the highest activation among all matching chunks is calculated and stored in a \lstinline|max/2| constraint (there is only one \lstinline|max| constraint after the rule in listing~\ref{lst:max_activation} has been applied to exhaustion). The constraint \lstinline|get_max/2| triggers the final maximum computation and binds the chunk and its activation to its parameters:

\begin{lstlisting}
get_max(MN,MA), max(N,A), threshold(RT) <=> 
  A >= RT | 
  MN=N,
  MA=A.
  
get_max(MN,MA), max(_,A), threshold(RT) <=> 
  A < RT | 
  MN=nil,
  % set activation to threshold
  MA=RT,
  write('No chunk has high enough threshold'),nl.
  
get_max(MN,MA), threshold(RT) <=>
  MN=nil,
  % set activation to threshold if no chunk matches
  MA=RT,
  write('No chunk matches.'),nl.
\end{lstlisting}

The first rule is applied in case of the activation of the maximal chunk being higher than the threshold. Then, the chunk and its activation are simply returned.

In the second rule, the matching chunk with the highest activation does not pass the threshold. Then no chunk can be returned, so the result of the \lstinline|get_max| request is \lstinline|nil|. The activation of this empty chunk is set to the threshold, because the retrieval latency, i.e. the time the retrieval request takes depends on the threshold in case that no chunk could be found. So this value is used later.

The last rule will only be applied if both of the other rules did not match. This is the case, if there has no \lstinline|max| constraint been put to the store, which only occur, if no chunk matched the request. This also leads to an empty chunk as a result.

\paragraph{New Module Request Interface}

Requests that regard the subsymbolic layer need some additional information and return some additional results: First, somehow the \emph{Context}, i.e. all chunks that are in the values of the buffer chunks, have to be passed from the buffer system to the requested module (in this case the declarative module, but it may be possible that there are other modules which need the context). Additionally, the requested module has to return the time it takes, since every request may take a different time that is only known by the module, but has to be considered by the scheduler of the procedural module.

The interface from section~\ref{interface_for_module_requests} changes to:

\begin{lstlisting}[label=lst:imodule_final, caption={The final version of the interface \emph{IModule}}]
module_request(+BufName, +ChunkDef, +Context, -ResChunk, -ResState, -ResTime) 
\end{lstlisting}

where \lstinline|Context| is a list of the chunk names that are in the current context (as defined in section~\ref{current_context} on page~\pageref{current_context}) and \lstinline|ResTime| is bound to the time the request will take. As described in section~\ref{changing_the_buffer_system} on page \pageref{changing_the_buffer_system}, the buffer actions are divided in two phases: The first only schedules the second phase at the time when the action is finished, whereas the second phase actually performs the action, i.e. the changes to the buffers.

A similar method as for the buffer modifications or clearings is applied for buffer requests: They are divided into three rules with three trigger constraints -- \lstinline|buffer_request/2|, \lstinline|start_request/2| and \lstinline|do_buffer_request/2| -- similar to the division into two rules as already described in section~\ref{changing_the_buffer_system} on page~\pageref{changing_the_buffer_system} for the other actions. The difference is that, since a request may take a certain time, the first rule schedules the start of the request with the priority \lstinline|0|, so all other types of buffer actions have been performed. The request is actually performed immediately when calling \lstinline|start_request|, but the effects to the requested buffer are applied not until \lstinline|do_buffer_request| is called, which is scheduled at the result time (\lstinline|ResTime|) of the request. This is due to the dependence of the latency of a request on the activation values of the matching chunks, so the request has to be performed in advance to calculate the correct time it will take, so the result has to be known before the request ends in simulation time. This yields the following code in the buffer system:

\begin{lstlisting}[caption=Schedule the start of a buffer request, escapeinside={(*@}{@*)}]
buffer_request(BufName, Chunk) <=>
  get_now(Now),
  add_q(Now,0,start_request(BufName,Chunk)).
\end{lstlisting}

\begin{lstlisting}[caption=Execute the buffer request and schedule time the result is applied, label=lst:schedule_buffer_request, escapeinside={(*@}{@*)}]
buffer(BufName, ModName, _) \ start_request(BufName, Chunk) <=> 
  write('Started buffer request '),
  write(BufName),nl,
  get_now(Now),
  buffer_state(BufName,busy),
  do_buffer_clear(BufName), % clear buffer immediately
  get_context(Context), (*@\label{lst:schedule_buffer_request:context}@*)
  ModName:module_request(BufName, Chunk, Context, ResChunk,ResState,RelTime),
  performed_request(BufName, ResChunk, ResState), % save result of request
  Time is Now + RelTime, 
  add_q(Time, 0, do_buffer_request(BufName, Chunk)).
\end{lstlisting}

In line~\ref{lst:schedule_buffer_request:context} the current context is calculated and bound in form of a list of chunk names to the variable \lstinline|Context|.
  
\begin{lstlisting}[caption=Apply the results of the buffer request]
do_buffer_request(BufName, _), buffer(BufName, ModName, _), buffer_state(BufName,_), performed_request(BufName, ResChunk, ResState) <=>  
  write('performing request: '),write(BufName),nl,
  (ResState=error, 
  buffer(BufName, ModName, nil),
  buffer_state(BufName,error) ;  
  
  ResState = free,
  ResChunk = chunk(ResChunkName,_,_),
  add_chunk(ResChunk), 
  buffer(BufName, ModName, ResChunkName),
  buffer_state(BufName,free)).  
\end{lstlisting}

Note that a buffer request has the lowest priority of all buffer actions, as shown in table~\ref{tab:action_priorities}. If the request was performed before the buffer modifications and clearings have taken effect, the wrong context would be used for the activation calculations.

\paragraph{Adapting the Retrieval Request}

With the now defined methods, the overall activation of a chunk can be calculated. The module request for the retrieval buffer as introduced in listing~\ref{lst:retrieval_request_symbolic} can be adapted as follows:

\begin{lstlisting}[caption={Retrieval request with subsymbolic calculations}, escapeinside={(*@}{@*)}]
<<module_request(retrieval, chunk(Name,Type,Slots), Context, ResChunk, ResState, RelTime)>> <=> 
  find_chunk(Name,Type,Slots), (*@\label{lst:retrieval_request_subsymbolic:find_chunk1}@*)
  collect_matches(Res), (*@\label{lst:retrieval_request_subsymbolic:find_chunk2}@*)
  % trigger activation calculation for matching chunks regarding given context
  calc_activations(Res,Context), (*@\label{lst:retrieval_request_subsymbolic:calc_activations}@*)
  
  % find threshold for maximum check
  get_conf(rt,RT), (*@\label{lst:retrieval_request_subsymbolic:threshold1}@*)
  threshold(RT), (*@\label{lst:retrieval_request_subsymbolic:threshold2}@*)
  
  get_max(MaxChunk,MaxAct), (*@\label{lst:retrieval_request_subsymbolic:max}@*)
  
  % Return resulting chunk, state and time
  return_chunk(MaxChunk,ResChunk), (*@\label{lst:retrieval_request_subsymbolic:return_chunk}@*)
  get_state(ResChunk,ResState), (*@\label{lst:retrieval_request_subsymbolic:get_state}@*)
  calc_time(MaxAct,RelTime). (*@\label{lst:retrieval_request_subsymbolic:calc_time}@*)
\end{lstlisting}

\begin{description}
 \item[Find matching chunks] (lines~\ref{lst:retrieval_request_subsymbolic:find_chunk1}~and~\ref{lst:retrieval_request_subsymbolic:find_chunk2}) First of all, all matching chunks are searched and saved in a list called \lstinline|Res|, similarly to the symbolic approach in listing~\ref{lst:retrieval_request_symbolic}.
 \item[Calculate Activations of the matching chunks] (line~\ref{lst:retrieval_request_subsymbolic:calc_activations}) The activations of the matching chunks in the list \lstinline|Res| are computed regarding the context that has been handed over by the request.
 \item[Get the threshold] (lines~\ref{lst:retrieval_request_subsymbolic:threshold1}~and~\ref{lst:retrieval_request_subsymbolic:threshold2}) The current threshold is retrieved from the configuration and a \lstinline|threshold| constraint is placed in the store. The next steps will need a threshold constraint present.
 \item[Find chunk with highest activation] (line~\ref{lst:retrieval_request_subsymbolic:max}) The chunk with the highest activation is saved in \lstinline|MaxChunk|, its activation value in \lstinline|MaxAct|.
 \item[Return a chunk specification] (line~\ref{lst:retrieval_request_subsymbolic:return_chunk}) The request is supposed to return a complete chunk specification in the variable \lstinline|ResChunk|. This is achieved by \lstinline|return_chunk|.
 \item[Return the resulting state of the buffer] (line~\ref{lst:retrieval_request_subsymbolic:get_state}) The resulting state \lstinline|ResState| of the requested retrieval buffer is \lstinline|free|, if a matching chunk has been found and \lstinline|error| if no chunk matches the request:
 
\begin{lstlisting}
get_state(nil,error).
get_state(_,free).
\end{lstlisting}

 \item[Return the time the request takes] (line~\ref{lst:retrieval_request_subsymbolic:calc_time}) The time depends on the activation of the chunk. If no matching chunk has been found, the activation is assumed to be the threshold value. This is already achieved by the maximum calculation as described above. According to equation~\eqref{eq:retrieval_latency}, the resulting time is computed as follows:
 
\begin{lstlisting}
calc_time(Act,ResTime) :-
  get_conf(lf,F),
  ResTime=F*exp(-Act). 
\end{lstlisting}
\end{description}

\subsubsection{Configuration of the Retrieval}

ACT-R offers some configuration variables which influence the retrieval process. In the CHR implementation, some of those configuration variables are implemented in the system according to the configuration infrastructure as described in section~\ref{configuration}. In ACT-R, configuration variables are set with the command \lstinline|(sgp :Var Val)| which sets the value of the variable \lstinline|Var| to \lstinline|Val|. 

\begin{description}
 \item[Turn on the subsymbolic layer] The variable \lstinline|esc| that can be set to \lstinline|t| for \emph{true} and \lstinline|nil| for \emph{false} controls the activation of the subsymbolic layer for retrieval requests. In CHR, the declarative module observes the value of this variable by the observer interface presented in section~\ref{configuration}. Depending on the value of the variable, the constraint \lstinline|subsymbolic/0| is present or not:
 
\begin{lstlisting}
% subsymbolic layer turned on -> add subsymbolic constraint
set_subsymbolic(t), subsymbolic <=> 
  subsymbolic.
set_subsymbolic(t) <=> 
  subsymbolic.

% subsymbolic layer turned off -> remove subsymbolic constraint
set_subsymbolic(nil), subsymbolic <=> 
  true.
set_subsymbolic(nil) <=> 
  true.
\end{lstlisting}

For each rule only involved in the subsymbolic layer, the \lstinline|subsymbolic| constraint is added to its kept head, so the rule only fires if the subsymbolic layer is turned on.

\item[Retrieval threshold] The retrieval threshold $\theta$ is set by the configuration variable \lstinline|rt|.
\item[Latency factor] The latency factor $F$ is set by the configuration variable \lstinline|lf|.
\item[Proportion of $\theta$ and $F$] The configuration system automatically sets the latency factor if the retrieval threshold is set. If an individual value for $F$ should be set, then the automatically set value has to be overwritten after the threshold has been set.

\begin{lstlisting}
latency-factor-by-threshold @
set_conf(rt,RT) ==> 
  LF is 0.35*exp(RT), 
  set_conf(lf,LF). 
\end{lstlisting}

\item[Decay parameter] The decay parameter $d$ is set by the configuration variable \lstinline|bll|.

\end{description}


\subsection{Conflict Resolution and Production Utility}

If there are competing strategies that match a current state, the production system selects the rule with the highest production utility to fire. This process is called \emph{conflict resolution} in the terminology of production rule systems and is described in the following.

\subsubsection{Conflict Resolution}
\label{implementation:conflict_resolution}

In \cite[151\psqq]{fru_chr_book_2009} a general implementation of conflict resolution in CHR is described. This approach can be easily adapted to the needs of ACT-R. Replace every production rule

\begin{lstlisting}
<<{buffer tests} \ fire>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

with two rules

\begin{lstlisting}[caption={Translation scheme for production rules regarding conflict resolution}, label=lst:conflict_resolution_scheme]
<<<delay-name>>> @
  <<fire, {buffer tests}>> ==> {guard} | conflict_set(name).
<<<name>>> @
  <<{buffer tests}, apply_rule(name)>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

The first rule adds the matching rule to a conflict set without computing anything, the second rule actually performs the calculations as soon as the \lstinline|apply_rule| constraint is present.

At the end, add a rule

\begin{lstlisting}
<<<no-rule>>> @
  <<fire>> <=> conflict_set([]), choose.
\end{lstlisting}

As soon as the \lstinline|fire| constraint is present (so the recognize cycle/conflict resolution process begins), each matching rule adds a \lstinline|conflict_set/1| constraint with its name. The last rule finishes the recognize cycle by deleting the fire constraint \emph{after} all rules that match had their chance to add a \lstinline|conflict_set| constraint. Then an empty \lstinline|conflict_set| constraint, indicated by \lstinline|[]|, is added. At the end of this phase, the constraint store contains a bunch of \lstinline|conflict_set| constraints that represent the matching rules plus an empty \lstinline|conflict_set| constraint. If no rule matches, there is only an empty \lstinline|conflict_set| constraint in the store.

The last rule also triggers the choosing process by adding the constraint \lstinline|choose|. The following rules handle the choosing process:

\begin{lstlisting}
<<conflict_set(_) \ conflict_set([])>> <=> true.
  
<<<find-max-utility>>> @ <<production_utility(P1,U1), production_utility(P2,U2), conflict_set(P1) \ conflict_set(P2)>> <=>
  <<<U1 >= U2>>> |
  true.
\end{lstlisting}

The first rule deletes the empty \lstinline|conflict_set| constraint, if there has been an applicable production rule which is recognized by other \lstinline|conflict_set| constraints present. 

The second rule assumes, that for each production rule \lstinline|p| in the procedural memory there is a \lstinline|production_utility(p,u)| constraint that holds the utility value \lstinline|u| of the production \lstinline|p|. If there are two \lstinline|conflict_set| constraints in the store, the one with the higher utility value will be kept and the other will be removed from the store.

If the rules have been applied to exhaustion, there is only one \lstinline|conflict_set| constraint in the store -- either an empty one ore one with the name of a rule. The following rules handle the choosing process:

\begin{lstlisting}
<<choose, conflict_set([])>> <=>
  no_rule.

<<<choose>>> @ <<choose, conflict_set(P)>> <=>
  <<<P \== []>>> |
  get_now(Now),
  Time is Now + 0.05,
  add_q(Time,0,apply_rule(P)). 
\end{lstlisting}

The first rule is only applicable, if there were no matching rules and the empty conflict-set, indicated by the \lstinline|conflict_set([])| constraint, is still present. Then this fact is indicated by a \lstinline|no_rule| constraint.

In the second rule, the firing of the last remaining rule is scheduled 50\,ms from the current time, as it is described in section~\ref{procedural_knowledge}. The event is the \lstinline|apply_rule(P)| constraint, which leads the second rule in listing~\ref{lst:conflict_resolution_scheme} to fire, which performs the actions of the rule.

When the chosen production rule is applied, its actions are performed and eventually a \lstinline|conflict_resolution| constraint is added to the store. This constraint leads the next conflict resolution event to being scheduled:

\begin{lstlisting}
<<now(Time) \ conflict_resolution>> <=> add_q(Time,-10,fire).
\end{lstlisting}

The event is scheduled at the current time with very low priority, i.e. a priority lower than all requests, so all the actions of the rule have had the chance to be executed. If there was no matching rule, the \lstinline|no_rule| constraint is in the store. This leads the next conflict resolution event to be scheduled after the next event (which may lead to a change of the system state):

\begin{lstlisting}
<<no_rule>> <=> after_next_event(fire).
\end{lstlisting}

Note that the described method of implementing the conflict resolution process of ACT-R, matches exactly the description in the reference manual:

\begin{quote}
``The procedural module will automatically schedule conflict-resolution events. The first one is
scheduled at time 0 and a new one is scheduled after each production fires. If no production is
selected during a conflict-resolution event then a new conflict-resolution event is scheduled to occur
after the next change occurs.'' \cite[156]{actr_reference}
\end{quote}

In \cite{fru_chr_book_2009}, the \lstinline|conflict_set| and \lstinline|apply_rule| constraints also have the values of the variables that have been bound in the matching of the rule in the collecting phase:\footnote{The example is slightly modified from the original in \cite{fru_chr_book_2009}: In the original, the name of the rule does not play a role and the priorities are known in advance} 

\begin{lstlisting}
<<<delay-name>>> @
  <<fire, {buffer tests}>> ==> {guard} | conflict_set(rule(name, {Variables in the head of the rule})).
<<<name>>> @
  <<{buffer tests}, apply_rule(rule(name, {Variables in the head of the rule}))>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

This is due to the fact that during the conflict resolution process other rules may have changed the constraint store and the rule might not be applicable anymore. However, in ACT-R the procedural module is a serial bottleneck, so no rules that change the state of the buffer system can be applied during the conflict resolution. Additionally, in \cite{fru_chr_book_2009} the rules that were in the conflict set but have not been applied, remain in the conflict set for the next cycle and are applied, if they have at some point the highest priority in the set and are still applicable (ensured by the bound variables in \lstinline|apply_rule|). In ACT-R, this does not play a role, since the recognize-act cycle is defined serially and only one rule is applied in each cycle. In the next cycle, all rules are checked again for matching heads and the computations are performed on the new values. Note that the problem of trivial non-termination of propagation rules described in \cite[5]{abdennadher_sts_chr13}, which has to be considered when changing the operational order of rule applications in CHR, does not play a role for ACT-R, since it does not implement propagation rules.

\subsubsection{Computing the Utility Values}

As described in section~\ref{production_utility}, rules can have a certain amount of reward that can be distributed among all rules that have been applied since the last reward has been distributed. The reward a rule can distribute, can be saved in a \lstinline|reward/2| constraint. If a rule is applied, the time of application can be saved in a \lstinline|to_reward/2| constraint which states that the rule in the constraint has been applied and therefore receives a part of the next reward as soon as it occurs: 

\begin{lstlisting}
<<apply_rule(P)>> ==> <<<P \== []>>> | get_now(Now), to_reward(P,Now).
\end{lstlisting}

Note that the \lstinline|apply_rule/1| constraint from the last section is used to determine when a rule is fired. When a rule that can distribute a reward is applied, the reward is triggered:

\begin{lstlisting}
<<apply_rule(P), reward(P,R)>> ==>
  <<<P \== []>>> |
  trigger_reward(R).
\end{lstlisting}

This will reward all rules that have a \lstinline|to_reward/2| constraint in the store which leads to a new production utility value:

\begin{lstlisting}[escapeinside={(*@}{@*)}, label=lst:trigger_reward]
<<trigger_reward(R) \ production_utility(P,U), to_reward(P,FireTime)>> <=>
  calc_reward(R,FireTime,Reward),
  get_conf(alpha,Alpha),
  NewU is U + Alpha*(Reward-U), (*@\label{lst:trigger_reward:learning}@*)
  production_utility(P,NewU).
  
calc_reward(R,FireTime,Reward) :- (*@\label{lst:trigger_reward:calc_reward}@*)
  get_now(Now),
  Reward is R - (Now-FireTime).
\end{lstlisting}

Note that in line~\ref{lst:trigger_reward:learning} the utility is adapted by the utility learning rule as shown in equation~\eqref{eq:utility_learning}. The reward the rule receives is calculated by the Prolog predicate in lines~\ref{lst:trigger_reward:calc_reward} sqq.: The more time passed since the rule application, the less is the reward of the rule.

In the end, there has to be a rule that cleans up the reward trigger, after all the rules have been rewarded. This ensures, that the next \lstinline|to_reward| constraints are not immediately consumed by the last reward trigger:

\begin{lstlisting}
<<trigger_reward(_)>> <=> true.
\end{lstlisting}

\subsubsection{Configuration of the Conflict Resolution}

There are some methods to influence the conflict resolution process using the ACT-R command \lstinline|(spp ...)| that sets values for individual production rules. This command is translated into CHR as described in section~\ref{lisp_functions}. Additionally, there are some configuration variables that can be set -- as described in section~\ref{configuration} -- by the command \lstinline|(sgp ...)|:

\begin{description}
 \item[Setting the utility of a rule] Utilities can be set statically by the user by the ACT-R command \lstinline|(spp P :u U)| which sets the utility of the rule \lstinline|P| to \lstinline|U|.
 \item[Setting the reward of a rule] The amount of reward a rule can distribute is set by the user. By default, no rules have a reward to trigger. With the ACT-R command \lstinline|(spp P :reward R)|, the reward of the rule \lstinline|P| is set to \lstinline|R|. This command is also implemented among the standard lisp methods.  
 \item[Default values and turning the utility mechanisms off] At the moment, there is no command in the CHR implementation that allows to turn off the conflict resolution mechanisms: The system sets a default utility value for each production rule and no rewards in the initialization process (the rule \lstinline|init @ run <=> ...| as described in section~\ref{initialization}). The user is able to set other initial utility values and rewards for particular rules. If no rewards are set, the utility values will remain at their initial values. Hence, if the user does not set any utilities or rewards, each rule will have the same utility value that does not change. If there are competing rules, the conflict resolution process will pick one. This can be regarded as turned off utility mechanisms.
 \item[Learning rate] The learning rate $\alpha$ is set by the command \lstinline|(sgp :alpha A)| that sets the configuration variable \lstinline|alpha| to \lstinline|A|.
\end{description}

\subsubsection{Public Methods of the Conflict Resolution}
\label{implementation:icore_interface}

Since the scheduler has to have access to the constraints \lstinline|fire/0| and \lstinline|apply_rule/1| to control the timing conflict resolution, those constraints are added to the \emph{ICore} interface as described in section~\ref{implementation:components}. Additionally, the constraint \lstinline|set_production_utility/2| is added to the \emph{ICore} interface, because the utilities may be set from outside the procedural module initially.

\section{Compiler}

With the implementation of the basic ACT-R concepts, a simple compiler has been created to automate the translation of Lisp ACT-R rules to CHR rules according to the translation schemes defined in section~\ref{implementation:procedural_module}. The compiler has been built using Prolog and CHR. However, it still lacks suitable translation of some of the details in the procedural module presented in section~\ref{implementation:production_rule_grammar}.

\subsection{Basic Idea}

The basic idea of the compiler is that it gets an ACT-R model definition written in the Lisp-like ACT-R syntax and produces the correspondent CHR rules. The model should be executable by just loading the translation and typing in the query \lstinline|run|. Hence, the translated model should somehow load the CHR framework simulating ACT-R, for instance the modules, the buffer system, the scheduler, etc. %Figure~\ref{fig:basic_idea} illustrates the process.

\subsection{Compiling}

The compiler consists of three parts: A tokenizer, a parser and an actual translation component. Those three parts are described individually in the following sections.

\subsubsection{Tokenizer}

The tokenizer gets the file with the model definition as input and does some preprocessing on it: From the input -- a sequence of characters -- it builds a list of tokens. Tokens are separated by white-space (or by special characters) and can be one of the following character sequences in the input:

\begin{description}
 \item[Special Characters] are individual tokens and are defined as all allowed characters that are not letters, numbers or white-space. In ACT-R, the symbols \lstinline|!, (, ), +, -, =, >, ?| are considered special characters. Some special characters of ACT-R are missing in this list, but are not implemented in the compiler, yet.
 \item[Keywords] are treated like a special character, but contain more than one symbol. In ACT-R, one of the keywords is \lstinline|==>|, separating the LHS from the RHS of a production rule.
 \item[Identifiers] Every character sequence which starts with a letter and contains only letters or numbers. An identifier ends, if a special character or a white-space is read from the input. The \lstinline|-| character is an exception, because it can be used within identifiers, although it is a special character.
 
 \emph{Example:} \lstinline|count, addition-fact, chunk1|
 \item[Numbers] Every word that only contains digits \lstinline|0-9|. As for every token, a number ends, if a white-space, a special character or a keyword occurs.
\end{description}

\begin{example}[Tokenizing some input]
The input 

\begin{lstlisting}
(p name
  =buffer>
    s  v
==>
  +buffer>
    s  new-value
  -buffer2>
)
\end{lstlisting}

produces the output list

\begin{lstlisting}
['(',p,name,=,buffer,>,s,v,==>,+,buffer,>,s,new-value, -,buffer2,>,')']
\end{lstlisting}
\end{example}

The basic idea for the implementation of such a tokenizer is described in~\cite[19\psqq]{prolog_tokenizer}. It basically follows a deterministic finite automaton with the state transitions as illustrated in figure~\ref{fig:tokenizer_automaton}.

\begin{figure}[htb]
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=5cm,
                    semithick]
  \tikzstyle{every state}=[fill=none,draw,text=black,minimum size=1.5cm]

  \node[initial,state,accepting] (start)                            {start};
  \node[state]                   (identifier) [right of=start]      {identifier};
  \node[state]                   (number)     [below of=start]      {number};
  \node[state]                   (fail)       [below right of=start] {fail};

  \path (start)      edge [loop above] node {break} (start)
                     edge [bend left]  node {letter} (identifier)
                     edge [bend left]  node {digit}  (number)
                     edge              node {otherwise} (fail)
        (identifier) edge [loop above] node {letter, number, $\{ \mathtt{-} \}$} (identifier)
                     edge [bend left, above]  node {break $\setminus \{\texttt{-}\}$} (start)
                     edge [bend left] node {otherwise} (fail)
        (number)     edge [loop below] node {number} (number)
                     edge [bend left]  node {break} (start)
                     edge [bend right]  node {letter} (fail)
        (fail)       edge [loop below] node {*} (fail);
\end{tikzpicture}
\caption{The finite automaton implemented by the tokenizer. The labels of the arrows are sets of symbols, e.g. \emph{letter} denotes all characters that are letters. The class \emph{break} is the union of the classes  \emph{white-space}, \emph{keyword} and \emph{special character}.}
\label{fig:tokenizer_automaton}
\end{figure}


In Prolog, text input can be handled as a list of ASCII character codes. To classify those characters according to the list above, some predicates and facts can be used:

\begin{lstlisting}
digit(D) :- 46 < D, D < 59.
special_char(33). %!
special_char(40). %(
...
\end{lstlisting}

The tokenizer gets a list of such character codes and returns a list of tokens:

\begin{lstlisting}
getTokens([], []).

getTokens([X|Xs], Ts) :- 
  white_space(X),
  getTokens(Xs,Ts). 
  
getTokens(In, [T|Ts]) :- 
  getToken(start, In, Rest, T), !, 
  getTokens(Rest, Ts).
\end{lstlisting}

The first predicate is the base case. The second rule just drops the white-space and calls the tokenizing predicate again with the rest of the list. The last predicate only applies if the other predicates failed. It starts the inspection of the symbols by calling the predicate \lstinline|getToken(Q,In,Rest,T)| which gets the \lstinline|start| state as argument \lstinline|Q| and the current input list \lstinline|In| and returns the rest of the list and the result token \lstinline|T|, after some input has been processed. The \lstinline|getToken| predicate starts in the start state and then decides deterministically which of the state transitions is chosen by inspecting the first character from the input list. It then remains in the state according to the state transition diagram in figure~\ref{fig:tokenizer_automaton} until it reads a character that forces it to leave the state. Then it binds the remaining input to the list \lstinline|Rest| and all the characters that have been consumed in this state to the result token \lstinline|T|. For the identifiers, the following implementation is used:

\begin{lstlisting}
getToken(start, [X|Xs],Rest,LT) :-
  letter(X), 
  getToken(identifier, Xs,Rest,[X],T), % find rest of word
  downcase_atom(T,LT). % convert uppercase letters to lowercase
  
getToken(identifier, [C|R],Rest,S,T) :-
  (letter(C); digit(C); minus(C)), 
  getToken(identifier,R,Rest,[C|S],T).
  
getToken(identifier,Rest,Rest,S,W) :-
  reverse(S,S1),
  atom_chars(W,S1). 
\end{lstlisting}

The first predicate checks, if the list starts with a letter. It then changes the state to \lstinline|identifier|, because only identifiers start with a letter. The predicate \lstinline|getToken/5| has an accumulator list as an additional argument to the original \lstinline|getToken/4| predicate. It remains in the state identifier, if it reads a letter, a digit or the symbol~\lstinline|-| and accumulates the read symbol in a list (second predicate). If the second predicate cannot be applied any more, because the input list starts with a symbol that is not allowed for an identifier, the third predicate binds this remaining input to the list \lstinline|Rest| and returns the reversed accumulated characters as token. The first predicate then changes the case of the token to lowercase and returns it to \lstinline|getTokens|, which changes the state to \lstinline|start| and begins the next cycle, until the complete input has been consumed. The implementation for digits is analogous.

The arrow keyword is handled separately by a predicate which, as shown in the following listing, consumes the three characters \lstinline|==>| at once. This predicate has to be the first to be checked.

\begin{lstlisting}
getToken(start, [61,61,62|Rest], Rest, '==>').
\end{lstlisting}

Note that the processing fails, if a not-allowed symbol is read from input, so all of the \lstinline|getToken| predicates fail.

\subsubsection{Parser}

The parser takes a list of tokens as input and returns a parse tree. It is implemented by the use of Definite Clause Grammar Rules (DCG rules), which allow to directly write grammar-like rules like:

\begin{lstlisting}
s --> [a], s, [b].
s --> [].
\end{lstlisting}

This program recognizes the language $\{ a^nb^n \enspace | \enspace n \leq 0 \}$. The query \lstinline|s([a,a,b,b],[])| returns \lstinline|true|, whereas \lstinline|s([a,b,b],[])| returns \lstinline|false|. An introduction to DCG rules is given in~\cite{ogb_dcg}.

Hence, the grammar in section~\ref{implementation:production_rule_grammar} can be translated almost directly to such DCG rules. However, this only returns if the input list is a word of the defined grammar. To get a parse-tree out of the parsing process, the rules can be extended according to the following scheme:

\begin{lstlisting}
a(a(B,C)) --> b(B), c(C).
b(b(B)) --> ...
c(c(C)) --> ...
\end{lstlisting}

I.e., the path taken by the program is accumulated in an argument as a term. A result of the example could be \lstinline|a(b(...),c(...))|.

\subsubsection{Translation Component}

In the translation component, CHR rules are generated from the parse-tree according to the methods discussed in this chapter. For the output, a writer that has been presented in the exercises of the \emph{Rule-Based Programming} lecture at the University of Ulm by Amira Zaki \cite{chr_homepage} has been used.

The translation component also organizes the complete parsing process: It loads the input file, calls the tokenizer and the parser and then recursively analyzes the resulting parsing tree. Whenever an ACT-R production rule has been processed completely, it produces a CHR rule using the writer.

For the variables in the rules, it uses a symbol table for each rule to ensure that the same variable is always translated to the same Prolog variable in the result.

\subsection{Limitations of the Current Implementation}
\label{implementation:compiler:problems}

The current implementation of the compiler can be improved at some points. First of all, it can only process a subset of the grammar that actually is a subset of the simplified grammar shown in section~\ref{implementation:production_rule_grammar}. For example, it is only able to parse the negation slot-modifier, the others are not implemented yet, but can be added easily in the future.

The formulation of the grammar also differs from the original definition, so for future work, it would be advantageous to assimilate the two grammars. Additionally, lists have been implemented very complicated in the DCG rule grammar and could be simplified by using actual Prolog lists instead of constructs like \lstinline|tests --> test, tests; test|, which make the parse tree very complicated. Instead, the tree could be simplified to \lstinline[mathescape]|tests([t$_\mathtt{1}$, ... , t$_\mathtt{n}$])|.

Another problem is that duplicate slot tests as shown in section~\ref{implementation:duplicate_slot_tests} on page~\pageref{implementation:duplicate_slot_tests} cannot be handled by the compiler yet.

The recursive approach of the translation component can get very confusing the more rules are added, because a lot of help data has to be accumulated and passed between the different recursion levels (sometimes upwards, sometimes downwards). Another approach could be to store the data that is parsed at a certain level in the constraint store. Eventually, some CHR rules put the parts together in the end.

Finally, the compiler does not produce any error messages, but only fails silently if there are syntactical problems in the input. For usability, it would be helpful to add meaningful error messages.
