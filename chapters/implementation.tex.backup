\chapter{Implementation of ACT-R in CHR}
\label{implementation}

After the comprehensive but at some point informal overview of the ACT-R theory in chapter \ref{actr_description}, this chapter presents a possible implementation of the described concepts of the ACT-R theory in CHR. Note that this work only regards the fundamental concepts of ACT-R and abstracts from some details. For example, the experiment environment as described in section~\ref{experiment_environment} is ignored.

For the implementation, some special cases and details that are not exactly defined in theory have to be considered. Hence, some concepts of the theory that are implemented in this work are formalized first. The implementation in form of CHR rules sticks to those formalisms and is often very similar to them.

Additionally, the implementation is described incrementally, i.e. first, a very minimal subset of ACT-R is presented that will be refined gradually with the progress of this chapter. In the end, an overview of the actual implementation as a result of this work is given.

Some of the definitions in this chapter result directly from the theory, some of them needed a further analysis of the official ACT-R 6.0 Reference Manual \cite{actr_reference} or the tutorials \cite{actr_tutorial}. 

\section{Declarative and Procedural Knowledge}

The basic idea of the implementation is to represent declarative knowledge, working memory etc. as constraints and to translate the ACT-R production rules to CHR rules. This approach leads to a very compact and direct translation of ACT-R models to Constraint Handling Rules.

In addition to the production rules there will be rules that implement parts of the framework of ACT-R, for example rules that implement basic chunk operations like modifying or deleting chunks from declarative memory or a buffer. Those parts of the system are described as well as the central data structures and the translation.

First, a formalization of declarative knowledge in form of chunk networks and their implementation in CHR is given. Then, the working memory -- also referred to as the buffer system -- is explored and the implementation is discussed. After those definitions of the basic data structures of ACT-R, the procedural system is described including the translation of ACT-R production rules to CHR rules using the previously defined data structures.

Furthermore, the reproduction of ACT-Rs modular architecture is shown and the implementation of the declarative module is presented.

After this overview of the basic concepts of ACT-R, the description goes into more detail about timing issues and the subsymbolic layer.

\section{Chunk Stores}

Since chunks are the central data-structure of ACT-R used for representation of declarative knowledge and to exchange information between modules and to state requests, this section first deals with this central part of ACT-R.

\subsection{Formal Representation of Chunks}

In multiple parts of ACT-R it is necessary to store chunks and then operate on then. Hence, the abstract data structure of such a chunk store is defined.

Since chunk stores have been referred to as networks in the previous chapters, the general idea of this definition of a chunk store bases upon a relation that represents such a network.

\begin{definition}[chunk-store]
A \emph{chunk-store} $\Sigma$ is a tuple $(C,E,\mathcal{T},HasSlot,Isa)$, where $C$ is a set of chunks and $E$ a set of primitive elements, with $C \cap E = \emptyset$. $V = C \cup E \cup \{ \mathtt{nil} \}$ are the \emph{values} of~$\Sigma$ and $\mathcal{T}$ a set of chunk-types. A chunk-type $T = (t,S) \in \mathcal{T}$ is a tuple with a \emph{unique}\footnote{$\forall (t,S), (t',S') \in \mathcal{T}: t = t' \Rightarrow S = S'$ } type name $t$ and a set of slots $S$. The set of all slot-names is $\mathcal{S}$. 

$HasSlot \subseteq C \times \mathcal{S} \times V$ and $Isa \subseteq C \times T$ are relations and are defined as follows:

\begin{itemize}
 \item $c \enspace Isa \enspace T \Leftrightarrow$ chunk $c$ is of type $T$.
 \item $(c,s,v) \in HasSlot \Leftrightarrow v$ is the value of slot $s$ of $c$. This can also be written as $c \overset{s}{\longrightarrow} v$ and is spoken ``$c$ is connected to $v$'' or ``$v$ is in the slot $s$ of $c$''.
\end{itemize}

The $Isa$ relation has to be right-unique and left-total, so each chunk has to have exactly one type.

% The following function is defined:
% 
% \begin{align*}
%  %\item $slots: C \rightarrow \mathcal{S} \times V$ \\
%  %$slots(c) = \{ (s,v) | (c,s,v) \in HasSlot \}$ 
%  slots: \mathcal{T} \rightarrow \mathcal{S} &\\
%        slots((t,S)) = S&
% \end{align*}


A chunk-store is \emph{type-consistent}, iff $\forall (c,(t,S)) \in Isa: \forall s \in S \enspace \exists ! (c,s,v) \in HasSlot$. So every chunk must have exactly one value for each slot of its type and only describe slots of its type. Empty slots are represented by the value \lstinline|nil|. Since every chunk has exactly one type, this is valid for all chunks in the store.

%iff $\forall(c,s,v) \in HasSlot: c \enspace Isa \enspace (T,S) \Rightarrow \exists s' \in S: s=s'$ and $\forall c \in C: \enspace c \enspace Isa \enspace (T,S) \Rightarrow \forall s \in S: \exists (c',s',v) \in HasSlot: c=c', s=s'$. 

\end{definition}


\begin{definition}[abstract methods of a chunk store]
\label{def:abstract_methods_chunk_store}
The following methods can be defined over a chunk store $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$:

\begin{description}
 \item[\texttt{chunk-type(name slot\textsubscript{1} slot\textsubscript{2} ... slot\textsubscript{n})}] adds the type $T = (\mathtt{name},\{\mathtt{slot_1}, \dots, \mathtt{slot_n}\})$ to the store, i.e. $\mathcal{T'} = \mathcal{T} \cup \{T\}$. 
 \item[\texttt{add-chunk(name isa type slot\textsubscript{1} val\textsubscript{1} ... slot\textsubscript{n} val\textsubscript{n})}] adds a new chunk to the store, i.e. $C' = C \cup \{ \mathtt{name} \}$, $Isa' = Isa \cup (\mathtt{name}, (\mathtt{type}, slots(\mathtt{type}))$ and $HasSlot' = \bigcup_{i = 1}^n{\mathtt{(name,slot_i,val_i)}} \cup HasSlot.$ Note, that due to the expansion of $C$, the condition that $C$ and $E$ have to be disjoint may be violated. To fix this violation, the element can be removed from $E$: $E' = (E \cup C) - (E \cap C).$ 
 
 Additionally, a valid mechanism to restore type-consistency may be introduced: It might happen, that not all slots are specified in the call of the \lstinline|add-chunk| method. Since it is claimed by the definition of $HasSlot$ that for all slots $s$ of a chunk $c$ there must be a $(c,s,v) \in HasSlot$, in implementations the unspecified slots are initialized as empty slots, represented by the empty value \lstinline|nil|. Furthermore, slots specified in the call of the method that are not a member of the chunk's type should cause an error to preserve type-consistency.
  \item[\texttt{alter-slot(name slot\textsubscript{1} val\textsubscript{1} ... slot\textsubscript{n} val\textsubscript{n})}] changes the slot values of a chunk identified by its name. Only existing slots can be altered.
  \item[\texttt{remove-chunk(name)}] removes the chunk with the given name from $C$ and all of its occurrences in $Isa$ and $HasSlot$.
  \item[\texttt{return-chunk(name)}] gets a chunk name as input and returns a chunk specification, i.e. the name, type and all slot-value pairs of this chunk in the store.
\end{description} 
\end{definition}

\begin{example}
 \label{ex:addition_fact_formal}
 The addition-fact chunk in figure \ref{fig:chunk_addition_fact} and its chunk-type are defined as follows:
 
\begin{lstlisting}
chunk-type(addition-fact arg1 arg2 sum)
add-chunk(a isa addition-fact arg1 5 arg2 2 sum 7)
\end{lstlisting}
 
 This leads to the following chunk-store: 
 \begin{align*}
 (\{a\}, \{2,5,7\},\\ 
 \{(addition-fact, \{arg1, arg2, sum\})\},\\
 \{(a,arg1,5), (a,arg2,2), (a,sum,7)\},\\
 \{(a, addition-fact)\}).
 \end{align*}
 
 $slots(a) = \{(arg1,5), (arg2,2), (sum,7)\}$ and $slots((addition-fact,\{arg1, arg2, sum\}) = \{arg1, arg2, sum\}$. Hence, the store is type-consistent.
\end{example}

\subsection{Representation of Chunks in CHR}

Declarative knowledge is represented as a network of chunks, defined by the two relations $Isa$, specifying the belonging of a chunk to a type, and $HasSlot$, specifying the slot-value pairs of a chunk. Those relations can be translated directly into CHR by defining the following constraints representing the relations and sets:

\begin{lstlisting}
:- chr_constraint chunk_type(+).
% chunk_type(ChunkTypeName)

:- chr_constraint chunk_type_has_slot(+,+).
% chunk_type_has_slot(ChunkTypeName, SlotName).
\end{lstlisting}

The \lstinline|chunk_type/1| constraint represents the set $\mathcal{T}$ of chunk-types in the store, but refers only to the chunk-type names. The set of slots of a chunk-type is specified by the \lstinline|chunk_type_has_slot/2| constraint\footnote{For a chunk-type $T \in \mathcal{T}$, with $T = (t, S)$, there exists a \texttt{chunk\_type(t)} and for every slot $s \in S$ there is a \texttt{chunk\_type\_has\_slot(t,s)} in the constraint store.}.

For the chunks:

\begin{lstlisting}
:- chr_constraint chunk(+,+).
% chunk(ChunkName, ChunkType)

:- chr_constraint chunk_has_slot(+,+,+).
% chunk_has_slot(ChunkName, SlotName, Value)
\end{lstlisting}

The \lstinline|chunk/2| constraint represents both the set $C$ of chunks and the $Isa$ relation, since the presence of a constraint \lstinline|chunk(c,t)| signifies, that chunk \lstinline|c| is of a type $T = (\mathtt{t},S)$.

The $HasSlot$ relation is represented by the \lstinline|chunk_has_slot(c,s,v)| constraint, which really is just a direct translation of an element $(c,s,v) \in HasSlot$.

Note that all values in the just presented constraints have to be ground. This is a demand claimed by the original ACT-R implementation and makes sense, since each value in a slot of a chunk is a real, ground value and the concept of variables does not have an advantage in this context, because every element that can be stored in the brain is assumed to be known by the brain.

Additionally, from the definition of a chunk store it is known, that the $Isa$ relation has to be left-total. Therefore, for every chunk \lstinline|c| in the store, exactly one \lstinline|isa(c,t)| constraint has to be in the store. Due to type-consistency, for each \lstinline|chunk_type_has_slot(t,s)| constraint a \lstinline|chunk_has_slot(c,s,v)| constraint has to be defined. If it should be expressed that a chunk has an empty slot, the special chunk name \lstinline|nil| can be used as slot value to indicate that. Note that \lstinline|nil| must not be the name of a regular chunk or chunk-type.

\begin{example}
\label{ex:addition_fact_chr}
The chunk and chunk-type in example~\ref{ex:addition_fact_formal} are represented as:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)
\end{lstlisting}
\end{example}


\subsubsection{Distinction of Elements and Chunks}
\label{distinction_elements_chunks}

A chunk store distinguishes between a set of chunks $C$ and a set of elements $E$. For implementational reasons it can be helpful if there are only chunks in the system, because elements just behave like chunks with no slots. Hence, a chunk-type \lstinline|chunk| with no slots will be added automatically to the store. Each element $e \in E$ and added as a chunk of type \lstinline|chunk| to the set of chunks $C$. After this operation $E = \emptyset$, and for every former element $e$ of $E$: $e \in C$, $(e,(chunk,\emptyset)) \in Isa$.

So $E$ is represented now by $\{ c \in C | c Isa (chunk,\emptyset)$ in the implementation.

\begin{example}
The chunk representation from example~\ref{ex:addition_fact_chr} is changed to:

\begin{lstlisting}
chunk_type(addition-fact)
chunk_type_has_slot(addition-fact,arg1)
chunk_type_has_slot(addition-fact,arg2)
chunk_type_has_slot(addition-fact,sum)

chunk_type(chunk)

chunk(a,addition-fact)
chunk_has_slot(a,arg1,5)
chunk_has_slot(a,arg2,2)
chunk_has_slot(a,sum,7)

chunk(5,chunk)
chunk(2,chunk)
chunk(7,chunk)
\end{lstlisting}

\end{example}


\subsubsection{Simple Implementation of the Default Methods}
\label{chunk_specification}

To implement the methods in definition~\ref{def:abstract_methods_chunk_store}, first a data type for chunk specifications has to be introduced. From this specification the correct constraints modeling the chunk-store are added or modified.

The straight-forward definition of a data type for chunk specifications is just to use the specification like in definition~\ref{def:abstract_methods_chunk_store}: Since \lstinline|(name isa type slot_1 val_1 \dots slot_n val_n)| is just a list in LISP and specifies a chunk uniquely, a similar Prolog term can be used:

\begin{lstlisting}
:- chr_type chunk_def ---> nil; chunk(any, any, slot_list).
:- chr_type list(T) ---> []; [T | list(T)].
% a list of slot-value pairs
:- chr_type slot_list == list(pair(any,any)).
:- chr_type pair(T1,T2) ---> (T1,T2).
\end{lstlisting}

This definition states that a chunk is either \lstinline|nil|, i.e. an empty chunk, or a term \lstinline|chunk(Name, Type, SVP)|, where \lstinline|SVP| is a list of slot-value pairs. This is the direct translation of the chunk-specification used in the definition, amended by the \lstinline|nil| construct, that may be needed for later purposes.

The default methods can be implemented as follows:

\paragraph{add\_chunk}

This method creates the chunks and elements of the chunk store. The set $E$ of elements is minimal, i.e. only elements that appear in the slots of a chunk but are not chunks themselves are members of $E$. However, the set $E$ is never constructed explicitly, but represented by chunks of the special type \lstinline|chunk| that provides no slots. So each value in the slot of a chunk that is added to the store and that is not an element of the chunk store yet, gets its own chunk of type \lstinline|chunk|. As soon as a chunk with the name of such a primitive element is added to the store, the chunk of type \lstinline|chunk| is removed from the store.

\begin{lstlisting}[caption={Rules for \texttt{add\_chunk}}, label=lst:add_chunk_rules]
% empty chunk will not be added
<<add_chunk(nil)>> <=> true.
  
% initialize all slots with nil
<<add_chunk(chunk(Name,Type, _)), chunk_type_has_slot(Type,S)>> ==> 
  chunk_has_slot(Name,S,nil).

% chunk has been initialized with empty slots -> actually add chunk
<<add_chunk(chunk(Name,Type, Slots))>> <=>
  do_add_chunk(chunk(Name,Type,Slots)).
\end{lstlisting}

First, all \lstinline|chunk_type_has_slot| constraints are added to the store and initialized with \lstinline|nil| as slot value. This leads to complete chunk specifications that are consistent to the type as demanded by a type-consistent chunk-store.

If all slots have been initialized, \lstinline|do_add_chunk| performs the actual setting of the real slot values:
  
\begin{lstlisting}[caption={Additional rules for adding chunks}]  
% base case
<<do_add_chunk(chunk(Name, Type, []))>> <=> 
  chunk(Name, Type). 

% overwrite slots with empty values
<<chunk(V,_) \ do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=>
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).

% overwrite slots with empty values  
<<do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=> 
  <<<V == nil>>> | % do not add chunk(nil,chunk)
  chunk_has_slot(Name,S,V), 
  do_add_chunk(chunk(Name,Type,Rest)).  

% overwrite slots with empty values  
<<do_add_chunk(chunk(Name, Type, [(S,V)|Rest])), chunk_has_slot(Name,S,nil)>>  <=> 
  <<<V \== nil>>> |
  chunk_has_slot(Name,S,V), 
  chunk(V,chunk), % no chunk for slot value found => add chunk of type chunk 
  
<<do_add_chunk(_)>> <=> false.
\end{lstlisting}

The first rule is the base case, where no slots have to be added any more. Then, as a last step the actual \lstinline|chunk| constraint of the chunk that is added to the store is created.

The second rule deals with the case, that a slot-value pair has to be added with a value that is already described by a chunk. Then the \lstinline|nil|-initialized slot of this chunk is removed and replaced by another slot containing the actual value.

The next rule ensures that the helper chunk specification \lstinline|nil| will not get a chunk in the store, even if it is in the slots of a chunk.

Otherwise, if the value of the slot to be added is not \lstinline|nil|, the next rule can fire and the slot with the actual value will replace the previously \lstinline|nil|-initialized slot with the actual value. Additionally, since the first rule obviously did not fire for this constellation, \lstinline|V| is a value different from \lstinline|nil| that does not have a chunk in the store. Hence, it must be a primitive element. Thus a new chunk of type \lstinline|chunk| is added to the store for this value.

If no rule matches, the user tried to create a chunk with slots that are not specified in the chunk-type. This leads to an error.

On top of the rules in listing~\ref{lst:add_chunk_rules}, there must be added a rule that deletes a primitive element (i.e. a chunk of type \lstinline|chunk|), if the user introduces a real chunk with the name of this element:

\begin{lstlisting}[caption={Clean up primitive elements}]  
% delete chunk of Type chunk, if real chunk is added
<<add_chunk(chunk(Name,_,_))>> \ <<chunk(Name,Type)>> <=> 
  <<<Type == chunk>>> |
  true.
\end{lstlisting}


\paragraph{add\_chunk\_type}

The following rules create a new chunk type:

\begin{lstlisting}[caption={rules for \texttt{add\_chunk\_type}}]
<<add_chunk_type(CT, [])>> <=> 
  chunk_type(CT).
<<add_chunk_type(CT, [S|Ss])>> <=> 
  chunk_type_has_slot(CT, S), 
  add_chunk_type(CT, Ss).
\end{lstlisting}

\paragraph{alter\_slot}

This method replaces the value of an existing slot for a given chunk, but only if it is a valid slot for the chunk-type of the altered chunk.

\begin{lstlisting}
<<alter_slot(Chunk,Slot,Value), chunk_has_slot(Chunk,Slot,_)>> <=>
  chunk_has_slot(Chunk,Slot,Value).
  
<<alter_slot(Chunk,Slot,Value)>> <=>
  false.
\end{lstlisting}

The first rule replaces the existing \lstinline|chunk_has_slot| constraint by a new one. This is called \emph{destructive assignment} as described in \cite[32]{fru_chr_book_2009}. The second rule only matches, if the first did not match (due to the refined operational semantics of CHR). This is only the case, if it is tried to alter a slot with a non-existing \lstinline|chunk_has_slot| constraint. However, since the chunk descriptions are complete, the slot cannot be valid for the type of the chunk and the altering has to fail.

\paragraph{remove\_chunk}

This method removes all occurrences of a chunk.

\begin{lstlisting}
<<remove_chunk(Name)>> \ <<chunk(Name, _)>> <=> true.
<<remove_chunk(Name)>> \ <<chunk_has_slot(Name, _, _)>> <=> true.
<<remove_chunk(_)>> <=> true.
\end{lstlisting}

\paragraph{return\_chunk}

This method creates a chunk specification as defined in section~\ref{chunk_specification} from the chunk name of a chunk in the store.

\begin{lstlisting}[caption={rules for \texttt{return\_chunk}}]
<<chunk(ChunkName, ChunkType)>> \ <<return_chunk(ChunkName,Res)>> <=> 
  <<<var(Res)>>> | 
  build_chunk_list(chunk(ChunkName, ChunkType, []),Res).

<<chunk_has_slot(ChunkName, S, V)>> \ <<build_chunk_list(chunk(ChunkName, ChunkType, L), Res)>> <=> 
  <<<\+member((S,V),L)>>> | 
  build_chunk_list(chunk(ChunkName, ChunkType, [(S,V)|L]),Res).
  
build_chunk_list(X,Res) <=> Res=X.
\end{lstlisting}

The first rule creates the initial chunk specification with name and type set, but without any slot specification. This initial representation is handed to the \lstinline|build_chunk_list| constraint.

The second rule adds a slot-value pair from the store to the list of slot-value pairs in the specification and builds the next chunk specification from this new representation.

In the last rule, the process terminates, if no other rule can fire any more. Then the result is bound to the handed specification.

\subsubsection{Checking Consistency and Type-Consistency}

At the moment, there are no rules that check the consistency of the chunk store. However, if the default methods for adding chunks are used, a type-consistent store is built automatically, since for every chunk has exactly one chunk-type\footnote{left-totality and right-uniqueness of $Isa$} and all slots from its chunk-type are described and only those slots are described (satisfies type-consistency). Additionally, there are no two different slot descriptions for the same chunk and every chunk in the store is described\footnote{This is demanded by the type-consistency: Since $Isa$ is left-total, every chunk is in the $Isa$ relation. Type-consisteny demands, that every chunk in the $Isa$ relation has a value for all slots of its type.} (satisfies the definition of a chunk-store).

Rules for checking those constraints could be added easily to the implementation.

\section{Procedural Module}
\label{implementation:procedural_module}

The part of the system, where the computations are performed, is the procedural module. It is the central component, that holds all the production rules, the working memory (in the buffer system) and organizes communication between modules (through buffers and requests). In the following, all of those subcomponents of the procedural module are described.

\subsection{Buffer System}

The buffer system can be regarded as a chunk-store, that is enhanced by buffers. A buffer can hold only one chunk at a time. The procedural module has a set $B$ of buffers, a chunk-store $\Sigma$ and a relation between the buffers and the chunks in $\Sigma$.

\begin{definition}[buffer system]
\label{def:buffer_system}
A \emph{buffer system} is a tuple $(B,\Sigma,Holds)$, where $B$ is a set of buffers, $\Sigma = (C, E, \mathcal{T}, HasSlot, Isa)$ a type-consistent chunk-store and $Holds \subseteq B \times (C \cup \{ \mathtt{nil} \})$ a right-unique and left-total relation, that assigns every buffer at most one chunk that it holds. If a buffer $b$ is empty, i.e. it does not hold a chunk, then $(b,\mathtt{nil}) \in Holds$.

A buffer system is \emph{consistent}, if every chunk that appears in $Holds$ is a member of $C$ and $\Sigma$ is a type-consistent chunk-store.

A buffer system is \emph{clean}, if its chunk-store only holds chunks which appear in $Holds$.
\end{definition}

For the implementation of a buffer system, the code of a chunk-store can be extended by a \lstinline|buffer/2| constraint, that encodes the set $B$ and the relation $Holds$ at once, since the relation is complete by definition\footnote{$\forall b \in B \enspace \exists c \in (C \cup \{ \mathtt{nil} \}): (b,c) \in Holds$}.

\subsubsection{Destructive Assignment and Consistency}
\label{destructive_assignment}

The demand of $Holds$ being right-unique\footnote{$\forall b \in B \enspace \forall c, d \in (C \cup \{ \mathtt{nil} \}): (b,c), (b,d) \in Holds \Rightarrow b = c$} is a form of destructive assignment as described in \cite[p. 32]{fru_chr_book_2009}, i.e. if a new chunk is assigned to a buffer, the old \lstinline|buffer| constraint is removed and a new \lstinline|buffer| constraint is introduced, holding the new chunk:

\begin{lstlisting}
<<set_buffer(B, C) \ buffer(B, _)>> <=> buffer(B, C).
\end{lstlisting}

This rule ensures that only one \lstinline|buffer| constraint exists for each buffer in $B$.

At the beginning of the program, a \lstinline|buffer| constraint has to be added for all the available buffers of the modules. This problem is discussed in section~\ref{initialization}.

In addition, if a new chunk is put into a buffer, it also has to be present in the chunk-store, since the production system relies on the knowledge about the chunks in its buffers and chunks are essentially defined by their slots (\emph{consistency property} in definition~\ref{def:buffer_system}). Hence, every time a chunk is stored in a buffer, the \lstinline|add_chunk| method described in definition~\ref{def:abstract_methods_chunk_store} has to be called. However, the chunks in the slots are not loaded, since they are not present for working memory. They only appear as primitive elements in the chunk-store. Figure~\ref{fig:buffer_system}

%This process is discussed later when talking about buffer requests in section~\ref{buffer_requests}.

\subsubsection{Buffer States}

Another formal detail of the buffer system is that buffers can have various states: \emph{busy}, \emph{free} and \emph{error}. A module is busy, if it is completing a request and free otherwise.

Since a module can only handle one request at a time and requests may need a certain time (like the retrieval request for example), the procedural module could state another request to a busy module. This is called \emph{jamming} which leads to error messages and should be avoided. One technique to avoid module jamming is to \emph{query} the buffer state in the conditional part of a production rule \cite[unit 2, p. 9]{actr_tutorial}. The possibility to query buffer states is discussed in the next section.

A buffer's state is set to \emph{error}, if a request was unsuccessful because of an invalid request specification or, in case of the declarative module for instance, a chunk that could not be found.

In CHR, a buffer state can be represented by a \lstinline|buffer_state(b,s)| constraint, which signifies that buffer \lstinline|b| has the state \lstinline|s|. Since every buffer has exactly one state all the time, it is required, that for every buffer there is such a constraint and it is ensured, that only one \lstinline|buffer_state| constraint is present for each buffer. This can be achieved by the destructive assignment method described in section~\ref{destructive_assignment}. 

At the beginning of the program, when a buffer is created (a \lstinline|buffer| constraint is placed into the store), a corresponding \lstinline|buffer_state| constraint has to be added. The initial state can be set to \lstinline|free|, since no request is being computed at the time of creation.

\subsection{Production Rules}

Production rules consist of a \emph{condition} part and an \emph{action} part. Syntactically, in ACT-R the condition is separated from the action by \lstinline|==>|. Additionally, each production rule has a name. Thus, a rule is defined by:

\begin{verbatim}
(p name condition* ==> action*)
\end{verbatim}

The condition part is also called the \emph{left hand side} of a rule (LHS) and the action part is called \emph{right hand side} (RHS).

\subsubsection{The Left Hand Side of a Rule}

Generally, a condition is either a \emph{buffer test}, i.e. a specification of slot-value pairs that are checked against the chunk in the specified buffer or a \emph{buffer query}, i.e. a check of the state of a buffer's module (either busy, free or error). A buffer test on the LHS of a rule is indicated by a \lstinline|=| followed by the buffer name of the tested buffer; a query is indicated by a \lstinline|?| in front of the buffer name.

The LHS of a rule may contain bound or unbound variables: \lstinline|=varname| is a variable with name \lstinline|varname|.

If the chunks in the buffers pass all buffer tests specified by the rule, the rule can fire, i.e. its right hand side will be applied. The LHS is a conjunction of buffer tests, i.e. there is no specific order for the tests \cite[p. 165]{actr_reference}.

\begin{example}[counting example -- left hand side]
The left hand side of the counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  ... )
\end{lstlisting}

The condition part consists of two buffer tests:

\begin{enumerate}
 \item The goal buffer is tested for a chunk of type \lstinline|count| and a slot with name \lstinline|number|. The value of the slot is bound to the variable \lstinline|=n|.
 \item The retrieval buffer is tested for a chunk of type \lstinline|count-fact| that has the variable \lstinline|=n| in its \lstinline|first| slot (with the same value as the \lstinline|number| slot of the chunk in the goal buffer, since \lstinline|=n| has been bound to that value), and another value in its second slot which is bound to the variable \lstinline|=m|.
\end{enumerate}

\end{example}

\subsubsection{The Right Hand Side of a Rule}

For the right hand side of a rule the following actions are allowed:

\begin{description}
 \item[Buffer Modifications] of the form
\begin{lstlisting}
=buffer>
  s  v
  ...
\end{lstlisting}

They are indicated by the buffer modifier \lstinline|=| right before the buffer name and are specified through a list of slot-value pairs. Note, that this list can be incomplete and must not contain a \lstinline|isa| specification. It leads all slots mentioned in the modification action of a buffer to be replaced by the specified values.

 \item[Buffer Requests] of the form
\begin{lstlisting}
+buffer>
  s  v
  ...
\end{lstlisting}

Requests are indicated by the buffer modifier \lstinline|+| and specified by a list of slot-value pairs. A request will be sent to the module of the specified buffer which reacts to the transmitted chunk of the request specification (in form of the slot-value pairs). The semantics of a request depends on the module, but the buffer is always first cleared before stating the request.
 \item[Buffer Clearings] of the form
 
\begin{lstlisting}
-buffer>
\end{lstlisting}

Clearings are indicated by the buffer modifier \lstinline|-|. When a buffer is cleared, the chunk it contains will be removed from the chunk-store of the buffer system and then be added to the declarative memory. 
\end{description}


\begin{example}[counting example]
\label{ex:counting}
The counting rule specified in the example in section~\ref{example_counting} could be defined as follows:

\begin{lstlisting}
(p count-rule
  =goal> 
    isa    count
    number =n
  =retrieval>
    isa    count-fact
    first  =n
    second =m
==>
  =goal>
    number =m
  +retrieval>
    isa    count-fact
    first  =m
)
\end{lstlisting}
\end{example}

\subsubsection{Direct Translation of Buffer Tests}

An ACT-R production rule of the form

\begin{lstlisting}[mathescape]
(p name
  =buffer$_\mathtt{1}$>
    isa   type$_1$
    slot$_\mathtt{1,1}$  val$_\mathtt{1,1}$
    ...
    slot$_\mathtt{1,n}$  val$_\mathtt{1,n}$
  ...
  =buffer$_\mathtt{k}$>
    isa   type$_\mathtt{k}$
    slot$_\mathtt{k,1}$  val$_\mathtt{k,1}$
    ...
    slot$_\mathtt{k,m}$  val$_\mathtt{k,m}$
==>
... )
\end{lstlisting}

states formally, that:

If $buffer_1 \enspace Holds \enspace c_1 \enspace \wedge \enspace c \enspace Isa \enspace type_1 \enspace \wedge \enspace c_1 \xrightarrow{slot_{1,1}} val_{1,1} \enspace \wedge \enspace \dots \enspace \wedge \enspace buffer_k \enspace Holds \enspace c_k \enspace \wedge \enspace c_k \enspace Isa \enspace type_k \enspace \wedge \enspace \dots$ is true, then the rule matches and the RHS should be performed.

This can be directly translated into a CHR rule:

\begin{lstlisting}[mathescape]
<<<name>>> @
  <<buffer(buffer$_\mathtt{1}$,C$_\mathtt{1}$),
  chunk(C$_\mathtt{1}$,type1),
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,1}$,val$_\mathtt{1,1}$),
  ...
  chunk_has_slot(C$_\mathtt{1}$,slot$_\mathtt{1,n}$,val$_\mathtt{1,n}$),
  ...
  buffer(buffer$_\mathtt{k}$,C$_\mathtt{k}$),
  chunk(C$_\mathtt{k}$,type$_\mathtt{k}$),
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,1}$,val$_\mathtt{k,1}$),
  ...
  chunk_has_slot(C$_\mathtt{k}$,slot$_\mathtt{k,m}$,val$_\mathtt{k,m}$)>>
==>
  ...
\end{lstlisting}

This rule checks the buffer system for the existence of a buffer holding a particular chunk and then checks the chunk store of the buffer system for that chunk with the type and slots specified in the ACT-R rule. The rule is a propagation rule, because the information of the chunk-store should not be removed.

If the values in the slot tests are variables, they can be directly translated to Prolog variables.

The CHR rule only fires, if all the checked buffers hold chunks that meet the requirements specified in the slot tests of the ACT-R rule. Since those slot-tests are just a conjunction of relation-membership tests and the CHR rule is a translation of these tests into constraints, both are equivalent. In detail: 

\begin{itemize}
 \item If a checked buffer \lstinline|b| holds no chunk, the constraint \lstinline|buffer(b,nil)| will be present, but the chunk store will not hold any of the required \lstinline|chunk| or \lstinline|chunk_has_slot| constraints and the rule will not fire.
 \item If a checked buffer \lstinline|b| holds a chunk, but the chunk does not meet one of the requirements in its slots, the rule does not fire.
 \item The rule only fires, if for all checked buffers there are valid \lstinline|buffer|, \lstinline|chunk| and \lstinline|chunk_has_slot| constraints present that meet all the requirements specified by the ACT-R rule.
 \item Variables on the LHS of a rule are bound to the values of the actual constraints that are tried for the matching. After the matching, each variable from the rule has a ground value bound to it, because there are no variables in the implementation of the buffer store. This corresponds to the semantics of an ACT-R production rule with variables on the LHS.
\end{itemize}

\subsubsection{Translation of Actions}
\label{translation_of_actions}

For each action type a constraint

\begin{lstlisting}
buffer_action(buffer,chunk-specification)
\end{lstlisting}

with corresponding rules that handle the action have to be added. Note, that the buffer action is defined by the action name, the buffer name and a chunk specification, because actions in ACT-R are defined through a buffer modifier that specifies the action, the name of the buffer and a list of slot-value pairs. Hence, this is a direct translation to CHR.

\paragraph{Buffer Modifications}

The modification of a buffer takes an incomplete chunk specification and modifies the given slots of the chunk in the specified buffer. This can be implemented as follows:

\begin{lstlisting}
<<buffer(BufName, OldChunk)>> \ <<buffer_change(BufName, chunk(_,_,SVs))>> <=>
  alter_slots(OldChunk,SVs).
\end{lstlisting}

This implementation uses a generalization of the \lstinline|alter_slot| method as described in definition~\ref{def:abstract_methods_chunk_store} and section~\ref{chunk_specification}:

\begin{lstlisting}  
<<alter_slots(_,[])>> <=> true.
<<alter_slots(Chunk,[(S,V)|SVs])>> <=> 
  alter_slot(Chunk,S,V),
  alter_slots(Chunk,SVs). 
\end{lstlisting}

Note that types cannot be changed. This corresponds to the grammar definition of ACT-R as presented in section~\ref{production_rule_grammar}.

\FIXME{add some rules! What about chunk type and chunk name -> not allowed in buffer modification -> mention in text}

\paragraph{Buffer Clearings}

When clearing a buffer, the chunk that was stored in the buffer will be removed from the chunk store and \lstinline|nil| will be written to the store. Additionally, the chunk goes to the declarative memory.

\begin{lstlisting}
<<buffer_clear(BufName), buffer(BufName, ModName, Chunk)>> <=> 
  write_to_dm(Chunk), 
  delete_chunk(Chunk), 
  buffer(BufName, nil).
\end{lstlisting}

\lstinline|write_to_dm| handles the writing of the chunk to the declarative memory:

\begin{lstlisting}
<<write_to_dm(ChunkName)>> <=> return_chunk(ChunkName, ResChunk), add_dm(ResChunk).
\end{lstlisting}

where \lstinline|add_dm| is basically just a global wrapper for the \lstinline|add_chunk| method of the declarative memory and will be explained in section~\ref{global_method_for_adding_chunks}.

\paragraph{Buffer Requests} The buffer requests have to be handled a little bit differently from the other actions. Therefore, they will be explained in section~\ref{interface_for_module_requests}. The changes to the buffer system are presented in section~\ref{how_the_buffer_system_states_a_request} and an example implementation of the module request interface for retrieval requests is given in section~\ref{retrieval_requests}.


\begin{example}[counting example in CHR -- simple]
The production rule in example~\ref{ex:counting} can be translated to:

\begin{lstlisting}
<<<count-rule>>> @
  <<buffer(goal,C1), 
    chunk(C1,count),
    chunk_has_slot(number,N),
  buffer(retrieval,C2),
    chunk(C2,count-fact),
    chunk_has_slot(first,N),
    chunk_has_slot(second,M)>>
==>
  buffer_change(goal,chunk(_,_,[(number,M)])),
  buffer_request(retrieval,chunk(_,count-fact,[first,M)])).
\end{lstlisting}

\end{example}


\subsubsection{Translation of Buffer Queries}

A buffer query

\begin{lstlisting}
...
?buffer>
  state  bstate 
...
==> ...
\end{lstlisting}

on the LHS of a production rule can be translated to the following CHR rule head:

\begin{lstlisting}
...
<<buffer_state(buffer,bstate)>> ... ==> ...
\end{lstlisting}

\subsection{The Production Rule Grammar}
\label{implementation:production_rule_grammar}

The discussed concepts lead to the following grammar for production rules, which is a simplified version of the actual grammar used in the original ACT-R implementation \cite[p. 162]{actr_reference}. 


\begin{lstlisting}{caption={The ACT-R production rule grammar} label=lst:production_rule_grammar}
production-definition ::= (p name condition* ==> action*)
name ::= a symbol that serves as the name of the production for reference
condition ::= [ buffer-test | query ]
action ::= [buffer-modification | request | buffer-clearing | output ]
buffer-test ::= =buffer-name> isa chunk-type slot-test*
buffer-name ::= a symbol which is the name of a buffer
chunk-type ::= a symbol which is the name of a chunk-type in the model
slot-test ::= {slot-modifier} slot-name slot-value
slot-modifier ::= [= | - | < | > | <= | >=]
slot-name ::= a symbol which names a possible slot in the specified chunk-type
slot-value ::= a variable or any Lisp value
query ::= ?buffer-name> query-test*
query-test ::= {-} queried-item query-value
queried-item ::= a symbol which names a valid query for the specified buffer
query-value ::= a bound-variable or any Lisp value
buffer-modification ::= =buffer-name> slot-value-pair*
slot-value-pair ::= slot-name bound-slot-value
bound-slot-value ::= a bound variable or any Lisp value
request ::= +buffer-name> isa chunk-type request-spec*
request-spec ::= {slot-modifier} slot-value-pair
request-parameter ::= a Lisp keyword naming a request parameter provided by the buffer specified
buffer-clearing ::= -buffer-name>
variable ::= a symbol which starts with the character =
output ::= !output! [ output-value ]
output-value ::= any Lisp value or a bound-variable
bound-variable ::= a variable which is used in the buffer-test conditions of the production (including a
variable which names the buffer that is tested in a buffer-test or dynamic-buffer-test) or is bound with
an explicit binding in the production
\end{lstlisting}

Some of the details in this grammar that have not been discussed yet are presented in the following.

\subsubsection{The Order of Rule Applications}

In the current translation scheme, the order of the rule applications does not match the semantics as described in the ACT-R theory\footnote{see section~\ref{procedural_knowledge}}. Consider the following rules in a compact notation:

\begin{lstlisting}
=b1>
  isa foo
  s1  v1
==>
=b1>
  s1  v2
=b2>
  s   x
\end{lstlisting}

and

\begin{lstlisting}
=b1>
  isa foo
  s1  v2
==>
=b2>
  s   y
=b1>
  s1  v3 % for termination
\end{lstlisting}

In the semantics of ACT-R, if the first rule matches, all the buffer modifications are performed first. After that, the procedural module can look for the next matching rule, which is the second one (due to the result of the first rule). This rule then would overwrite the value \lstinline|x| in the \lstinline|s| slot of buffer \lstinline|b2| with \lstinline|y|.

\begin{lstlisting}
<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)>>
==>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])).

<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)>>
==>
buffer_change(b2,chunk(_,_,[(s,y)])),
buffer_change(b1,chunk(_,_,[(s1,v3)])). % this is for termination
\end{lstlisting}

For the query

\begin{lstlisting}
?- chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c).
\end{lstlisting}

the result would be

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c2,s,x)
chunk_has_slot(c,s1,v3)
\end{lstlisting}

Ie., the buffer \lstinline|b2| holds the chunk with value \lstinline|x|. This is due to the fact, that after the first rule has modified the buffer \lstinline|b1|, the second rule matches and will be fired immediately, which then changes the value of \lstinline|b1| to \lstinline|y|. Afterwards, the second action of the first rule will be executed and the \lstinline|s| slot of the chunk in buffer \lstinline|b2| will be overwritten with \lstinline|x|.

Hence, somehow the fact that the procedural module is busy and cannot fire another rule, has to be modeled. This can be achieved by a simple phase constraint \lstinline|fire| that will be added after the complete execution of a rule and will be removed as soon as a rule is executed.

For every production rule, the rule

\begin{lstlisting}
{ buffer_tests } ==> { actions }
\end{lstlisting}

has to be changed to a simpagation rule

\begin{lstlisting}
{ buffer_tests } \ <<fire>> <=> { actions }, fire.
\end{lstlisting}

It is important, that the adding of \lstinline|fire| is the last action of a rule.

The example would be modified as follows:

\begin{lstlisting}
<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v1)
  \ fire>>
<=>
buffer_change(b1,chunk(_,_,[(s1,v2)])),
buffer_change(b2,chunk(_,_,[(s,x)])),
fire.

<<buffer(b1,C),
  chunk(C,foo),
  chunk_has_slot(C,s1,v2)
  \ fire>>
<=>
buffer_change(b2,chunk(_,_,[(s,y)])),
fire.
\end{lstlisting}


The test query

\begin{lstlisting}
?- chunk(c,foo), chunk_has_slot(c,s1,v1), chunk(c2,bar), chunk_has_slot(c2,s,v), buffer(b2,c2), buffer(b1,c), fire.
\end{lstlisting}

yields

\begin{lstlisting}
buffer(b1,c)
buffer(b2,c2)
chunk(c2,bar)
chunk(c,foo)
chunk_has_slot(c,s1,v3)
chunk_has_slot(c2,s,y)
fire
\end{lstlisting}

The fire constraint has to be added at the end of the query. This ensures the correct semantics and a completely constructed buffer system.\footnote{This was actually the reason, why in the first example without the \texttt{fire} constraint, the buffer \texttt{b1} was created at the end of the query: If it would be created at an earlier point, the first rule would have matched immediately and the computation would have yielded a different result.}

In appendix~\ref{app:ex:rule_order} a minimal executable example is provided.

\subsubsection{Bound and Unbound Variables}
\label{bound_and_unbound_variables}

According to the ACT-R production rule grammar in listing~\ref{lst:production_rule_grammar}, unbound variables can only appear on the left hand side of a rule. Hence, no new variables are introduced on the right hand side. Since all the elements in the buffer store are completely described and ground, every variable on the LHS of a rule will be bound to a ground value. This simplifies the rule selection and application process a lot, since every value of the calculation is known after the matching. This enables simple implementations of arithmetic tests, for example (see section~\ref{slot_modifiers}).

\subsubsection{Duplicate Slot Tests}

A problem that has not been addressed yet, is that ACT-R allows buffer tests like the following:

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  spam
\end{lstlisting}

In the logical reading, this would signify that $buffer \enspace Holds \enspace c \enspace \wedge \enspace c \enspace Isa \enspace foo \enspace \wedge \enspace c \xrightarrow{bar} spam \enspace \wedge \enspace c \xrightarrow{bar} spam$ which is equivalent to the test with only one check of the \lstinline|bar| slot\footnote{$x \wedge x = x$}.

However, in CHR the following rule head resulting from the simple translation scheme would not match:

\begin{lstlisting}
buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,bar,spam),
  chunk_has_slot(C,bar,spam)
\end{lstlisting}

Because there are no two identical \lstinline|chunk_has_slot| constraints in the store, the rule could not fire. When translating such a rule, the second test has to be eliminated.

However, this does not do the trick for all possible cases. For example, suppose a test

\begin{lstlisting}
=buffer>
  isa  foo
  bar  spam
  bar  =x
\end{lstlisting}

where the second test refers to a variable (or even both tests are variables). This problem could be solved by adding a guard to the rule from the simple translation:

\begin{lstlisting}
<<buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)>>
==> <<<spam == X>>> | ...
\end{lstlisting}

Since \lstinline|X| must be bound after the matching\footnote{see section~\ref{bound_and_unbound_variables}}, the test will always give the correct result. This also works for the first example, where the test would be \lstinline|spam == spam|, which is always true and hence could be reduced to the rule with the second test eliminated and no guard\footnote{true guards can always be reduced}.

It also works if the two slot-tests were contradictory, for example: 

\begin{lstlisting}
bar  spam
bar  eggs
\end{lstlisting}

would describe a rule that never can fire. The translation models exactly this behaviour:

\begin{lstlisting}
<<buffer(buffer,C),
chunk(C,foo),
chunk_has_slot(C,bar,spam)>>
==> <<<spam == eggs>>> | ...
\end{lstlisting}

since the built-in syntactic-equality test of Prolog would never return true for those two constants.

\subsubsection{Slot Modifiers}
\label{slot_modifiers}

In ACT-R, slot-tests can be preceded by \emph{slot modifiers}. Those modifiers allow to specify tests like inequality (\lstinline|-|) or arithmetic comparisons (\lstinline|<, >, <=, >=|) of the slot value of a chunk with the specified variable or value. Since the slots in a chunk store are always fully defined with ground values, those tests are decidable.

If no slot modifier is specified in a slot test, the default modifier \lstinline|=| is used, that states that the chunk in the specified buffer must have the specified value in the specified slot. This default semantics has been used in the previous sections when translating simple ACT-R rules to CHR and is performed automatically by the matching of CHR.

To translate the other slot modifiers to CHR, another CHR mechanism can be used: Guards. Since the allowed modifiers are all default built-in constraints\footnote{i.e. Prolog predicates}, a slot test with a modifier

\begin{lstlisting}
...
=buffer>
  ...
  ~slot  val
...
==>
\end{lstlisting}

where \lstinline|~| stands for one of the modifiers in \{ \lstinline|=,-,<,>,<=,>=| \} can be translated as follows:

\begin{lstlisting}
<<buffer(buffer,C),
  ...
  chunk_has_slot(C,slot,V),
  ...>>
==>
  <<<V # val>>> |
  ...
\end{lstlisting}

where \lstinline|#| is the placeholder for the built-in constraint that computes the test specified by \lstinline|~| and \lstinline|V| is a fresh variable that has not been used in the rule, yet.

For arithmetic slot modifiers the values being compared have to be numbers. If a value is not a number, the arithmetic test will fail and the rule cannot be applied \cite{actr_reference}.

Note, that slot tests with modifiers other than \lstinline|=| do not bind variables, but only perform simple checks, like it is with guards in CHR. If \lstinline|val| is an unbound variable and is never bound to a value on LHS, the default implementation throws a warning, and the rule will not match. Therefore, to handle this case, the rule translation scheme has to be extended by an additional guard check \lstinline|ground(Val)|, where \lstinline|Val| is the Prolog variable that replaces each occurrence of the variable \lstinline|val|.

As with normal slot tests, it is important to mention that if there are several tests on the same slot, the \lstinline|chunk_has_slot| constraint must appear only once on the LHS of the CHR rule, since every slot-value pair is unique in the constraint store. Ie., if the first slot test of a particular slot appears on the LHS of the ACT-R rule, a \lstinline|chunk_has_slot| constraint has to be added to the LHS of the CHR rule. For every other occurrence of this slot in a slot test, only guard checks are added.

\begin{example}
To clarify the details of the matching concept in ACT-R, here are some examples and their behaviour:

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
\end{lstlisting}

will throw a warning when loading the model. When running it, the rule will never fire, since no chunk value will match the inequality to the unbound variable \lstinline|bar|.

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  =bar
  eggs   =bar
\end{lstlisting}

will fire, if there is a chunk whose value in \lstinline|eggs| is different from the value in \lstinline|spam|.

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
\end{lstlisting}

matches for every value of the spam slot. The translation to CHR is:

\begin{lstlisting}
<<buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar)>>
==>
  <<<Bar=Eggs>>> | ...
\end{lstlisting}

In this case, a binding occurs in the guard, which is usually unwanted. However, since the \lstinline|Eggs| variable is unbound and therefore a fresh variable introduced in the guard, it is allowed and does not harm the matching process. It is even necessary to bind \lstinline|Eggs| to \lstinline|Bar| because of the semantics of the equivalent ACT-R rule. The following example is a little bit different: The rule

\begin{lstlisting}
=buffer>
  isa    foo
  spam  =bar
  spam  =eggs
  ham   =eggs
\end{lstlisting}

will match all chunks which have the same value in \lstinline|spam| and \lstinline|ham|. This translates to

\begin{lstlisting}
<<buffer(buffer,C),
  chunk(C,foo),
  chunk_has_slot(C,spam,Bar),
  chunk_has_slot(C,spam,Eggs)>>
==>
  <<<Bar==Eggs>>> | ...
\end{lstlisting}

Note, that in this case, no binding occurs, since both, \lstinline|Bar| and \lstinline|Eggs|, already occur in the head of the rule and are bound to some value. Hence, the test in the guard can be reduced to a simple syntactic equality test without binding (\lstinline|==|).

\end{example}

\paragraph{Relation to Negation-as-Absence}

The concept of negation-as-absence as described in \cite[147\psqq]{fru_chr_book_2009} is provided by many production rule systems. It enables the programmer to negate a fact in the sense that the fact is not explicitly in the store and therefore the rule is applicable -- so the programmer asks for the absence of a particular fact.

At the first glance, the slot modifiers seem to implement this concept, but this is not the case: All negated slot tests in ACT-R can be reduced to simple built-in guard checks, because the chunks in the store are always described completely and the values are ground, so simple built-in checks work automatically. This also works for invalid slot-tests that ask for slots which are not offered by the chunk-type they ask for. Then there will never be a constraint matching the head of the rule due to type consistency.

With these restrictions, ACT-R avoids the problems that come with negation-as-absence as they are explained in \cite[147\psqq]{fru_chr_book_2009} and the translation of such tests to CHR is very simple.

\subsubsection{Empty Slots}

An important special case in the semantics of ACT-R production rules is, that if there is a slot test specified, then a potential chunk only matches, if it really has a value in this slot. Chunks that have \lstinline|nil| in a slot specified in a buffer test, will not match the test. Hence, variables can not be used to test if two slots have the same value and the value is \lstinline|nil|, since every positive slot test involving \lstinline|nil| fails automatically \cite[p. 164, section ``Variables'', last sentence]{actr_reference}.

In CHR this special case can be handled, by adding a guard for each variable occurring in a positive slot-test checking that this variable does not equal \lstinline|nil|.

For negated slot tests, this is not the case: 

\begin{lstlisting}
=buffer>
  isa    foo
  -spam  4
\end{lstlisting}

matches also a chunk with an empty \lstinline|spam| slot (\lstinline|nil| in its \lstinline|spam| slot).



\subsubsection{Outputs}

The production system of ACT-R also provides methods to produce side-effects. In this work, only a subset of those methods is concerned: the outputs. Outputs can appear on the right hand side of an ACT-R rule:

\begin{lstlisting}
=buffer>
  isa  foo
==>
  !output! (a1 a2 a3)
\end{lstlisting}

The argument of such an output call is a list of Lisp-symbols, so it is possible to hand variables or terms.

This mechanism can be translated to Prolog directly:

\begin{lstlisting}
output([]).
output([X|Xs]) :-
  write(X),nl,
  output(Xs).
\end{lstlisting}

The \lstinline|X| have to be Prolog terms.

In ACT-R, function calls like \lstinline|!eval!| or \lstinline|!bind!| are allowed, but they are ignored in this work.

\section{Modular Organization}

By now, all components of the implementation have been assumed to be in one file: buffer system, production rules, declarative memory, \dots This leads to problems like name space pollution and duplicate code, since, e.g. both the buffer system and the declarative memory use different chunk stores, which have the same behaviour but different data. It would be nice to reuse this code in both modules, but keeping the stores separated. Additionally, the code is better readable and it is easier to add new modules if a program is distributed over multiple files. Finally, the ACT-R architecture already proposes a modular organization, so it seems likely to adopt this idea of a modular architecture.

The term \emph{module} is highly overloaded: In ACT-R it describes independent parts of human cognition, whereas in the world of programming the term is used in a slightly different manner. In the following, implementational modules will always be named explicitly as \emph{Prolog modules}.

Nevertheless, the modular organization of ACT-R with its independent modules can be implemented by defining a Prolog module for each ACT-R module and adding some other modules around them. In the following, the concept of Prolog modules is explained.

\subsection{Prolog Modules}

Defining a new module creates a new namespace for all CHR constraints and Prolog predicates, which is illustrated in the following example:

\begin{example}[Prolog Modules and CHR]

In this example, two modules \lstinline|mod1| and \lstinline|mod2| are defined, with partially overlapping constraints. \lstinline|mod2| exports the constraint \lstinline|c|. In the following, the behaviour an interaction of the modules is explored.

\begin{lstlisting}[caption={Definition of Module 1},label=lst:mod1]
:- module(mod1,[]).
:- use_module(library(chr)).

:- use_module(mod2).

:- chr_constraint a/0, b/0.

<<a>> <=> c.
\end{lstlisting}

\begin{lstlisting}[caption={Definition of Module 2},label=lst:mod2]
:- module(mod2,[c/0]).
:- use_module(library(chr)).

:- use_module(mod1).

:- chr_constraint a/0, b/0, c/0. 

<<a>> <=> b.
<<b>> <=> mod1:a.
\end{lstlisting}


In this definition, two new modules \lstinline|mod1| and \lstinline|mod2| are created and only the \lstinline|c| constraint of \lstinline|mod2| is exported, indicated by the lists in the module definitions.

The CHR constraint \lstinline|a| in listing~\ref{lst:mod1} is internally represented as \lstinline|mod1:a|, so it lives in its own namespace and does not pollute other namespaces. The constraint can appear on the right hand side of rules of other modules, but has to be called explicitly with its full namespace identifier. In line~8 of listing~\ref{lst:mod2}, the presence of the local \lstinline|a| constraint leads the rule to fire and \lstinline|mod2:a| is replaced by \lstinline|mod2:b|, which leads the rule in line~9 to fire and replaces the local \lstinline|mod2:b| constraint by an external \lstinline|mod1:a| constraint. So, external constraints can be called by their complete identifiers.

However, on the left hand side of a rule, only the constraints local to the current module can appear. 

Exported constraints can only appear once in a program, since they can be called without their namespace definition, which is demonstrated in line~8 of listing~\ref{lst:mod1}, where \lstinline|mod2:c| is called in \lstinline|mod1| without referring to \lstinline|mod2| explicitly.
\end{example}

\subsection{Interface for Module Requests}
\label{interface_for_module_requests}

The architecture of ACT-R provides an infrastructure for the procedural module to state requests to all the other modules. To implement this concept as general as possible, an interface has to be defined, which allows the adding of new modules to the system by just implementing this interface.

\begin{lstlisting}[caption={Simple Interface ``Module''},label=lst:interface_module]
module_request(+BufName,+Chunk,-ResChunk,-ResState)
\end{lstlisting}

The arguments of such a request are:

\begin{description}
 \item[BufName] The name of the requested buffer, e.g. \lstinline|retrieval|.
 \item[Chunk] A chunk specification that represents the arguments of the request. The form of the allowed chunk specifications and the semantics of the request are module-dependent. For example: \lstinline|chunk(_,t,[(foo,bar),(spam,eggs)])| could describe a chunk, that should be retrieved from declarative memory.
\end{description}

The request provides the following result:

\begin{description}
 \item[ResChunk] The resulting chunk in form of a chunk specification. The actual result and its semantics depend on the particular module.
 \item[ResState] The state of the buffer after the request. For example, if no matching chunk could be retrieved from declarative memory, the state would be \lstinline|error|.
\end{description}

This interface will be extended later on.

\subsection{How the Buffer System States a Request}
\label{how_the_buffer_system_states_a_request}

Every module that can handle a request implements the interface in listing~\ref{lst:interface_module}. When the buffer system gets a call \lstinline|buffer_request(buffer,chunk-specification)|, it simply can call the \lstinline|module_request| method of the corresponding module. This can be achieved by \lstinline|ModName:module_request(...)|, where \lstinline|ModName| is the name of the corresponding module.

Hence, the buffer system must now, which buffer belongs to which module. The \lstinline|buffer/2| constraint therefore has to be extended to a \lstinline|buffer/3| constraint, that also holds the module name of its module:

\begin{lstlisting}
buffer(BufName,ModName,Chunk)
\end{lstlisting}

A buffer request can now be handled as follows:

\begin{lstlisting}[caption={Retrieval Request in CHR}, label=lst:retrieval_request_symbolic]
<<buffer(BufName, ModName, _) \ buffer_request(BufName, Chunk)>> <=>
  set_buffer_state(BufName,busy),
  buffer_clear(BufName), % clear buffer immediately
  ModName:module_request(BufName, Chunk, ResChunk,ResState),
(ResState=error, 
  buffer(BufName, ModName, nil),
  set_buffer_state(BufName,error) ;
  
  ResState = free,
  ResChunk = chunk(ResChunkName,_,_),
  add_chunk(ResChunk), 
  buffer(BufName, ModName, ResChunkName),
  set_buffer_state(BufName,free)).
\end{lstlisting}

When getting a buffer request, the buffer state is set to \lstinline|busy| first. Then the buffer is cleared immediately, which leads the chunk in the buffer being added to the declarative memory. Then the module request is stated according to the interface. If the resulting state is \lstinline|error|, then the buffer gets this state and the content of the buffer is \lstinline|nil|, otherwise, if the resulting state is \lstinline|free|, the result will be added to the buffer and the state will eventually be set to \lstinline|free|. 

\subsection{Components of the Implementation}

uml component diagram + discussion



\section{Declarative Module}

The Declarative Module is a \emph{chunk store}, that additionally implements the \emph{module} interface. Therefore some rules to handle requests that find certain chunks in the chunk store have to be implemented. 

\subsection{Global Method for Adding Chunks}
\label{global_method_for_adding_chunks}

Since the declarative module is very important to the whole theory it kind of is a special module. Therefore, its Prolog module exports a predicate \lstinline|add_dm| that is just a wrapper for its chunk store. Hence, with the command \lstinline|add_dm| chunks can be added to the chunk store of the declarative module from every part of the program. This is e.g. used for the clearing of buffers in the buffer system, where the chunk of a buffer goes to the declarative memory when the buffer is cleared. This is the implementation of the command:

\begin{lstlisting}
<<add_dm(ChunkDef)>> <=> add_chunk(ChunkDef).
\end{lstlisting}



\subsection{Retrieval Requests}
\label{retrieval_requests}

A retrieval request gets an incomplete chunk specification as input and returns a chunk, whose slots match the provided chunk pattern.

\subsubsection{Chunk Patterns}

The chunk patterns are transmitted in form of chunk specifications as defined in section~\ref{chunk_specification}. Since those specifications may be incomplete, variables are considered as place-holders for values in the result. The result always is a complete and ground chunk specification, because every chunk in a chunk store has to be defined completely; empty slots are indicated by the value nil.

\begin{example}
In this example some possible requests are discussed.

\begin{enumerate}
 \item Request:
\begin{lstlisting}
chunk(foo,bar,_)        
\end{lstlisting}

A chunk with name \lstinline|foo|, type \lstinline|bar| and arbitrary slot values is requested.

 \item Request:
\begin{lstlisting}
chunk(_,bar,_)        
\end{lstlisting}

This request is satisfied by every chunk of type \lstinline|bar|.

 \item Request:
\begin{lstlisting}
chunk(_,t,[(foo,bar),(spam,eggs)])        
\end{lstlisting}

The most common case of requests is a specification of the type and a (possibly incomplete) number of slot-value pairs for that type. If a type does not provide a specified slot, the request is invalid and no chunk will be returned.

\end{enumerate}

\end{example}

\subsubsection{Finding Chunks}

In this section, a CHR constraint \lstinline|find_chunk/3| will be defined, that produces a \lstinline|match_set/1| constraint for each chunk that matches a specified pattern. Eventually, the match set will be collected and returned.

\begin{lstlisting}
<<find_chunk(N1,T1,Ss), chunk(N2,T2)>> ==> 
  <<<unifiable((N1,T1),(N2,T2),_), 
  nonvar(Ss)>>> | 
  test_slots(N2,Ss), 
  match_set([N2]).
  
<<find_chunk(N1,T1,Ss), chunk(N2,T2)>> ==> 
  <<<unifiable((N1,T1),(N2,T2),_), 
  var(Ss)>>> | 
  test_slots(N2,[]), 
  match_set([N2]).

<<find_chunk(_,_,_)>> <=> true.
\end{lstlisting}

First, for each chunk in the store, whose name and type is unifiable with the specified name and type, will be part of the initial match set. If in the chunk specification the name and type are variables, each chunk will match. For the unification test, the \lstinline|unifiable/3| predicate of Prolog is used, because the unification should not be performed but only tested. 

If name and type match the pattern, then the slots have to be tested.

The rule in line~7 is for chunk specifications that do not specify the slots. In this case, no slots have to be tested. If all chunks have been tested or no chunk matches at all, the process is finished (rule in line ~13).

After adding each matching candidate to the match set, whose name and type have already been checked, the match set is pruned from chunks that have non-matching slot values:

\begin{lstlisting}
<<test_slots(_,[])>> <=> true.

<<chunk_has_slot(N,S,V1), match_set([N]) 
\ test_slots(N,[(S,V2)|Ss])>> <=> 
  <<<unifiable(V1,V2,_)>>> | 
  test_slots(N,Ss).

<<chunk_has_slot(N,S,V1) 
\ test_slots(N,[(S,V2)|_]), match_set([N])>> <=> 
    <<<\+unifiable(V1,V2,_)>>> | 
    true.

<<test_slots(N,_) \ match_set([N])>> <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more and the test is finished and has been successful.

In line~3, the rule applies, if there is at least one slot \lstinline|(S,V2)| that has to be tested and a $HasSlot$ relation of the kind \lstinline|N| $\xrightarrow[]{\mathtt{S}}$ \lstinline|V1| with the slot \lstinline|S| to be tested, that is still in the match set, so no conflicting slot has been found yet. If the values \lstinline|V1| and \lstinline|V2| are unifiable, i.e. the both are the same constant or at least one is a variable, then the test passes and the chunk \lstinline|N| remains in the match set and the rest of the slot tests are performed.

The second rule in line~8 applied if the guard of the first rule did not hold, so the values \lstinline|V1| and \lstinline|V2| are not unifiable, but there is a connection \lstinline|N| $\xrightarrow[]{\mathtt{S}}$ \lstinline|V1| and in the request it has been specified that the value of slot \lstinline|S| has to be \lstinline|V2|. In this case, \lstinline|V1| $\neq$ \lstinline|V2|, so the test fails and the chunk \lstinline|N| has to be removed from the match set, since one of its slots does not match.

If the last two rules cannot be applied, the chunk does not provide a slot that, however, has been specified in the request. Hence, the chunk does not match and the last rule therefore deletes it from the match set. \FIXME{make simpagation rule to simplification rule?}

If those rules have been applied exhaustively, only the matching chunks will remain in the match set: If there would be an outstanding slot test, one of the rules would be applicable and the chunk would be removed from the match set, if the test fails (and the test would also be removed, because it has been performed). If the test is successful, the chunk will remain part of the match set, but the test will be removed. So the match set is correct and complete.

However, since the match set is distributed over a set of \lstinline|match_set| constraints, it would be desirable to collect all those matches in one set. This can be triggered by the constraint \lstinline|collect_matches/1|, which returns the complete match set in its arguments as soon as there is only one \lstinline|match_set| left:

\begin{lstlisting}
<<collect_matches(_) \ match_set(L1), match_set(L2)>> <=> 
  append(L1,L2,L), 
  match_set(L).
  
<<collect_matches(Res), match_set(L)>> <=> Res=L.

<<collect_matches(Res)>> <=> Res=[].
\end{lstlisting}

The first rule merges two match sets to one singe merge set containing a list with all the chunks of the former sets, if the \lstinline|collect_matches| trigger is present. 

In the second rule, if no two match sets are in the store, the result of the \lstinline|collect_matches| operation is the match set. The same applies for the last rule, where no match set is in the store and therefore the result is empty. Note, that this implies, that the rules have to be applied from top to bottom, left to right\footnote{This is called the refined operational semantics of CHR}.

The symbolic layer does not implement any rule for which chunk will be returned, if there are more than one in the match set. In this implementation, the first chunk in the list is chosen. The module request is now implemented as follows:

\begin{lstlisting}
<<module_request(retrieval,chunk(Name,Type,Slots),ResChunk, ResState)>> <=> 
  find_chunk(Name,Type,Slots),
  collect_matches(Res),
  first(Res,Chunk),
  return_chunk(Chunk,ResChunk),
  get_state(ResChunk,ResState).
\end{lstlisting}

where \lstinline|first(L,E)| gets a list \lstinline|L| and returns its first element \lstinline|E| or \lstinline|nil|, if the list was empty.

With \lstinline|return_chunk/2| and \lstinline|get_state/2|, the actual results of the request are computed:

By now, the variable \lstinline|Chunk| holds the name of the chunk to return, but in the specification of the module request, a complete chunk specification is demanded. \lstinline|return_chunk/2| is defined as a default method of a chunk store that gets a chunk name as its first argument and returns a chunk specification created from the values in the chunk store as its second argument.

The resulting state of the request is computed as follows: If the result chunk is \lstinline|nil|, then no chunk was in the match set, so the state of the declarative module will be \lstinline|error|. In any other case, the state is \lstinline|free| after the request has been performed.

\subsection{Chunk Merging}

An important technique used in ACT-R's declarative memory module, is the chunk merging: If a chunk enters the chunk store and all of its slots and values are the same as of a chunk already in the store, then those two chunks get merged. The merged chunk can be called with both names.

If a chunk entering the declarative memory has the same name as a chunk in that already is in the store, the new chunk gets a new name and if its slots are the same as the slots of the old chunk, they will be merged and the new name will be deleted.

\begin{lstlisting}
<<chunk(Name,Type) \ add_chunk(chunk(Name,Type,Slots))>> <=>
  <<<Type \== chunk>>> |
  add_chunk(chunk(Name:new,Type,Slots)).

% first check, if identical chunk exists
<<add_chunk(chunk(C,T,S))>> ==> 
  <<<T \== chunk>>> | 
  check_identical_chunks(chunk(C,T,S)).
\end{lstlisting}

The rules are added before the empty slot initialization in listing~\ref{lst:add_chunk_rules}. The first rule handles the case where a chunk with an already allocated name is added to the store. Then it gets a new name (which basically is just the old name extended by \lstinline|:new|, and tries to add this new chunk to the memory. 

The second rule adds an identity check for each chunk to be added except for primitive elements, since their slots are identical for every name, because every primitive element has no slots. Nevertheless they have to be distinguishable by their names and therefore cannot be merged.

The identity check is implemented as follows:

\begin{lstlisting}
<<check_identical_chunks(nil)>> <=> true.

<<chunk(NameOld,Type), check_identical_chunks(chunk(NameNew,Type,Slots))>> ==> 
  check_identical_chunks(chunk(NameNew,Type,Slots),NameOld).
  
<<check_identical_chunks(_)>> <=> true.
\end{lstlisting}

The rule in line~3 adds for each identity check and each chunk in the store a pairwise identity check which is performed by the following rules:

\begin{lstlisting}
<<chunk(NameOld, Type) \ check_identical_chunks(chunk(NameNew,Type,[]),NameOld)>> <=> 
  identical(NameOld,NameNew).
  
<<chunk(NameOld, Type), chunk_has_slot(NameOld, S, V) \ check_identical_chunks(chunk(NameNew,Type,[(S,V)|Rest]), NameOld)>> <=> 
  check_identical_chunks(chunk(NameNew,Type,Rest),NameOld).
  
<<chunk(NameOld, Type), chunk_has_slot(NameOld, S, VOld) \ check_identical_chunks(chunk(_,Type,[(S,VNew)|_]),NameOld)>> <=> 
  <<<VOld \== VNew>>> |
  true.
    
<<<remove_duplicates>>> @ <<identical(N,N)>> <=> true.

% abort checking for identical chunks if one has been found
<<<cleanup_identical_chunk_check>>> @ <<identical(NameOld,NameNew) \ check_identical_chunks(chunk(NameNew,_,_),NameOld)>> <=> true.
\end{lstlisting}

The first rule is the base case, where no slots have to be tested any more. Then the chunks are identical and an \lstinline|identical/2| constraint is added to the store for those two chunks.

The next rule applies for an identity check for a slot-value pair that is successful, whereas the third rule handles the opposite case and aborts the check for this pair of chunks without adding an \lstinline|identical| constraint.

In the fourth rule redundant information is removed and the lust rule aborts the identity check as soon as one matching chunk has been found.

Note that this implementation assumes that the chunk specification of the chunk entering the declarative memory is complete. If it is not complete, the correct semantics of the adding is that all unspecified slots are empty so their values equal \lstinline|nil|. Nevertheless, this implementation would merge the chunk with a chunk that has values in those unspecified slots. This could be improved by completing the chunk specifications before checking for identical chunks in the store.

For the easier use of the identical constraint at other points, transitive identities can be reduced to the only real chunk in the store (the one with the \lstinline|chunk| constraint):

\begin{lstlisting}
<<<reduce>>> @ <<chunk(C1,_), identical(C1,C2) \ identical(C2,C3)>> <=> 
  identical(C1,C3).
\end{lstlisting}

Additionally, the newly created names can be deleted if the chunk was identical to another chunk with a real name, since the new nomenclature was only store internal, so only the original name must be kept:

\begin{lstlisting}
<<identical(C,C:new)>> <=> true.
\end{lstlisting}

In the declarative module, the chunk search must be extended to find merged chunks by both names. This can be achieved as follows:

\begin{lstlisting}
<<identical(C1,C2) \ find_chunk(C2,T2.Ss2)>> <=> 
  <<<ground(C2)>>> | 
  find_chunk(C1,T2,Ss2).
\end{lstlisting}

so the chunk search of a chunk that is only a pointer to another chunk can be reduced to the search of this chunk. \FIXME{maybe this can cause problems if a production rule refers to a particular name and gets a chunk with the name of its brother..}

The process of chunk merging is described in \cite[??]{actr_reference}. The treating of identical names is not described there, but has been tested in the original implementation: ACT-R handles those identical names similarly to this approach by adding a sequential number to the identical name. For example, the chunk with name \lstinline|a| would be called \lstinline|a-0| if there already was a chunk \lstinline|a| in the store.

\section{Initialization}
\label{initialization}

In the examples the models had to be run by stating complex queries which create all necessary buffers and add all chunk types and chunks to the declarative memory manually. In the original ACT-R implementation, the command \lstinline|run| is used to run a model. This behaviour can be transferred to the CHR implementation easily by adding a \lstinline|run| constraint and a rule for this constraint, that performs all the initialization work.

\FIXME{modify count example from above}

\section{Timing in ACT-R}

So far, the execution order of the production rules has been controlled by the \lstinline|fire| constraint -- a phase constraint that simulated the occupation of the production system while a rule is executed.

However, certain buffer actions like buffer requests may take some time until they are finished. The procedural system is free to fire the next rule after all actions have been started\footnote{see chapters \ref{serial_parallel_aspects} and \ref{process_of_rule_selection_and_execution}} and the requests are performed in parallel to that.

Additionally, for the simulation it may be interesting to explore how much time certain actions have taken, especially when it comes to the subsymbolic layer.

Those aspects cannot be implemented easily using the current approach with phase constraints. Hence, the idea of introducing a central scheduling unit is a possible solution of those requirements: The unit has a serialized ordered list of events with particular timings. If a new event is scheduled, the time it is executed must be known. The scheduling unit inserts the event at the right position of the list preserving the ordered time condition. Figure~\ref{fig:scheduler} illustrates this approach.

The system just removes such events from the queue and executes them, which leads to new events in the queue. The queue organizes the right order of the events.

With this approach, the simulation of a parallel execution of ACT-R can be achieved: Each buffer action on the RHS of a rule just schedules an event that actually performs the action at a specified time (the current time plus its duration). 

The central part of the scheduler is a \emph{priority queue} which manages a list of events and returns them by time. It is described in the next section.

\subsection{Priority Queue}

A \emph{priority queue} is an abstract data structure that serves objects by their priority. It provides the following abstract methods:

\begin{description}
 \item[enqueue with priority] An object with a particular priority is inserted to the queue. 
 \item[dequeue highest priority] The object with the highest priority is removed from the queue and returned.
\end{description}

\subsubsection{Objects}

In the implementation of the scheduler, the priority queue contains objects of the form \lstinline|q(Time,Priority,Event)|. The priority of such a queue object is composed from the \lstinline|Time| and the \lstinline|Priority|. The order between the elements is defined as follows:

\begin{definition}[ordered time-priority condition]
\lstinline|q(T1,P1,E1)| $\prec$ \lstinline|q(T2,P2,E2)|, i.e. the object \lstinline|q(T1,P1,E1)| is the predecessor of the object \lstinline|q(T2,P2,E2)|, if \lstinline|T1| $<$ \lstinline|T2|. In the case that \lstinline|T1 = T2|, then \lstinline|q(T1,P1,E1)| $\prec$ \lstinline|q(T2,P2,E2)| if \lstinline|P1| $>$ \lstinline|P2|. So, events with smaller times will be returned first. If two events appear at the same time, it is possible to define a priority and the event with the higher priority will be returned first. 
\end{definition}

\subsubsection{Representation of the Queue}

The representation of the priority queue is inspired by \cite[38\psqq]{fru_chr_book_2009}: An order constraint \lstinline|A --> B| is introduced, which states that \lstinline|A| will be returned before \lstinline|B| (or \lstinline|B| is the direct successor of \lstinline|A|). The beginning of the queue will be defined by a start symbol \lstinline|s|, so the first real element is the successor of \lstinline|s|. A possible queue could be:

\begin{lstlisting}
    s     --> q(1,0,e1)
q(1,0,e1) --> q(3,7,e2)
q(3,7,e2) --> q(3,2,e3)
\end{lstlisting}

This queue achieves the ordered time-priority condition, since the queue objects are in the correct order according to their times and priorities. It is also consistent in a sense that it has no gaps and no object has more than one successor.

In general, there can be defined some rules to make such a queue consistent, i.e. every object only has one successor and the queue achieves the time-priority condition:

\begin{lstlisting}
<<A --> A>> <=> true.

<<_ --> s>> <=> false.

<<A --> B, A --> C>> <=>
  <<<leq(A,B),
  leq(B,C)>>> |
  A --> B,
  B --> C.
\end{lstlisting}

The first rule states, that if an object is its own successor, this information can be deleted. The second rule states, that nothing can be the predecessor of the start symbol. The last rule is the most important one: If one object has two successors, then these connections have to be divided into two connections according to the defined time-priority condition. This condition can be implemented as follows:

\begin{lstlisting}
leq(s,_).

% Time1 < Time2 -> event with time1 first, priority does not matter
leq(q(Time1,_,_), q(Time2,_,_)) :- 
  Time1 < Time2.

% same time: event with higher priority first
leq(q(Time,Priority1,_), q(Time,Priority2,_)) :- 
  Priority1 >= Priority2.
\end{lstlisting}

The first predicate states that the start symbol is is less than every other object. The other two rules implement the time-priority condition directly.

Note that two objects are considered the same, iff. their time, priority and event are syntactically the same. If an object is altered in one of the \lstinline|-->| constraints, it has to be edited in every other occurrence in the   list to avoid gaps.

Another important property is, that the list does not have any gaps, so it must be possible to track the queue from every element backwards to the start symbol. This condition is not achieved by the rules above, but since a priority queue only offers two mechanisms to modify it, a lot of those problems can be avoided:

\begin{description}
 \item[add\_q(Time,Priority,Event)] Enqueues an object with the specified properties. Ie., a new \lstinline|q(Time,Priority,Event)| object will be created and the following constraint will be added: \lstinline|s --> q(Time,Priority,Event)|. The rules presented above will lead to a linear, serialized list achieving the time-priority condition without gaps.
\begin{lstlisting}
<<add_q(Time,Priority,Evt)>> <=>
  s --> q(Time,Priority,Evt).
\end{lstlisting}
 \item[de\_q(X)] Dequeues the first element of the queue according to the time-priority condition and binds its value to \lstinline|X|.
\begin{lstlisting}
<<de_q(X), s --> A, A --> B>> <=>
  X = A,
  s --> B.

<<de_q(X), s --> A>> <=>
  X = A.  
  
<<de_q(X)>> <=> X = nil.
\end{lstlisting}

The first object just is the successor of \lstinline|s|, since the list has been constructed preserving the correct order and the property, that everything starts at \lstinline|s|. If the first object has a successor, this object is the new first object. If there are no order constraints left, the queue is empty and \lstinline|de_q| returns \lstinline|nil|.

\end{description}

\subsubsection{Special Operation for ACT-R}

In this implementation, another default method is added to the priority queue: 

\begin{description}
 \item[after\_next\_event(E)] Adds the event \lstinline|E| to the queue, after the first event without destroying the consistency and the time-priority condition of the queue.
\end{description}

To implement this method, the time and priorities have to be set such that the time-priority condition does hold:

\begin{lstlisting}
<<s --> q(Time,P1,E1) \ after_next_event(Evt)>> <=> 
  NP1 is P1 + 2, % increase priority of first event, so it still has highest priority
  P is P1 + 1, % priority of event that is added, ensured that it is higher than of the former second event (because it is P1+1)
  de_q(_), % remove head of queue
  add_q(Time,NP1,E1), % add head of queue again with new priority. Will be first again, because it has old prio (which is higher than prio of all successors)
  add_q(Time,P,Evt). % add new event. Will be < than Prio of head but it is ensured that it is higher than prio of second event
\end{lstlisting}

If the first event is \lstinline|q(Time,P1,E1)| and a new event \lstinline|Evt| has to be added after this event, the times of the two events are the same, the priority of the first event is \lstinline|P1 + 2| and the priority of the new event is \lstinline|P1 + 1|. The first event is removed from the queue and would be added with its new priority to the queue again, as it is with the new event. 

This is correct: The first event will be the first event again, because its old priority was higher than any other priority at that time point and since the new priority is even higher than that, no other event from the queue will have a higher priority. The new event also has a higher priority than every other event in the queue, but a lower priority than the first event, so it will be added after the first event.

By the \lstinline|de_q| and \lstinline|add_q| actions it is ensured, that no garbage of the old event remains in the queue and the events are added correctly through an official method of the queue.

\subsection{Scheduler}

The scheduler component is an own module that manages events by feeding a priority queue and controls the recognize-act cycle. It also holds the current time of the system. 

\subsubsection{Current Time}

The current time can be saved in a \lstinline|now/1| constraint. It is important that there is only one such constraint and that time increases monotonically.

Other modules can access the time only by a \lstinline|get_now/1| that only returns the current time saved in the \lstinline|now/1| constraint. The current time cannot be set from outside, but is determined by the last event dequeued from the priority queue.

\subsubsection{Recognize-Act Cycle}

As described before, the procedural module can only fire one rule at a time. When executing the RHS of a rule, all its actions are added to the scheduler with the time point when their execution is finished. For example: If on the RHS of the firing rule a retrieval request has to be performed, an event will be added to the priority queue with the time $Now + Duration$, so the chunk retrieved from the declarative memory will be written to the retrieval buffer at this time point.

After all events of the RHS have been added to the scheduler, the procedural module is free again and therefore the next rule can fire. The event of firing will be added to the priority queue as well by the \lstinline|fire| constraint at the end of each production rule. The rule will be added at the current time point, but with low priority, since it has to be ensured, that every action of the previously executed rule has been performed yet (in the sense that a corresponding event has been added at the specified time point). In many cases, no other rule will be applicable at this time, because most of the meaningful production rules have to wait for the results of the production rule before. 

Many of the buffer actions are performed immediately, so an event with the current time point is added for the buffer modifications or clearings. They are performed in a certain order defined by their priority as shown in table~\ref{tab:action_priorities}. The request actions are performed at last, but they perform a buffer clearing immediately and then start their calculation which can take some time. 

If no rule is applicable, the next time that a rule could be applicable is after having performed the next event. So, the next \lstinline|fire| event is scheduled directly after the first event in the queue. This simulates the behaviour that the procedural module stays ready to fire the next rule, without polling at every time point if a rule is applicable, but only reacting on changes to the buffer system. 


The following enumeration summarizes the recognize-act cycle with a scheduler:

\begin{enumerate}
 \item The next event is removed from the queue, the current time is set to the time of the event and the event is performed.
 \begin{enumerate}
 \item The dequeued event is a \lstinline|fire| constraint: The rule that matches all its conditions is fired and removes the \lstinline|fire| constraint.
 \item The actions of the rule are scheduled in the queue. Modifications and Clearings have the current time point, requests have a time point in the future depending on the module.
 \item The last action of the rule is to add a \lstinline|fire| constraint to the queue with the current time point and a low priority. This simulates that the procedural module is free again, after all in-place actions of a rule have been fired.
 \item There are two possibilities:
 \begin{enumerate}
  \item \emph{The next rule matches:} It will be performed like the last rule.
  \item \emph{No rule matches:} The next time, it could be possible that a rule can fire, is when something in the buffers changed. This only can happen, after the next event has been performed. So the next \lstinline|fire| event will be added to the queue by \lstinline|after_next_event| which has been described above.
 \end{enumerate}
  \end{enumerate}
 \item Go to point 1. This is performed until there are no events in the queue.
\end{enumerate}


The following parts are necessary to implement this cycle:

\paragraph{Start Next Cycle} 

The constraint \lstinline|nextcyc| leads the system to remove the next event from queue and perform it. Performing is done by a \lstinline|call_event| constraint:

\begin{lstlisting}
% After an event has been performed, nextcyc is triggered. 
%This leads to the next event in the queue to be performed.
<<nextcyc>> <=> de_q(Evt), call_event(Evt).
\end{lstlisting}

\paragraph{Call an Event} 

Event calling just takes a queue element and sets the current time to the time of the event and performs a Prolog \lstinline|call|. Additionally, a message is printed to the screen. After the event has been executed, the next cycle is initiated.

If the queue element is \lstinline|nil| (so no event has been in the queue), the computation is finished and the current time is removed.

\begin{lstlisting}
% no event in queue -> do nothing and remove current time
<<call_event(nil) \ now(_)>> <=> write('No more events in queue. End of computation.'),nl.

<<call_event(q(Time,Priority,Evt)), now(Now)>> <=> 
  Now =< Time | 
  now(Time),
  write(Now:Priority),
  write(' ... '),write('calling event: '), write(Evt),nl,
  call(Evt),
  nextcyc.
\end{lstlisting}

\paragraph{Changing the Buffer System}
\label{changing_the_buffer_system}

For each buffer action, add a \lstinline|do_buffer_action| constraint, that actually performs the code specified in the former action. Modify the action as follows:

\begin{lstlisting}
% Schedule buffer_action
<<buffer_action(BufName, Chunk)>> <=> 
  get_now(Now),
  Time is Now + Duration, 
  add_q(Time, Priority, do_buffer_action(BufName, Chunk)). 
\end{lstlisting}

with appropriate values for \lstinline|Duration| and \lstinline|Priority|.

\paragraph{Production Rules}

As in the last version of the production system, each rule has the following structure:

\begin{lstlisting}
<<<rule>>> @
  {conditions} \ <<fire>> <=> {actions}, conflict_resolution.
\end{lstlisting}

where \lstinline|conflict_resolution/0| just schedules the next \lstinline|fire| event and is defined as:

\begin{lstlisting}
<<conflict_resolution>> <=> 
  get_now(Now),
  add_q(Now,0,fire).
\end{lstlisting}

As the last production rule, there has to be:

\begin{lstlisting}
<<<no-rule>>> @ 
  <<fire>> <=> no_rule.
\end{lstlisting}

which removes the fire constraint if still present and states that no rule has been fired (since the fire constraint is still present). In this case, a new \lstinline|fire| event is scheduled after the next event:

\begin{lstlisting}
<<no_rule>> <=> 
  write('No rule matches -> Schedule next conflict resolution event'),nl,
  after_next_event(do_conflict_resolution).
\end{lstlisting}

\section{Lisp Functions}
\label{lisp_functions}

In ACT-R, it is possible to call some Lisp functions in the model definitions, for example to add chunk-types and declarative memory or set configuration variables. Since those functions cannot be called in the CHR/Prolog environment, there has to be a mechanism to implement missing functions.

\subsection{General Translation}

Lisp functions are lists (indicated by round braces \lstinline|(| and \lstinline|)|), which have the functor as their first element and the function arguments in the rest of the list. Hence, each Lisp function \lstinline|(f arg1 arg2 ...)| called in the model definition of an ACT-R model is translated into the adding of a CHR constraint \lstinline|lisp_f([arg1, arg2, ...])|. For all used functions, there has to be a default implementation in the module \lstinline|std_lisp|. In this implementation, the concept is reduced to simple procedural calls ignoring return values, which is adequate for most of the pure ACT-R models without the experiment environment. Here is an example implementation of the lisp function \lstinline|(chunk-type name slot1 slot2 ...)|:

\begin{lstlisting}
lisp_chunktype([Type|Slots]) <=>
  add_chunk_type(Type,Slots),
  declarative_module:add_chunk_type(Type,Slots).
\end{lstlisting}

\subsection{Configuration Variables}
\label{configuration}

In ACT-R, configuration variables which control the behaviour of the architecture are set with the Lisp function \lstinline|(sgp :Var Val)|, which sets the variable \lstinline|Var| to \lstinline|Val|. To handle such configuration variables, a configuration module can be added to the CHR implementation, that offers an interface to set variables and to ask for their values:

\begin{description}
 \item[Set configuration variables]
 \item[Get the value of a configuration variable]
\end{description}

\subsubsection{The Observer Pattern}



\section{Subsymbolic Layer}

By now, a translation scheme and a framework implementing the symbolic concepts of ACT-R. This section extends this implementation by the subsymbolic layer as described in section~\ref{subsymbolic_layer}.

\subsection{Activation of Chunks}

The activation of a chunk is a numerical value that determines if a chunk is retrieved and how long is the latency of the retrieval. The next sections describe how the concept can be implemented in CHR.

\subsubsection{Base-Level Learning}

One part of the activation value is the base-level activation of a chunk. The value is learned by the system and depends on practice as stated in equation~\eqref{eq:base_level_learning}:

\begin{equation*}
B_i = \mathrm{ln}\left(\sum_{j=1}^n{t_j^{-d}}\right) 
\end{equation*}

\paragraph{Presentations of a Chunk} 

To determine the base-level value of a chunk, the time points when it has been practiced have to be known. A chunk is considered as practiced when it enters the declarative memory either explicitly by calling \lstinline|add_dm| or implicitly by a buffer clearing. Additionally, if a chunk is merged with a chunk that enters the declarative memory, the original chunk is strengthened (so the chunk that has been in the declarative memory before is considered as presented). 

Hence, every time a chunk enters the declarative memory, the time of this event has to be stored. Therefore, a \lstinline|presentation/2| that holds the chunk name and the time of a presentation is introduced. To simplify the use of this constraint, the procedural constraint \lstinline|present/1|, that stores the presentation of a chunk at the current time, can be implemented as follows:

\begin{lstlisting}
<<chunk(Name,Type) \ present(chunk(Name,Type,_))>> <=> 
  getNow(Time),
  presentation(Name,Time).
\end{lstlisting}

The \lstinline|add_dm| command is extended by a presentation event:

\begin{lstlisting}
<<add_dm(ChunkDef)>> <=> 
  add_chunk(ChunkDef), 
  present(ChunkDef). 
\end{lstlisting}

If a chunk that is identical to a chunk already stored enters declarative memory, the original chunk is being strengthened by:

\begin{lstlisting}
<<identical(C1,C2) \ present(chunk(C2,_,_))>> <=> 
  present(C1).
\end{lstlisting}

\paragraph{Calculating the Base-Level Value}

Somewhere in the process of a request, the activation of a set of chunks has to be calculated. Therefore, a constraint \lstinline|calc_activation(Chunk,Activation)|  that gets a chunk name and binds its activation value to the second argument, can be introduced:

\begin{lstlisting}
<<presentation(C,PTime), calc_activation(C,A)>> ==> 
  get_now(Now), 
  Time is Now - PTime, 
  base_level_part(C,Time,_,A).
  
calc_activation(_,_) <=> true.
\end{lstlisting}

These two rules produce for every presentation of the chunk a \lstinline|base_level_part| with the name of the chunk and the time since a particular presentation has happened. Additionally, two unbound variables are given to the part constraint: The first is a variable that will hold an intermediate result and the second is the actual activation value that is bound to the return value of the \lstinline|calc_activation| constraint.

Each of those \lstinline|base_level_part| constraints are part of the result which is the activation value of their chunk. The following rule converts the time $t_j$ to the value $t_j^{-d}$ as stated in equation~\eqref{eq:base_level_learning}:

\begin{lstlisting}
% if A and B not set: set B to Time^(-D). Time is the time since the presentation of this base_level_part
<<base_level_part(_,Time,B,A)>> ==>
  <<<var(A), var(B), 
  Time =\= 0>>> |
  get_conf(bll,D), % decay parameter
  B is Time ** (-D).
\end{lstlisting}

The result is bound to the variable \lstinline|B|. The rule only can be applied, if the intermediate result \lstinline|B| and the result \lstinline|A| are not bound to any value.

As soon as the intermediate result has been calculated, two \lstinline|base_level_part| constraints can be merged, by adding their \lstinline|B| values up according to the base-level learning equation~\eqref{eq:base_level_learning}:

\begin{lstlisting}
% collect base level parts and add them together. Only if Bs are set
<<base_level_part(C,_,B1,A), base_level_part(C,_,B2,A)>> <=>
  <<<nonvar(B1), nonvar(B2), 
  var(A)>>> |
  B is B1+B2,
  base_level_part(C,_,B,A).
\end{lstlisting}

If this rule is applied to exhaustion, only one \lstinline|base_level_part| constraint will be remaining. Hence, below this rule, a rule for this single constraint can be introduced:

\begin{lstlisting}
% if B is set, A is not set and there are no more base_level_parts of this chunk: calculate actual base level activation and store it in A. Only possible if B is =\= 0.
<<base_level_part(_,_,B,A)>> <=>
  <<<var(A),nonvar(B), 
  B =\= 0>>> |
  A is log(B).
\end{lstlisting}

Note, that the rule has to be executed after the last rule cannot be applied anymore, because otherwise it would take an intermediate result as the actual result.

With this set of rules, the base-level activation can be calculated according to its definition. There are some special cases, that can be handled implementation specifically (all cases, where the guards prevent the rules from firing are such cases that may need some kind of special treatment).

\paragraph{Fan Values}

In the calculation process, the fan value $\mathrm{fan}_j$ of a chunk $j$ may be needed. This value is the number of chunks where $j$ appears in the slots plus the chunk itself. So, a chunk that does not appear in any slots has the fan value $1$, a chunk that appears in the slots of another chunk has the value $2$, etc. This can be achieved in CHR as follows:

\begin{lstlisting}
<<chunk(C,_)>> ==> fan(C,1).

<<chunk_has_slot(_,_,C), chunk(C,_)>> ==> fan(C,1).

<<fan(C,F1), fan(C,F2)>> <=> 
  F is F1+F2, 
  fan(C,F).
\end{lstlisting}

The first rule adds a fan of $1$ for each chunk. The next rule adds a fan of $1$ for a chunk \lstinline|C| for each slot where \lstinline|C| is the value. In the last rule, two fan values for one particular chunk are summed up to a single fan value. Note, that this has to be considered when deleting a chunk: For every chunk in the slots of the deleted chunk, the fan value must be decreased by one.

As noted before in section~\ref{distinction_elements_chunks} on page~\pageref{distinction_elements_chunks}, primitive elements are stored as chunks of the type \lstinline|chunk| that has no slots. This is very important of the fan calculation as it is presented here, since the fan value depends on the presence of a \lstinline|chunk| constraint to calculate the proper fan value. Otherwise, the fan value of primitive elements would always be off by one.

\paragraph{Associative Weights}

The activation calculation also depends on a contextual component, the associatiove weights. For a value $S_{ji}$, which describes the associative strength from a chunk $j$ to a chunk $i$, the following rules apply:

\begin{lstlisting}
<<fan(J,F), chunk(I,_), chunk_has_slot(I,_,J) \ calc_sji(J,I,Sji)>> <=> 
  <<<I \== J>>> | 
  Sji is 2 - log(F).

<<calc_sji(_,_,Sji)>> <=> Sji=0.
\end{lstlisting}

The \lstinline|calc_sji(J,I,Sji)| gets a chunk \lstinline|J| and a chunk \lstinline|I|, calculates their associative weight from \lstinline|J| to \lstinline|I| and binds it to \lstinline|Sji|. The first rule can be applied, if \lstinline|J| appears in the slots of chunk \lstinline|I|. Then, the associative weight is calculated according to equation~\eqref{eq:assoc_strength}:

\begin{equation*}
S_{ji} = S - \mathrm{ln}(\mathrm{fan}_j) 
\end{equation*}

The value of $S$ is assumed to be $2$ in this rule; a configurable constant for $S$ as described in section~\ref{configuration} can be introduced easily.

If \lstinline|J| does not appear in the slots of chunk \lstinline|I|, then $S_{ji} := 0$ by definition.

\paragraph{Calculate the Overall-Activations}

The new constraint \lstinline|calc_activations/2| gets a list of chunks and a context and initiates the computation of the overall activation values of the chunks in the list regarding the context. Remember, that for the associative weights, the current context plays a role, since all associative weights from the chunks (the $j$s) in the context to the chunk whose activation is calculated are summed up (see section~\ref{activation} for details).

\begin{lstlisting}[escapeinside={(*@}{@*)}]
<<calc_activations([],_)>> <=>
  true.
  
<<calc_activations([C|Cs],Context)>> <=> 
  calc_activation(C,B), 
  calc_activations(Cs,Context), 
  context(C,Context,Assoc), (*@\label{lst:calc_activations:context}@*)
  
  length(Context,N), (*@\label{lst:calc_activations:attentional1}@*)
  Assoc1 is 1/N * Assoc, (*@\label{lst:calc_activations:attentional2}@*)
  A is B + Assoc1, (*@\label{lst:calc_activations:final}@*)
  max(C,A). (*@\label{lst:calc_activations:max}@*)
\end{lstlisting}

The first rule is the base-case that simply finishes the calculation. The second rule takes the first chunk in the list and calculates its base-level activation \lstinline|B| by \lstinline|calc_activation|. The next line triggers the computation for the rest of the chunks in the list (using the same context).

For the chunk \lstinline|C| the context component, i.e. the associative weight, is calculated by the call of \lstinline|context(C,Context,Assoc)| in line~\ref{lst:calc_activations:context}, which binds the associative weight to \lstinline|Assoc|, i.e. the result of $\sum_{j \in C}{S_{ji}}$ ($C$ is the context as represented by \lstinline|Context|) is bound to the variable \lstinline|Assoc|.

Afterwards, the attentional weighting $W_j$ is considered in lines~\ref{lst:calc_activations:attentional1} and \ref{lst:calc_activations:attentional2}. The variable \lstinline|Assoc1| now holds the value of $W_j \cdot \sum_{j \in C}{S_{ji}}$.

The overall activation of chunk \lstinline|C| is -- as defined in equation~\eqref{eq:activation_equation} -- calculated in line~\ref{lst:calc_activations:final} by adding the base-level activation to the sum of the associative weightings of the chunk.

Eventually, in line~\ref{lst:calc_activations:max}, the activation of this chunk is added to the set of potential maximum candidates of all activation values. The maximum then is calculated as follows:

\begin{lstlisting}[caption={Calculate highest activation of all matching chunks}, label=lst:max_activation]
max(_,A1) \ max(_,A2) <=> 
  A1 >= A2 |
  true.
\end{lstlisting}

This deletes all potential candidates for the maximal activation value that have a smaller value than another candidate. In \cite[19\psqq]{fru_chr_book_2009} this algorithm is presented in more detail.

\paragraph{Threshold and Maximum}

The request is only successful, if there is a matching chunk that has an activation higher than a specified threshold. In the following, it is assumed that the threshold is saved in a \lstinline|threshold/1| constraint.

In the last section, the chunk with the highest activation among all matching chunks is calculated and stored in a \lstinline|max/2| constraint (there is only one \lstinline|max| constraint, after the rule in listing~\ref{lst:max_activation} has been applied to exhaustion). The constraint \lstinline|get_max/2| triggers the final maximum computation and binds the chunk and its activation to its parameters:

\begin{lstlisting}
get_max(MN,MA), max(N,A), threshold(RT) <=> 
  A >= RT | 
  MN=N,
  MA=A.
  
get_max(MN,MA), max(_,A), threshold(RT) <=> 
  A < RT | 
  MN=nil,
  % set activation to threshold
  MA=RT,
  write('No chunk has high enough threshold'),nl.
  
get_max(MN,MA), threshold(RT) <=>
  MN=nil,
  % set activation to threshold if no chunk matches
  MA=RT,
  write('No chunk matches.'),nl.
\end{lstlisting}

The first rule is applied in the case, that the activation of the maximal chunk is higher than the threshold. In this case, the chunk and its activation are simply returned.

In the second rule, the matching chunk with the highest activation does not pass the threshold. Then no chunk can be returned, so the result of the \lstinline|get_max| request is \lstinline|nil|. The activation of this empty chunk is set to the threshold, because the retrieval latency, i.e. the time the retrieval request takes, is dependent on the threshold in case that no chunk could be found. So this value is used later.

The last rule will only be applied, if both of the other rules did not match. This is the case, if there has no \lstinline|max| constraint been put to the store, which does only occur, if no chunk matched the request. This also leads to an empty chunk as a result.

\paragraph{New Module Request Interface}

Requests that regard the subsymbolic layer need some additional information and return some additional results: First, somehow the \emph{Context}, i.e. all chunks that are in the values of the buffer chunks, have to be passed from the buffer system to the requested module (in this case the declarative module, but it may be possible that there are other modules which need the context). Additionally, the requested module has to return the time it takes, since every request may take a different time that is only known by the module, but has to be considered by the scheduler of the procedural module.

The interface from section~\ref{interface_for_module_requests} changes to:

\begin{lstlisting}
module_request(+BufName, +ChunkDef, +Context, -ResChunk, -ResState, -ResTime) 
\end{lstlisting}

where \lstinline|Context| is a list of the chunk names that are in the current context (as defined in section~\ref{current_context} on page~\pageref{current_context}) and \lstinline|ResTime| is bound to the time the request will take. As described in section~\ref{changing_the_buffer_system} on page \pageref{changing_the_buffer_system}, the buffer actions are divided in two phases: The first only schedules the second phase at the time when the action is finished, whereas the second phase actually performs the action, i.e. the changes to the buffers.

The same is valid for buffer requests: They are divided into two rules -- \lstinline|buffer_request/2| and \lstinline|do_buffer_request/2| -- as already described in section~\ref{changing_the_buffer_system} on page~\pageref{changing_the_buffer_system} for the other actions. The difference is, that the request is actually performed immediately when calling \lstinline|buffer_request|, but the effects to the buffers this request has are applied not until \lstinline|do_buffer_request| is called, which is scheduled at the result time (\lstinline|ResTime|) of the request. This is due to the dependence of the latency of a request on the activation values of the matching chunks, so the request has to be performed in advance to calculate the correct time it will take.

This yields the following code in the buffer system:

\begin{lstlisting}[label=Schedule buffer request, escapeinside={(*@}{@*)}]
buffer(BufName, ModName, _) \ buffer_request(BufName, Chunk) <=> %% todo: check for free buffer!!
  write('Scheduled buffer request '),
  write(BufName),nl,
  get_now(Now),
  buffer_state(BufName,busy),
  do_buffer_clear(BufName), % clear buffer immediately
  get_context(Context), (*@\label{lst:schedule_buffer_request:context}@*)
  ModName:module_request(BufName, Chunk, Context, ResChunk,ResState,RelTime),
  performed_request(BufName, ResChunk, ResState), % save result of request
  Time is Now + RelTime, 
  add_q(Time, 0, do_buffer_request(BufName, Chunk)).
\end{lstlisting}

In line~\ref{lst:schedule_buffer_request:context} the current context is calculated and bound in form of a list of chunk names to the variable \lstinline|Context|.
  
\begin{lstlisting}[label=Handle buffer request]
do_buffer_request(BufName, _), buffer(BufName, ModName, _), buffer_state(BufName,_), performed_request(BufName, ResChunk, ResState) <=>  %% todo: check for free buffer!!
  write('performing request: '),write(BufName),nl,
  (ResState=error, 
  buffer(BufName, ModName, nil),
  buffer_state(BufName,error) ;  
  
  ResState = free,
  ResChunk = chunk(ResChunkName,_,_),
  add_chunk(ResChunk), 
  buffer(BufName, ModName, ResChunkName),
  buffer_state(BufName,free)).  
\end{lstlisting}

Note that a buffer request has the lowest priority of all buffer actions, as shown in table~\ref{tab:action_priorities}. If the request would be performed before the buffer modifications and clearings have taken effect, the wrong context would be used for the activation calculations.

\paragraph{Adapting the Retrieval Request}

With the now defined methods, the overall activation of a chunk can be calculated. The module request for the retrieval buffer as introduced in listing~\ref{lst:retrieval_request_symbolic} can be adapted as follows:

\begin{lstlisting}[escapeinside={(*@}{@*)}]
<<module_request(retrieval, chunk(Name,Type,Slots), Context, ResChunk, ResState, RelTime)>> <=> 
  find_chunk(Name,Type,Slots), (*@\label{lst:retrieval_request_subsymbolic:find_chunk1}@*)
  collect_matches(Res), (*@\label{lst:retrieval_request_subsymbolic:find_chunk2}@*)
  calc_activations(Res,Context), (*@\label{lst:retrieval_request_subsymbolic:calc_activations}@*)
  % find threshold for maximum check
  get_conf(rt,RT), (*@\label{lst:retrieval_request_subsymbolic:threshold1}@*)
  threshold(RT), (*@\label{lst:retrieval_request_subsymbolic:threshold2}@*)
  
  get_max(MaxChunk,MaxAct), (*@\label{lst:retrieval_request_subsymbolic:max}@*)
  
  return_chunk(MaxChunk,ResChunk), (*@\label{lst:retrieval_request_subsymbolic:return_chunk}@*)
  get_state(ResChunk,ResState), (*@\label{lst:retrieval_request_subsymbolic:get_state}@*)
  calc_time(MaxAct,RelTime). (*@\label{lst:retrieval_request_subsymbolic:calc_time}@*)
\end{lstlisting}

\begin{description}
 \item[Find matching chunks (lines~\ref{lst:retrieval_request_subsymbolic:find_chunk1}~and~\ref{lst:retrieval_request_subsymbolic:find_chunk2})] First of all, all matching chunks are searched and saved in a list called \lstinline|Res|, similarly to the symbolic approach in listing~\ref{lst:retrieval_request_symbolic}.
 \item[Calculate Activations of the matching chunks (line~\ref{lst:retrieval_request_subsymbolic:calc_activations})] The activations of the matching chunks in the list \lstinline|Res| are computed regarding the context that has been handed over by the request.
 \item[Get the threshold (lines~\ref{lst:retrieval_request_subsymbolic:threshold1}~and~\ref{lst:retrieval_request_subsymbolic:threshold2})] The current threshold is retrieved from the configuration and a \lstinline|threshold| constraint is placed in the store. The next steps will need a threshold constraint present.
 \item[Find chunk with highest activation (line~\ref{lst:retrieval_request_subsymbolic:max})] The chunk with the highest activation is saved in \lstinline|MaxChunk|, its activation value in \lstinline|MaxAct|.
 \item[Return a chunk specification (line~\ref{lst:retrieval_request_subsymbolic:return_chunk})] The request is supposed to return a complete chunk specification in the variable \lstinline|ResChunk|. This is achieved by \lstinline|return_chunk|.
 \item[Return the resulting state of the buffer (line~\ref{lst:retrieval_request_subsymbolic:get_state})] The resulting state \lstinline|ResState| is \lstinline|free|, if a matching chunk has been found and \lstinline|error| if no chunk matches the request:
 
\begin{lstlisting}
get_state(nil,error).
get_state(_,free).
\end{lstlisting}

 \item[Return the time the request takes (line~\ref{lst:retrieval_request_subsymbolic:calc_time})] The time depends on the activation of the chunk. If no matching chunk has been found, the activation is assumed to be the threshold value. This is already achieved by the maximum calculation as described above. The resulting time is computed as follows:
 
\begin{lstlisting}
calc_time(Act,ResTime) :-
  get_conf(lf,F),
  ResTime=F*exp(-Act). 
\end{lstlisting}

This corresponds to equation~\eqref{eq:retrieval_latency}.
\end{description}

\subsubsection{Configuration of the Retrieval}

ACT-R offers some configuration variables which influence the retrieval process. In the CHR implementation, some of those configuration variables are implemented in the system according to the configuration infrastructure as described in section~\ref{configuration}. In ACT-R, configuration variables are set with the command \lstinline|(sgp :Var Val)| which sets the value of the variable \lstinline|Var| to \lstinline|Val|. 

\begin{description}
 \item[Turn on the subsymbolic layer] The variable \lstinline|esc| that can be set to \lstinline|t| for \emph{true} and \lstinline|nil| for \emph{false} controls the activation of the subsymbolic layer for retrieval requests. In CHR, the declarative module observes the value of this variable by the observer interface presented in section~\ref{configuration}. Depending on the value of the variable, the constraint \lstinline|subsymbolic/0| is present or not:
 
\begin{lstlisting}
% subsymbolic layer turned on -> add subsymbolic constraint
set_subsymbolic(t), subsymbolic <=> subsymbolic.
set_subsymbolic(t) <=> subsymbolic.

% subsymbolic layer turned off -> remove subsymbolic constraint
set_subsymbolic(nil), subsymbolic <=> true.
set_subsymbolic(nil) <=> true.
\end{lstlisting}

For each rule only involved in the subsymbolic layer, the constraint \lstinline|subsymbolic/0| is added to its kept head, so the rule only fires if the subsymbolic layer is turned on.

\item[Retrieval threshold] The retrieval threshold $\theta$ is set by the configuration variable \lstinline|rt|.
\item[Latency factor] The latency factor $F$ is set by the configuration variable \lstinline|lf|.
\item[Proportion of $\theta$ and $F$] The configuration system automatically sets the latency factor if the retrieval threshold is set. If an individual value for $F$ should be set, then the automatically set value has to be overwritten after the threshold has been set.

\begin{lstlisting}
latency-factor-by-threshold @
set_conf(rt,RT) ==> LF is 0.35*exp(RT), set_conf(lf,LF). 
\end{lstlisting}

\item[Decay parameter] The decay parameter $d$ is set by the configuration variable \lstinline|bll|.

\end{description}


\subsection{Conflict Resolution and Production Utility}

If there are competing strategies that match a current state, the production system selects the rule with the highest production utility to fire. This process is called \emph{conflict resolution} in the terminology of production rule systems and is described in the following.

\subsubsection{Conflict Resolution}

In \cite[151\psqq]{fru_chr_book_2009} a general implementation of conflict resolution in CHR is described. This approach can be easily adapted to the needs of ACT-R.

Replace every production rule

\begin{lstlisting}
<<{buffer tests} \ fire>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

with two rules

\begin{lstlisting}{caption={Translation scheme for production rules regarding conflict resolution}, label=lst:conflict_resolution_scheme}
<<<delay-name>>> @
  <<fire, {buffer tests}>> ==> {guard} | conflict_set(name).
<<<name>>> @
  <<{buffer tests}, apply_rule(name)>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

The first rule adds the matching rule to a conflict set without computing anything, the second rule actually performs the calculations as soon as the \lstinline|apply_rule| constraint is present.

At the end, add a rule

\begin{lstlisting}
<<<no-rule>>> @
  <<fire>> <=> conflict_set([]), choose.
\end{lstlisting}

As soon as the \lstinline|fire| constraint is present (so the recognize cycle/conflict resolution process begins), each matching rule adds a \lstinline|conflict_set/1| constraint with its name. The last rule finishes the recognize cycle by deleting the fire constraint \emph{after} all rules that match had their chance to add a \lstinline|conflict_set| constraint and adds an empty \lstinline|conflict_set| constraint, indicated by \lstinline|[]|. The constraints store contains at the end of this phase a bunch of \lstinline|conflict_set| constraints that represent the matching rules plus an empty \lstinline|conflict_set| constraint. If no rule matches, there is only an empty \lstinline|conflict_set| constraint in the store.

The last rule also triggers the choosing process by adding the constraint \lstinline|choose|. The following rules handle the choosing process:

\begin{lstlisting}
<<conflict_set(_) \ conflict_set([])>> <=> true.
  
<<<find-max-utility>>> @ <<production_utility(P1,U1), production_utility(P2,U2), conflict_set(P1) \ conflict_set(P2)>> <=>
  <<<U1 >= U2>>> |
  true.
\end{lstlisting}

The first rule deletes the empty \lstinline|conflict_set| constraint, if there are other \lstinline|conflict_set| constraints present, i.e. there has been a rule that can fire.

The second rule assumes, that for each production rule \lstinline|p| in the procedural memory there is a \lstinline|production_utility(p,u)| constraint that holds the utility value \lstinline|u| of the production \lstinline|p|. If there are two \lstinline|conflict_set| constraints in the store, the one with the higher utility value will be kept and the other removed from the store.

If the rules have been applied to exhaustion, there is only one \lstinline|conflict_set| constraint in the store -- either an empty one ore one with the name of a rule. The following rules handle the choosing process:

\begin{lstlisting}
<<choose, conflict_set([])>> <=>
  no_rule.

<<<choose>>> @ <<choose, conflict_set(P)>> <=>
  <<<P \== []>>> |
  get_now(Now),
  Time is Now + 0.05,
  add_q(Time,0,apply_rule(P)). 
\end{lstlisting}

The first rule is only applicable, if there were no matching rules and the empty \lstinline|conflict_set| is still present. Then this fact is indicated by a \lstinline|no_rule| constraint.

In the second rule, the firing of the last remaining rule is scheduled 50\,ms from the current time, as it is described in section~\ref{procedural_knowledge}. The event is the \lstinline|apply_rule(P)| constraint, which leads the second rule in listing~\ref{lst:conflict_resolution_scheme} to fire, which performs the actions of the rule.

When the chosen rule is applied, its actions are performed and eventually, a \lstinline|conflict_resolution| constraint is added to the store. This constraint leads the next conflict resolution event to being scheduled:

\begin{lstlisting}
<<now(Time) \ conflict_resolution>> <=> add_q(Time,0,fire).
\end{lstlisting}

The event is scheduled at the current time with very low priority, so all the actions of the rule have had the chance to be executed.

If there was no matching rule, the \lstinline|no_rule| constraint is in the store. This leads the next conflict resolution event to be scheduled after the next event (which may lead to a change of the system state):

\begin{lstlisting}
<<no_rule>> <=> after_next_event(fire).
\end{lstlisting}

Note, that the described method of implementing the conflict resolution process of ACT-R, matches exactly the description in the reference manual:

\begin{quote}
``The procedural module will automatically schedule conflict-resolution events. The first one is
scheduled at time 0 and a new one is scheduled after each production fires. If no production is
selected during a conflict-resolution event then a new conflict-resolution event is scheduled to occur
after the next change occurs.'' \cite[156]{actr_reference}
\end{quote}

In \cite{fru_chr_book_2009}, the \lstinline|conflict_set| and \lstinline|apply_rule| constraints also have the values of the variables that have been bound in the matching of the rule in the collecting phase\footnote{The example is slightly modified from the original in \cite{fru_chr_book_2009}: In the original, the name of the rule does not play a role and the priorities are known in advance}: 

\begin{lstlisting}
<<<delay-name>>> @
  <<fire, {buffer tests}>> ==> {guard} | conflict_set(rule(name, {Variables in the head of the rule})).
<<<name>>> @
  <<{buffer tests}, apply_rule(rule(name, {Variables in the head of the rule}))>> <=> {guard} | {actions}, conflict_resolution.
\end{lstlisting}

This is due to the fact, that during the conflict resolution process other rules may have changed the constraint store and the rule might not be applicable anymore. However, in ACT-R the procedural module is a serial bottleneck, so no rules that change the state of the buffer system can be applied during the conflict resolution. Additionally, in \cite{fru_chr_book_2009} the rules that were in the conflict set but did not match, remain in the conflict set for the next cycle and are applied, if they have at some point the highest priority in the set and are still applicable (ensured by the bound variables in \lstinline|apply_rule|). In ACT-R, this does not play a role, since the recognize-act cycle is defined serially and only one rule is applied in each cycle. In the next cycle, all rules are checked again for matching heads and the computations are performed on the new values. Note that the problem of trivial non-termination of propagation rules described in \cite[5]{abdennadher_sts_chr13}, which has to be considered when changing the operational order of rule applications in CHR, does not play a role for ACT-R, since it does not implement propagation rules.

\subsubsection{Computing the Utility Values}

As described in section~\ref{production_utility}, rules can have a certain amount of reward that can be distributed among all rules that have been applied since the last reward has been distributed.

The reward a rule can distribute, can be saved in a \lstinline|reward/2| constraint. If a rule is applied, the time of application can be saved in a \lstinline|to_reward/2| constraint, that states that the rule in the constraint has been applied and therefore receives a part of the next reward as soon as it occurs: 

\begin{lstlisting}
<<apply_rule(P)>> ==> <<<P \== []>>> | get_now(Now), to_reward(P,Now).
\end{lstlisting}

Note, that the \lstinline|apply_rule/1| constraint from the last section is used to determine, when a rule is fired.

When a rule that can distribute a reward is applied, the reward is triggered:

\begin{lstlisting}
<<apply_rule(P), reward(P,R)>> ==>
  <<<P \== []>>> |
  trigger_reward(R).
\end{lstlisting}

This will reward all rules that have a \lstinline|to_reward/2| constraint in the store, which leads to a new production utility value:

\begin{lstlisting}[escapeinside={(*@}{@*)}, label=lst:trigger_reward]
<<trigger_reward(R) \ production_utility(P,U), to_reward(P,FireTime)>> <=>
  calc_reward(R,FireTime,Reward),
  get_conf(alpha,Alpha),
  NewU is U + Alpha*(Reward-U), (*@\label{lst:trigger_reward:learning}@*)
  production_utility(P,NewU).
  
calc_reward(R,FireTime,Reward) :- (*@\label{lst:trigger_reward:calc_reward}@*)
  get_now(Now),
  Reward is R - (Now-FireTime).
\end{lstlisting}

Note, that in line~\ref{lst:trigger_reward:learning} the utility is adapted by the utility learning rule as shown in equation~\eqref{eq:utility_learning}. The reward the rule receives is calculated by the Prolog predicate in lines~\ref{lst:trigger_reward:calc_reward} sqq.: The more time passed since the rule application, the less the reward of the rule.

In the end, there has to be a rule that cleans up the reward trigger, after all the rules have been rewarded. This ensures, that the next \lstinline|to_reward| constraints are not immediately consumed by the last reward trigger:

\begin{lstlisting}
<<trigger_reward(_)>> <=> true.
\end{lstlisting}

\subsubsection{Configuration of the Conflict Resolution}

There are some methods to influence the conflict resolution process using the ACT-R command \lstinline|(spp ...)| that can set values for individual production rules. This command is translated into CHR as described in section~\ref{lisp_functions}. Additionally, there are some configuration variables that can be set -- as described in section~\ref{configuration} -- by the command \lstinline|(sgp ...)|:

\begin{description}
 \item[Setting the utility of a rule] Utilities can be set statically by the user by the ACT-R command \lstinline|(spp P :u U)|, which sets the utility of the rule \lstinline|P| to \lstinline|U|.
 \item[Setting the reward of a rule] The amount of reward a rule can distribute is set by the user. By default, no rules have a reward to trigger. With the ACT-R command \lstinline|(spp P :reward R)|, the reward of the rule \lstinline|P| is set to \lstinline|R|. This command is also implemented among the standard lisp methods.  
 \item[Default values and turning the utility mechanisms off] At the moment, there is no command in the CHR implementation that allows to turn off the conflict resolution mechanisms: The system sets a default utility value for each production rule and no rewards in the initialization process (the rule \lstinline|init @ run <=> ...| as described in section~\ref{initialization}). The user is able to set other initial utility values and rewards for particular rules. If no rewards are set, the utility values will remain at their initial values. Hence, if the user does not set any utilities or rewards, each rule will have the same utility value that does not change. If there are competing rules, the conflict resolution process will pick one. This can be regarded as turned off utility mechanisms.
 \item[Learning rate] The learning rate $\alpha$ is set by the command \lstinline|(sgp :alpha A)| that sets the configuration variable \lstinline|alpha| to \lstinline|A|.
\end{description}

\subsection{Extended Component Diagram}

\section{Compiler}

With the implementation of the basic ACT-R concepts, a simple compiler has been created to automate the translation of Lisp ACT-R rules to CHR rules according to the translation schemes defined in section~\ref{implementation:procedural_module}. The compiler has been built using Prolog and CHR. However, it still lacks suitable translation of some of the details in the procedural module presented in section~\ref{implementation:production_rule_grammar}.

\subsection{Basic Idea}

The basic idea of the compiler is that it gets an ACT-R model definition written in the Lisp-like ACT-R syntax and produces the correspondent CHR rules. The model should be executable by just loading the translation and typing in the query \lstinline|run|. Hence, the translated model should somehow load the CHR framework simulating ACT-R, for instance the modules, the buffer system, the scheduler, etc. Figure~\ref{fig:basic_idea} illustrates the process.

\subsection{Compiling}

The compiler consists of three parts: A tokenizer, a parser and an actual translation component. Those three parts are described individually in the following sections.

\subsubsection{Tokenizer}

The tokenizer gets the file with the model definition as input and does some preprocessing on it: From the input -- a sequence of characters -- it builds a list of tokens. Tokens are separated by white-space (or by special characters) and can be one of the following character sequences in the input:

\begin{description}
 \item[Special Characters] are individual tokens and are defined as all allowed characters that are not letters, numbers or white-space. In ACT-R: \lstinline|!, (, ), +, -, =, >, ?|. Some special characters of ACT-R are missing in this list, but are not implemented in the compiler, yet.
 \item[Keywords] are treated like a special character, but contains more than one symbol. In ACT-R, a keyword is \lstinline|==>|, separating the LHS from the RHS of a production rule.
 \item[Identifier] Everything that starts with a letter and contains only letters or numbers. An identifier ends, if a special character or a white-space is read from the input. An exception is the \lstinline|-| character, which can be used within identifiers. \emph{Example:} \lstinline|count, addition-fact, chunk1|
 \item[Numbers] Every word, that only contains numbers.
\end{description}

\begin{example}
\FIXME{tokenize some input here}
\end{example}




\subsubsection{Parser}

\subsubsection{Translation Component}

\subsection{Problems with the current implementation}






