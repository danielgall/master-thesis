\chapter{Description of ACT-R}

In computational psychology, the approach to explore human cognition is to implement detailed, computational models that enable computers to execute them and simulate human behaviour \cite{sun_introduction_2008}. By conducting the same experiments with humans and with simulations of the suggested underlying cognitive models, the plausibility of models can be checked and models can be improved gradually.

On the other hand, psychology is experiencing a movement towards specialization \cite{anderson_integrated_2004}, ie. there are a lot of independent, highly specialized fields that lack a more global view.

To implement consistent models of cognition, it is necessary to develop a theory that tries to put all those highly specialized components together and allows modelers to build their models on the basis of this theory. Cognitive architectures try to explain \FIXME{definition cognitive architecture from book}
\FIXME{move to introduction and motivation}


Adaptive Control of Thought (ACT-R) is a cognitive architecture, that ``is capable of interacting with the outside world, has been mapped onto brain structures, and is able to learn to interact with complex dynamic tasks.'' \cite[p. 29]{taatgen_modeling_2006} 

On top of the provided cognitive architecture, one can specify models for specific tasks. The cognitive architecture constrains the modeling to facilitate the modeling process. Thereby it ensures cognitive plausibility to some degree \cite[p. 29]{taatgen_modeling_2006}.

When talking about ACT-R, one can refer to the theory or the implementation. The theory gives a view which abstracts from implementational details that may be concerned when talking about implementation \FIXME{source}. In this work, implementation always refers to the vanilla Lisp implementation that can be downloaded from \cite{actr_homepage}.

In this chapter, a short overview over the theory of ACT-R is given. First, the description is informal to provide a general image of how ACT-R works. Then, some important parts of the system are defined more formally in chapter \ref{implementation}, as soon as it is needed in the implementation. All of the information in this chapter refers to the theory. Implementation is discussed in chapter \ref{implementation}.

\section{Procedural and Declarative Knowledge}

A central idea of ACT-R is the distinction between \emph{declarative} and \emph{procedural knowledge.} The declarative knowledge consists of simple facts, whereas the procedural knowledge contains information on what to do with those facts.

\subsection{Modular organization}

This approach leads to a modular organization of ACT-R with modules for each purpose needed to simulate human cognition. Figure \ref{fig:modular_organization} provides an overview of some of the default modules of ACT-R. For example, the declarative module stores the factual information (the declarative knowledge), the visual module perceives and processes the visual field, the procedural module holds the procedural information and controls the computational process. 

Each module is independent from the other modules and computations can be performed massively parallel within one module. The visual module, for example, can process the entire visual field at once. Additionally, modules can perform their computations parallel to other modules, for instance: The declarative module can search a specific fact while the visual module processes the visual field.

However, each module can perform its computation only locally and has no access to computations of other modules. To communicate, modules have associated buffers, where they can put a limited amount of information -- one primitive knowledge element -- and the procedural module can access each of these buffers. The information in a buffer could be one single fact retrieved from declarative memory or one visual object from the visual field perceived by the visual module. Information between modules is exchanged by the procedural module taking information from one buffer and putting it into another (with an optional computation on the way). This leads to a serial bottleneck in the computation, since every communication between modules has to go its way through the procedural module.

In figure \ref{fig:recognize_act} the general computational process is illustrated by showing the \emph{recognize-act-cycle}: The procedural information is stored as rules that have a \emph{condition} and an \emph{action}. The condition refers to the so-called \emph{working memory}, which basically is the content of all the buffers. In the recognize-phase of the cycle, a suitable rule that matches the current state of the working memory is searched. If the condition of a rule holds, it \emph{fires} and performs its actions -- this is the act-phase of the cycle. Those actions can cause changes on the buffers that may lead to the next rule matching the current state in the next recognize-part of the cycle.

In the following sections, some of the modules and their precise interaction will be described in more detail.

\subsection{Declarative Knowledge}

The declarative module organizes the factual knowledge as an associative memory. Ie., it consists of a set of concepts that are connected to each other in a certain way.

Such elementary concepts are represented in form of chunks that can be seen as basic knowledge elements. They can have names, but they are not critical for the description of the facts and just for readability in the theory. The real description of a concept comes from its connections.

Chunks can have slots that are connected to other chunks or elements. Such an element can be regarded as a chunk without any slots. For instance, the fact that five plus to equals to seven can be modeled as a chunk that is connected to the numbers 5, 2 and 7 (see \ref{fig:chunk_addition_fact}). Notice that in the figure each slot has a individual name. This is necessary to distinguish the connections of the chunks, otherwise the summands were indistinguishable from the sum in the example.

Each chunk is associated with a chunk-type that determines which slots a chunk can have. For example, the fact in figure \ref{fig:chunk_addition_fact} has the type \verb|addition-fact|. All chunks of this type must provide the slots \verb|arg1|, \verb|arg2| and \verb|sum|.

For the chunk types there is no upper limit of slots they can define. However, Anderson et al. suggested to limit the number of slots to Miller's Number of $7 \pm 2$, for the reason of plausibility \cite{unknown}. \FIXME{Find cite}

\subsubsection{Textual Representation of Chunks}

In the following, chunk-type and chunk definitions are given in a textual way which is based on the syntax of the standard implementation of ACT-R.

\begin{definition}
The term \verb|chunk-type(name slot1 slot2 ... slotn)| defines a chunk-type with name \verb|name| and slots with names \verb|slot1| to \verb|slotn|.

The term \verb|chunk(name isa type slot1 val1 ... slotn valn)| defines a chunk of type \verb|type| with name \verb|name| and corresponding slot-value-pairs, where \verb|slot1 val1| signifies that the value of the slot \verb|slot1| is \verb|val1|. The slot-value-definitions must match the chunk-type-definition of \verb|type|.
\end{definition}

\begin{example}
 The addition-fact chunk in figure \ref{fig:chunk_addition_fact} and its chunk-type are defined as follows:\\
 \verb|chunk-type(addition-fact arg1 arg2 sum)|\\
 \verb|chunk(a isa addition-fact arg1 5 arg2 2 sum 7)|
\end{example}

\subsubsection{Buffers}

As mentioned before, modules communicate through buffers by putting a limited amount of information into their associated buffers. More precisely, each buffer can hold only \emph{one chunk at a time}.

For example, the declarative module has the retrieval buffer associated with it, which can hold one specific declarative chunk. The declarative module can put chunks in the buffer that can be processed by the procedural module, which is described in the next section.

\subsection{Procedural Knowledge}

Procedural Knowledge in ACT-R is formulated as a set of condition-action rules. Each rule defines in its condition-part the circumstances under which it can be applied. Those conditions refer to the current chunks in the buffer. In the condition-part of a rule it is defined which kind of chunk with certain slot values must be present in which buffer for the rule to fire. For example, one rule in the process of adding the numbers 5 and 2 could have the conditions that there is a chunk of type \verb|addition-fact| in the retrieval buffer with 5 and 7 in its argument-slots and specify certain actions if this is the case.

If the chunks in the buffers match all the conditions stated in a rule, it can be applied (``fired''), which leads its action-part to be performed. Actions can be changes of values in the chunks of a buffer, the clearing of a buffer or a buffer request, which leads the corresponding module to put a certain chunk into the requested buffer. Buffer requests are also stated in form of a chunk description where chunk-type and slots can have a special meaning. The actual semantics of a request is dependent on the module. For example, the declarative module will search a chunk that matches the chunk in the description of the request. One production rule, for instance, in the process of adding the numbers 5 and 2 could be, if the wrong \verb|addition-fact| chunk is stored in the retrieval buffer, a retrieval request will be performed, which states that the declarative module should put a chunk into the retrieval buffer, that has 5 and 2 in its argument slots and is of type \verb|addition-fact|. After the successful performance of the request, a chunk with 5 and 2 as its argument will be stored in the retrieval buffer, that also has a value for the sum.

Although the term \emph{module} is used for the procedural system, it differs a lot from the other modules: In contrast to other modules, the procedural module has no own buffers, but can access the buffers of all the other modules. ``It really is just a system of mapping cortical buffers to other cortical buffers'' \cite[p. 54]{anderson_how_2007}.

The procedural system can only fire one rule at once and it takes 50\,ms for a rule to fire \cite[p. 54]{anderson_how_2007}. After firing the selected rule, the next recognize cycle starts and a suitable rule will be detected and caused to fire. While that time, other modules may perform requests triggered in the action of the first rule. Sometimes, rules have to wait for results of certain modules and they cannot fire before those results are available. Those two facts illustrate how the procedural module can become a serial bottleneck in the computation process.

\subsection{Goal Module}

An essential part of human cognition is the ability to keep track of the current goal to achieve and to subordinate all actions to the goal \cite[p. 1041]{anderson_integrated_2004}. For complex cognitive tasks, several rules have to be applied in series and intermediate results must be stored (without changing of the environment). Another important aspect is, that complex tasks can have different subgoals that have to be achieved to achieve the main goal. For instance, if one wants to add two multi-digit numbers, he would add the columns and remember the results as intermediate results.

In ACT-R, the goal module with the goal buffer is used for this purpose. 

\subsubsection{Working memory}

The goal module and buffer are often referred to as \emph{working memory} \cite[p. 1041]{anderson_integrated_2004}, but actually it can have another meaning as stated in \cite{anderson_working_1996}: As usual in production systems, everything that is present to the production system and can match against the production rules is part of the working memory. With this definition, all chunks in the buffers form the working memory.

In this work, the term working memory will be used in this second meaning, since it discusses the topic from a computer science view and the second definition is related to production rule systems. When talking about the content of the goal buffer, this will be remarked explicitly.

\subsection{Other Modules/Outside World}

Since human cognition is embodied, there must be a way to interact with the outside world to simulate human cognition in realistic experiments. Therefore, ACT-R offers perceptual/motor modules like the manual module for control of the hands, the visual module for perceiving and processing the visual field or the aural module perceiving sounds in the environment.

Like with every other module, communication is achieved through the buffers of those modules. 

\subsection{Example}

\FIXME{finish}
counting
inspired by tutorial
more examples can be found there

\section{Serial and Parallel Aspects of ACT-R}

In the previous sections there were some remarks on the serial and parallel aspects of ACT-R. According to \cite[p. 68]{anderson_how_2007}, four types of parallelism and seriality can be distinguished:

\begin{description}
 \item[Within-Module Parallelism] As mentioned above, one module is able to explore a big amount of data in parallel. For example, the visual module can inspect the whole visual field or the declarative module performs a massively parallel search over all chunks.
 \item[Within-Module Seriality] 
 \item[Between-Module Parallelism]
 \item[Between-Module Serialism]
\end{description}

\FIXME{finish}

The procedural module is the central serial bottleneck in the system, since the whole communication between modules is going through the production system and the whole computation process is controlled there. The fact that only one rule can fire at a time leads to a serial overall computation. Another serial aspect is that some computations need to wait for the results of a module request. If no other rule matches in the time while the request is performed, the whole system has to wait for this calculation to finish. After the request, the module puts the result in its buffer and the rule needing the result of the computation can fire and computation is continued.

\section{Subsymbolic layer}

The previously discussed aspects of the ACT-R theory are part of the so-called symbolic layer. This layer only describes discrete knowledge structures without dealing with more complex questions like: 

\begin{itemize}
\item How long does it take to retrieve a certain chunk? 
\item Forgetting of chunks
\item If more than one rule matches, which one will be taken?
\end{itemize}

Therefore, ACT-R provides a subsymbolic layer that introduces ``neural-like activation processes that determine the availability of [\dots] symbolic structures'' \cite{anderson_implications_2000}.

\subsection{Activation of Chunks}

The activation $A_i$ of a chunk $i$ is a numerical value that determines if and how fast a chunk can be retrieved by the declarative module. Suppose there are two chunks that encode addition facts for the same two arguments (let them be 5 and 2), but with different sums (6 and 7), for example. This could be the case, if a child learned the wrong fact, for example. When stating a module request for an addition fact that encodes the sum of 5 and 2, somehow one of the two chunks has to be chosen by a certain method, since they are both matching the request. This is determined by the activation of the chunks: The chunk with the higher activation will be chosen.

Additionally, a very low chunk activation can prevent a chunk of being retrieved: If the activation $A_i$ is less than a certain \emph{threshold} $\tau$, then the chunk $i$ cannot be found.

At last, activation determines also how fast a chunk is being retrieved: The higher the activation, the shorter the retrieval time.

The activation $A_i$ of a chunk $i$ is defined as:

\begin{equation}
 \label{eq:activation_equation}
 A_i = B_i + \sum_j{W_j S_{ji}}
\end{equation}

where $B_i$ is the \emph{base-level activation} of the chunk $i$, $W_j$ the \emph{attentional weighting} of chunk $j$ and $S_{ji}$ the \emph{associative strength} from chunk $j$ to chunk $i$ \cite[p. 1042]{anderson_integrated_2004}, \cite[p. 33]{taatgen_modeling_2006}. Figure \ref{fig:chunk_activation} illustrates the addition-fact $5 + 2 = 7$ with the corresponding quantities introduced in the last equation. Equation \eqref{eq:activation_equation} is called \emph{Activation Equation}.

The idea of this equation is, that the activation of a chunk is composed of its own base-level activation and a spreading part \FIXME{aufteilen in zwei Gleichungen wie im Tutorial: erst nur base level und dann activation spreading!!}

The values for $W_j$ reflect how many sources of activation are in the current context. A source of activation is a chunk that is referred to in the slots of a chunk in the goal buffer or in all buffers, depending on the version of the ACT-R theory \cite[p. 1042]{anderson_integrated_2004}, \cite[p. 33]{taatgen_modeling_2006}, \cite[unit 5, p. 1]{actr_tutorial}. To limit the total amount of source of activation, $W_j$ is set to $\frac{1}{n}$, where $n$ is the number of sources of activation. With this equation, the total amount of activati \FIXME{finish}

The base-level activation is a value associated with each chunk and depends on how often a chunk has been practiced and when the last retrieval of the chunk has been performed. Hence, $B_i$ of chunk $i$ is defined as:

\begin{equation}
\label{eq:base_level_learning}
B_i = \mathrm{ln}\left(\sum_{j=1}^n{t_j^{-d}}\right)
\end{equation}

where $t_j$ is the time since the $j$th practice, $n$ the number of overall practices of the chunk and $d$ is the decay rate that describes how fast the base-level activation decreases if a chunk has not been practiced (how fast a chunk will be forgotten). Usually, $d$ is set to $0.5$ \cite[p. 1042]{anderson_integrated_2004}. Equation \eqref{eq:base_level_learning} is called \emph{Base-Level Learning Equation}, as it defines the adaptive learning process of the base-level value.

This equation is the result of a rational analysis by Anderson and Schooler. It reflects the log odds that a chunk will reappear depending on when it has appeared in the past \cite[p. 33]{taatgen_modeling_2006}. This analysis led to the \emph{power law of practice} \cite[p. 1042]{anderson_integrated_2004}. In \cite[pp. 8--11]{anderson_implications_2000} equation \eqref{eq:base_level_learning} is motivated in more detail by describing the power law of learning/practice, the power law of forgetting and the multiplicative effect of practice and retention with some data. Shortly, it states, that if a particular fact is practiced, there is a improvement of performance which corresponds to a power law. At the same time, performance degrades with time corresponding to a power law. Additionally, they state that if a fact has been practiced a lot, it will not be forgotten for a longer time.

\subsubsection{Strength of Association and Fan effect}

In equation \eqref{eq:activation_equation} the strength of association $S_{ji}$ from a chunk $j$ to a chunk $i$ is used to determine the activation of a chunk $i$. In the ACT-R theory, the value of $S_{ji}$ is set to 

\begin{equation}
S_{ji} = S - \mathrm{ln}(\mathrm{fan}_j)
\end{equation}

where $\mathrm{fan}_j$ is the number of facts associated to term $j$ \cite[p. 1042]{anderson_implications_2000}. This states that the associative strength from chunk $j$ to $i$ decreases the more facts are associated to $j$.

This is due to the \emph{fan effect:} The more facts a person studies about a certain concept, the more time he or she needs to retrieve a particular fact of that concept \cite[p. 186]{anderson_fan_1999}. This has been demonstrated in an experiment presented in \cite{anderson_implications_2000}, where every participant studied facts about persons and locations like:

\begin{itemize}
 \item A hippie is in the park.
 \item A hippie is in the church.
 \item A captain is in the bank.
 \item \dots
\end{itemize}

\FIXME{Finish}


motivation and effects of activation
activation equation
base level learning
latency

\subsection{Production Utility}



\section{Learning}

